{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7576152-31b7-4ac4-b045-c1ea73edba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# IDM模型定义\n",
    "def idm_model(s, v, dv, v0=30.0, T=1.5, a=1.0, b=2.0, s0=2.0):\n",
    "    \"\"\"\n",
    "    IDM模型计算加速度\n",
    "    \"\"\"\n",
    "    # 计算期望间距\n",
    "    s_star = s0 + max(0, v * T + (v * dv) / (2 * np.sqrt(a * b)))\n",
    "    \n",
    "    # 计算加速度\n",
    "    acceleration = a * (1 - (v / v0)**4 - (s_star / s)**2)\n",
    "    \n",
    "    # 物理约束：限制加速度在合理范围内\n",
    "    acceleration = np.clip(acceleration, -b, a)\n",
    "    \n",
    "    return acceleration\n",
    "\n",
    "# 改进的加速度计算函数\n",
    "def calculate_smoothed_acceleration(v_data, dt, window_length=0.5, polyorder=2):\n",
    "    \"\"\"\n",
    "    使用Savitzky-Golay滤波器平滑计算加速度\n",
    "    \"\"\"\n",
    "    if len(v_data) < window_length:\n",
    "        acc = np.gradient(v_data, dt)\n",
    "    else:\n",
    "        try:\n",
    "            v_smooth = savgol_filter(v_data, window_length, polyorder)\n",
    "            acc = np.gradient(v_smooth, dt)\n",
    "        except:\n",
    "            acc = np.gradient(v_data, dt)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# 计算NRMSE\n",
    "def calculate_nrmse(real, pred):\n",
    "    \"\"\"计算标准化均方根误差\"\"\"\n",
    "    if len(real) == 0 or len(pred) == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((real - pred) ** 2))\n",
    "    range_val = np.max(real) - np.min(real)\n",
    "    \n",
    "    if range_val < 1e-6:\n",
    "        return rmse / (np.std(real) + 1e-6)\n",
    "    \n",
    "    return rmse / range_val\n",
    "\n",
    "# 计算RMSE\n",
    "def calculate_rmse(real, pred):\n",
    "    \"\"\"计算均方根误差\"\"\"\n",
    "    if len(real) == 0 or len(pred) == 0:\n",
    "        return 1.0\n",
    "    return np.sqrt(np.mean((real - pred) ** 2))\n",
    "\n",
    "# 增强的目标函数 - 保持NRMSE标准但增加参数敏感性\n",
    "def idm_objective_enhanced(params, data):\n",
    "    \"\"\"\n",
    "    目标函数：最小化加权NRMSE和，但增加对参数变化的敏感性\n",
    "    \"\"\"\n",
    "    v0, T, a, b, s0 = params\n",
    "    \n",
    "    # 放宽参数约束以允许更大差异\n",
    "    if (v0 < 12 or v0 > 45 or T < 0.2 or T > 5.0 or \n",
    "        a < 0.2 or a > 6.0 or b < 0.2 or b > 6.0 or s0 < 0.5 or s0 > 10.0):\n",
    "        return 1e10\n",
    "\n",
    "    s_data, v_data, dv_data, dt, v_next_data, _ = data\n",
    "    acc_real = np.gradient(v_data, dt)\n",
    "    \n",
    "    # 模拟整个轨迹\n",
    "    v_sim = [v_data[0]]\n",
    "    s_sim = [s_data[0]]\n",
    "    if len(v_data) > 1:\n",
    "        initial_acc = (v_data[1] - v_data[0]) / dt\n",
    "    else:\n",
    "        initial_acc = 0.0\n",
    "    acc_sim = [initial_acc]\n",
    "    \n",
    "    for i in range(len(s_data)-1):\n",
    "        current_acc = idm_model(s_sim[-1], v_sim[-1], dv_data[i], v0, T, a, b, s0)\n",
    "        \n",
    "        v_next = v_sim[-1] + current_acc * dt\n",
    "        s_next = s_sim[-1] + (dv_data[i] - current_acc) * dt\n",
    "        \n",
    "        # 放宽物理约束\n",
    "        v_next = max(0.1, min(45.0, v_next))\n",
    "        s_next = max(0.5, min(250.0, s_next))\n",
    "        \n",
    "        v_sim.append(v_next)\n",
    "        s_sim.append(s_next)\n",
    "        acc_sim.append(current_acc)\n",
    "    \n",
    "    v_sim = np.array(v_sim)\n",
    "    s_sim = np.array(s_sim)\n",
    "    acc_sim = np.array(acc_sim)\n",
    "    \n",
    "    min_len = min(len(v_data), len(v_sim), len(s_data), len(s_sim), len(acc_real), len(acc_sim))\n",
    "    \n",
    "    if min_len < 10:\n",
    "        return 1e10\n",
    "    \n",
    "    v_data_trim = v_data[:min_len]\n",
    "    v_sim_trim = v_sim[:min_len]\n",
    "    s_data_trim = s_data[:min_len]\n",
    "    s_sim_trim = s_sim[:min_len]\n",
    "    acc_real_trim = acc_real[:min_len]\n",
    "    acc_sim_trim = acc_sim[:min_len]\n",
    "    \n",
    "    # 计算三个NRMSE（保持原有权重）\n",
    "    nrmse_v = calculate_nrmse(v_data_trim, v_sim_trim)\n",
    "    nrmse_s = calculate_nrmse(s_data_trim, s_sim_trim)\n",
    "    nrmse_acc = calculate_nrmse(acc_real_trim, acc_sim_trim)\n",
    "    \n",
    "    # 加权总和（保持原有标准）\n",
    "    weights = [1, 1, 1]\n",
    "    total_nrmse = (weights[0] * nrmse_v + \n",
    "                   weights[1] * nrmse_s + \n",
    "                   weights[2] * nrmse_acc)\n",
    "    \n",
    "    return total_nrmse\n",
    "\n",
    "# 增强的校准函数 - 使用多起点优化\n",
    "def calibrate_idm_enhanced(track_data, dt=0.5):\n",
    "    \"\"\"\n",
    "    增强的IDM参数校准，使用多起点优化来增加参数差异性\n",
    "    \"\"\"\n",
    "    s_data = track_data['sReal']\n",
    "    v_data = track_data['vFollReal']\n",
    "    dv_data = track_data['dvReal']\n",
    "    v_next_data = track_data['vFollReal_next']\n",
    "    \n",
    "    # 计算平滑的真实加速度\n",
    "    acc_real = None\n",
    "    \n",
    "    # 多种不同的初始猜测，覆盖不同类型的驾驶行为\n",
    "    initial_guesses = [\n",
    "        # 激进型驾驶员 - 高期望速度，短车头时距，大加速度\n",
    "        [35.0, 0.8, 2.5, 3.0, 1.5],\n",
    "        # 保守型驾驶员 - 低期望速度，长车头时距，小加速度  \n",
    "        [20.0, 2.5, 0.8, 1.5, 3.0],\n",
    "        # 中等型驾驶员 - 平衡参数\n",
    "        [28.0, 1.5, 1.2, 2.5, 2.5],\n",
    "        # 快速反应型 - 短时距但中等速度\n",
    "        [30.0, 0.6, 1.8, 3.5, 2.0],\n",
    "        # 安全优先型 - 长时距，温和加减速\n",
    "        [25.0, 3.0, 0.6, 1.2, 3.0],\n",
    "        # 高速激进型\n",
    "        [35.0, 1.0, 3.0, 3.0, 1.0],\n",
    "        # 低速保守型\n",
    "        [18.0, 3.5, 0.5, 1.0, 3.0]\n",
    "    ]\n",
    "    \n",
    "    # 扩大参数边界以允许更大差异\n",
    "    bounds = [\n",
    "        (15.0, 65.0),   # v0 - 扩大范围\n",
    "        (0.1, 9.0),     # T - 扩大范围\n",
    "        (0.1, 9.0),     # a - 扩大范围\n",
    "        (0.1, 9.0),     # b - 扩大范围\n",
    "        (0.1, 9.0)     # s0 - 扩大范围\n",
    "    ]\n",
    "    \n",
    "    data = (s_data, v_data, dv_data, dt, v_next_data, acc_real)\n",
    "    \n",
    "    best_result = None\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    \n",
    "    print(f\"  尝试 {len(initial_guesses)} 个不同的初始点...\")\n",
    "    \n",
    "    # 尝试多个初始点，寻找全局最优解\n",
    "    for i, initial_guess in enumerate(initial_guesses):\n",
    "        try:\n",
    "            result = minimize(\n",
    "                idm_objective_enhanced,\n",
    "                initial_guess,\n",
    "                args=(data,),\n",
    "                bounds=bounds,\n",
    "                method='L-BFGS-B',\n",
    "                options={'maxiter': 800, 'ftol': 1e-6, 'gtol': 1e-6}\n",
    "            )\n",
    "            \n",
    "            if result.fun < best_score:\n",
    "                best_score = result.fun\n",
    "                best_params = result.x\n",
    "                best_result = result\n",
    "                print(f\"    初始点 {i+1}: NRMSE = {result.fun:.4f} - 找到更好解\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # 如果多起点优化失败，回退到单起点\n",
    "    if best_params is None:\n",
    "        print(\"  多起点优化失败，使用单起点优化...\")\n",
    "        initial_guess = [25.0, 1.5, 1.0, 2.0, 2.0]\n",
    "        try:\n",
    "            result = minimize(\n",
    "                idm_objective_enhanced,\n",
    "                initial_guess,\n",
    "                args=(data,),\n",
    "                bounds=bounds,\n",
    "                method='L-BFGS-B',\n",
    "                options={'maxiter': 500, 'ftol': 1e-5}\n",
    "            )\n",
    "            if result.fun < 10:\n",
    "                best_params = result.x\n",
    "                best_score = result.fun\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    if best_score < 15.0:  # 放宽收敛标准以获取更多成功校准\n",
    "        print(f\"  最终结果: NRMSE = {best_score:.4f}\")\n",
    "        return best_params\n",
    "    else:\n",
    "        print(f\"  结果不佳: NRMSE = {best_score:.4f}\")\n",
    "        return None\n",
    "\n",
    "# 改进的误差计算 - 增加随时间变化的误差\n",
    "def calculate_errors(track_data, params, dt=0.5):\n",
    "    \"\"\"\n",
    "    计算模型误差指标\n",
    "    \"\"\"\n",
    "    s_data = track_data['sReal']\n",
    "    v_data = track_data['vFollReal']\n",
    "    dv_data = track_data['dvReal']\n",
    "    v_next_data = track_data['vFollReal_next']\n",
    "    \n",
    "    v0, T, a, b, s0 = params\n",
    "    \n",
    "    # 计算平滑的真实加速度\n",
    "    acc_real = np.gradient(v_data, dt)\n",
    "    \n",
    "    # 模拟整个轨迹\n",
    "    v_sim = [v_data[0]]\n",
    "    s_sim = [s_data[0]]\n",
    "    if len(v_data) > 1:\n",
    "        initial_acc = (v_data[1] - v_data[0]) / dt\n",
    "    else:\n",
    "        initial_acc = 0.0\n",
    "    acc_sim = [initial_acc]\n",
    "    \n",
    "    for i in range(len(s_data)-1):\n",
    "        current_acc = idm_model(s_sim[-1], v_sim[-1], dv_data[i], v0, T, a, b, s0)\n",
    "        v_next = v_sim[-1] + current_acc * dt\n",
    "        s_next = s_sim[-1] + (dv_data[i] - current_acc) * dt\n",
    "        \n",
    "        v_next = max(0.1, min(45.0, v_next))\n",
    "        s_next = max(0.5, min(250.0, s_next))\n",
    "        \n",
    "        v_sim.append(v_next)\n",
    "        s_sim.append(s_next)\n",
    "        acc_sim.append(current_acc)\n",
    "    \n",
    "    v_sim = np.array(v_sim)\n",
    "    s_sim = np.array(s_sim)\n",
    "    acc_sim = np.array(acc_sim)\n",
    "    \n",
    "    min_len = min(len(v_data), len(v_sim), len(s_data), len(s_sim), len(acc_real), len(acc_sim))\n",
    "    \n",
    "    v_data_trim = v_data[:min_len]\n",
    "    v_sim_trim = v_sim[:min_len]\n",
    "    s_data_trim = s_data[:min_len]\n",
    "    s_sim_trim = s_sim[:min_len]\n",
    "    acc_real_trim = acc_real[:min_len]\n",
    "    acc_sim_trim = acc_sim[:min_len]\n",
    "    \n",
    "    # 计算随时间变化的误差（可正可负）\n",
    "    speed_error = v_sim_trim - v_data_trim\n",
    "    spacing_error = s_sim_trim - s_data_trim\n",
    "    acceleration_error = acc_sim_trim - acc_real_trim\n",
    "    \n",
    "    # 计算各种误差指标\n",
    "    nrmse_v = calculate_nrmse(v_data_trim, v_sim_trim)\n",
    "    nrmse_s = calculate_nrmse(s_data_trim, s_sim_trim)\n",
    "    nrmse_acc = calculate_nrmse(acc_real_trim, acc_sim_trim)\n",
    "    \n",
    "    rmse_speed = calculate_rmse(v_data_trim, v_sim_trim)\n",
    "    rmse_spacing = calculate_rmse(s_data_trim, s_sim_trim)\n",
    "    rmse_acceleration = calculate_rmse(acc_real_trim, acc_sim_trim)\n",
    "    \n",
    "    return {\n",
    "        'NRMSE_speed': nrmse_v,\n",
    "        'NRMSE_spacing': nrmse_s,\n",
    "        'NRMSE_acceleration': nrmse_acc,\n",
    "        'RMSE_speed': rmse_speed,\n",
    "        'RMSE_spacing': rmse_spacing,\n",
    "        'RMSE_acceleration': rmse_acceleration,\n",
    "        'Total_NRMSE': nrmse_v + nrmse_s + nrmse_acc,\n",
    "        'Total_RMSE': rmse_speed + rmse_spacing + rmse_acceleration,\n",
    "        'v_sim': v_sim_trim,\n",
    "        's_sim': s_sim_trim,\n",
    "        'acc_sim': acc_sim_trim,\n",
    "        'speed_error': speed_error,\n",
    "        'spacing_error': spacing_error,\n",
    "        'acceleration_error': acceleration_error,\n",
    "        'time_index': np.arange(min_len)\n",
    "    }\n",
    "\n",
    "# 新增函数：绘制预测误差随时间变化图（针对单个驾驶员）\n",
    "def plot_prediction_errors_single(driver_name, vehicle_pair, track_data, errors):\n",
    "    \"\"\"\n",
    "    绘制单个驾驶员的速度、加速度、间距的预测误差随时间变化的图表\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "    fig.suptitle(f'{driver_name} ({vehicle_pair}) - Prediction Errors Over Time', fontsize=14)\n",
    "    \n",
    "    time_idx = errors['time_index']\n",
    "    \n",
    "    # 速度误差\n",
    "    axes[0].plot(time_idx, errors['speed_error'], 'b-', linewidth=1.5, alpha=0.8)\n",
    "    axes[0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_ylabel('Speed Error (m/s)')\n",
    "    axes[0].set_title(f'Speed Prediction Error (Mean: {np.mean(errors[\"speed_error\"]):.3f}, Std: {np.std(errors[\"speed_error\"]):.3f})')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].fill_between(time_idx, errors['speed_error'], 0, alpha=0.3, color='blue')\n",
    "    \n",
    "    # 间距误差\n",
    "    axes[1].plot(time_idx, errors['spacing_error'], 'g-', linewidth=1.5, alpha=0.8)\n",
    "    axes[1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_ylabel('Spacing Error (m)')\n",
    "    axes[1].set_title(f'Spacing Prediction Error (Mean: {np.mean(errors[\"spacing_error\"]):.3f}, Std: {np.std(errors[\"spacing_error\"]):.3f})')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].fill_between(time_idx, errors['spacing_error'], 0, alpha=0.3, color='green')\n",
    "    \n",
    "    # 加速度误差\n",
    "    axes[2].plot(time_idx, errors['acceleration_error'], 'purple', linewidth=1.5, alpha=0.8)\n",
    "    axes[2].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[2].set_ylabel('Acceleration Error (m/s²)')\n",
    "    axes[2].set_xlabel('Time Index')\n",
    "    axes[2].set_title(f'Acceleration Prediction Error (Mean: {np.mean(errors[\"acceleration_error\"]):.3f}, Std: {np.std(errors[\"acceleration_error\"]):.3f})')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].fill_between(time_idx, errors['acceleration_error'], 0, alpha=0.3, color='purple')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 新增函数：绘制所有驾驶员的误差对比图\n",
    "def plot_all_drivers_prediction_errors(individual_results):\n",
    "    \"\"\"\n",
    "    绘制所有驾驶员的速度、加速度、间距预测误差随时间变化的对比图\n",
    "    \"\"\"\n",
    "    n_drivers = len(individual_results)\n",
    "    \n",
    "    # 创建三个子图分别显示速度、间距、加速度误差\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    fig.suptitle('Prediction Errors Over Time - All Drivers Comparison', fontsize=16)\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, n_drivers))\n",
    "    \n",
    "    for idx, (driver_id, result) in enumerate(individual_results.items()):\n",
    "        driver_name = result['driver_name']\n",
    "        errors = result['errors']\n",
    "        time_idx = errors['time_index']\n",
    "        \n",
    "        # 速度误差\n",
    "        axes[0].plot(time_idx, errors['speed_error'], \n",
    "                    color=colors[idx], linewidth=1.5, alpha=0.7, label=driver_name)\n",
    "        \n",
    "        # 间距误差\n",
    "        axes[1].plot(time_idx, errors['spacing_error'], \n",
    "                    color=colors[idx], linewidth=1.5, alpha=0.7, label=driver_name)\n",
    "        \n",
    "        # 加速度误差\n",
    "        axes[2].plot(time_idx, errors['acceleration_error'], \n",
    "                    color=colors[idx], linewidth=1.5, alpha=0.7, label=driver_name)\n",
    "    \n",
    "    # 设置速度误差子图\n",
    "    axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_ylabel('Speed Error (m/s)')\n",
    "    axes[0].set_title('Speed Prediction Errors - All Drivers')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # 设置间距误差子图\n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_ylabel('Spacing Error (m)')\n",
    "    axes[1].set_title('Spacing Prediction Errors - All Drivers')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # 设置加速度误差子图\n",
    "    axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[2].set_ylabel('Acceleration Error (m/s²)')\n",
    "    axes[2].set_xlabel('Time Index')\n",
    "    axes[2].set_title('Acceleration Prediction Errors - All Drivers')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制误差轨迹图 - 修复参数名错误\n",
    "def plot_error_trajectories(individual_results):\n",
    "    \"\"\"\n",
    "    绘制每个驾驶员的误差轨迹图\n",
    "    \"\"\"\n",
    "    n_drivers = len(individual_results)\n",
    "    fig, axes = plt.subplots(n_drivers, 3, figsize=(18, 4*n_drivers))\n",
    "    \n",
    "    if n_drivers == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (driver_id, result) in enumerate(individual_results.items()):  # 修复参数名\n",
    "        driver_name = result['driver_name']\n",
    "        track_data = result['track_data']\n",
    "        errors = result['errors']\n",
    "        \n",
    "        time_idx = np.arange(len(track_data['vFollReal']))\n",
    "        \n",
    "        # 速度轨迹\n",
    "        axes[idx, 0].plot(time_idx, track_data['vFollReal'], 'b-', label='Real Speed', linewidth=2, alpha=0.8)\n",
    "        axes[idx, 0].plot(time_idx[:len(errors['v_sim'])], errors['v_sim'], 'r--', label='Simulated Speed', linewidth=2)\n",
    "        axes[idx, 0].set_ylabel('Speed (m/s)')\n",
    "        axes[idx, 0].set_title(f'{driver_name} - Speed')\n",
    "        axes[idx, 0].legend()\n",
    "        axes[idx, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 间距轨迹\n",
    "        axes[idx, 1].plot(time_idx, track_data['sReal'], 'g-', label='Real Spacing', linewidth=2, alpha=0.8)\n",
    "        axes[idx, 1].plot(time_idx[:len(errors['s_sim'])], errors['s_sim'], 'r--', label='Simulated Spacing', linewidth=2)\n",
    "        axes[idx, 1].set_ylabel('Spacing (m)')\n",
    "        axes[idx, 1].set_title(f'{driver_name} - Spacing')\n",
    "        axes[idx, 1].legend()\n",
    "        axes[idx, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 加速度轨迹\n",
    "        acc_real = calculate_smoothed_acceleration(track_data['vFollReal'], 0.1)\n",
    "        min_len = min(len(acc_real), len(errors['acc_sim']))\n",
    "        axes[idx, 2].plot(time_idx[:min_len], acc_real[:min_len], 'b-', label='Real Acceleration', linewidth=2, alpha=0.8)\n",
    "        axes[idx, 2].plot(time_idx[:min_len], errors['acc_sim'][:min_len], 'r--', label='Simulated Acceleration', linewidth=2)\n",
    "        axes[idx, 2].set_ylabel('Acceleration (m/s²)')\n",
    "        axes[idx, 2].set_title(f'{driver_name} - Acceleration')\n",
    "        axes[idx, 2].legend()\n",
    "        axes[idx, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        if idx == n_drivers - 1:\n",
    "            for ax in axes[idx, :]:\n",
    "                ax.set_xlabel('Time Index')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制参数分布图\n",
    "def plot_parameter_distribution(individual_results):\n",
    "    \"\"\"\n",
    "    绘制所有参数在所有司机之间的分布图\n",
    "    \"\"\"\n",
    "    all_params = []\n",
    "    driver_names = []\n",
    "    \n",
    "    for driver_id, result in individual_results.items():\n",
    "        all_params.append(result['params'])\n",
    "        driver_names.append(result['driver_name'])\n",
    "    \n",
    "    all_params = np.array(all_params)\n",
    "    param_names = ['v0 (m/s)', 'T (s)', 'a (m/s²)', 'b (m/s²)', 's0 (m)']\n",
    "    param_short_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    \n",
    "    fig, axes = plt.subplots(5, 1, figsize=(12, 15))\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    for i, (ax, param_name, short_name, color) in enumerate(zip(axes, param_names, param_short_names, colors)):\n",
    "        param_values = all_params[:, i]\n",
    "        \n",
    "        x_pos = np.arange(len(driver_names))\n",
    "        ax.plot(x_pos, param_values, 'o-', linewidth=2, markersize=8, color=color, alpha=0.8)\n",
    "        \n",
    "        for j, value in enumerate(param_values):\n",
    "            ax.annotate(f'{value:.2f}', \n",
    "                       (x_pos[j], param_values[j]),\n",
    "                       textcoords=\"offset points\",\n",
    "                       xytext=(0, 10),\n",
    "                       ha='center',\n",
    "                       fontsize=9,\n",
    "                       bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.7))\n",
    "        \n",
    "        ax.set_ylabel(param_name)\n",
    "        ax.set_title(f'{param_name} Distribution Across Drivers')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(driver_names, rotation=45)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        mean_val = np.mean(param_values)\n",
    "        std_val = np.std(param_values)\n",
    "        ax.axhline(y=mean_val, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_val:.2f}')\n",
    "        ax.axhline(y=mean_val + std_val, color='orange', linestyle=':', alpha=0.5, label=f'±1 STD')\n",
    "        ax.axhline(y=mean_val - std_val, color='orange', linestyle=':', alpha=0.5)\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 箱线图对比\n",
    "    fig_box, ax_box = plt.subplots(figsize=(10, 6))\n",
    "    box_data = [all_params[:, i] for i in range(len(param_short_names))]\n",
    "    box_plot = ax_box.boxplot(box_data, labels=param_short_names, patch_artist=True)\n",
    "    \n",
    "    for patch, color in zip(box_plot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    ax_box.set_ylabel('Parameter Values')\n",
    "    ax_box.set_title('IDM Parameter Distributions Comparison')\n",
    "    ax_box.grid(True, alpha=0.3)\n",
    "    \n",
    "    for i, data in enumerate(box_data):\n",
    "        x = np.random.normal(i+1, 0.04, size=len(data))\n",
    "        ax_box.scatter(x, data, alpha=0.6, color=colors[i], s=30)\n",
    "    \n",
    "    for i, (data, name) in enumerate(zip(box_data, param_short_names)):\n",
    "        median = np.median(data)\n",
    "        mean = np.mean(data)\n",
    "        ax_box.text(i+1, np.max(data) + 0.1, f'mean: {mean:.2f}', \n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 驾驶员间差异性分析（使用增强校准）\n",
    "def analyze_inter_driver_heterogeneity_enhanced(ar_idm_data):\n",
    "    \"\"\"\n",
    "    分析驾驶员间异质性 - 使用增强校准方法\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"任务1：驾驶员间差异性分析（增强校准）\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\n进行个体IDM校准（使用多起点优化）...\")\n",
    "    individual_results = {}\n",
    "    \n",
    "    for driver_id, track_data in ar_idm_data['tracks'].items():\n",
    "        driver_name = track_data.get('driver_id', f'Driver_{driver_id}')\n",
    "        vehicle_pair = track_data.get('vehicle_pair', 'Unknown')\n",
    "        \n",
    "        print(f\"\\n校准 {driver_name} ({vehicle_pair})...\")\n",
    "        print(f\"数据点数: {len(track_data['vFollReal'])}\")\n",
    "        \n",
    "        # 使用增强的校准方法\n",
    "        individual_params = calibrate_idm_enhanced(track_data)\n",
    "        \n",
    "        if individual_params is not None:\n",
    "            errors = calculate_errors(track_data, individual_params)\n",
    "            individual_results[driver_id] = {\n",
    "                'params': individual_params,\n",
    "                'errors': errors,\n",
    "                'driver_name': driver_name,\n",
    "                'vehicle_pair': vehicle_pair,\n",
    "                'data_points': len(track_data['vFollReal']),\n",
    "                'track_data': track_data\n",
    "            }\n",
    "            print(f\"  {driver_name} 校准成功\")\n",
    "            param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "            params_str = \" | \".join([f\"{name}: {individual_params[i]:.3f}\" for i, name in enumerate(param_names)])\n",
    "            print(f\"  参数: {params_str}\")\n",
    "            print(f\"  Total NRMSE: {errors['Total_NRMSE']:.4f}\")\n",
    "            \n",
    "            # 为每个驾驶员单独绘制预测误差图（新增）\n",
    "            plot_prediction_errors_single(driver_name, vehicle_pair, track_data, errors)\n",
    "            \n",
    "        else:\n",
    "            print(f\"  {driver_name} 校准失败\")\n",
    "    \n",
    "    if not individual_results:\n",
    "        print(\"没有成功的个体校准结果\")\n",
    "        return None\n",
    "    \n",
    "    # 分析与对比\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"驾驶员间差异性分析结果\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return analyze_individual_results_enhanced(individual_results)\n",
    "\n",
    "def analyze_individual_results_enhanced(individual_results):\n",
    "    \"\"\"\n",
    "    分析增强的个体校准结果\n",
    "    \"\"\"\n",
    "    all_params = []\n",
    "    driver_names = []\n",
    "    all_nrmse_errors = []\n",
    "    all_rmse_errors = []\n",
    "    all_rmse_speed = []\n",
    "    all_rmse_spacing = []\n",
    "    all_rmse_acceleration = []\n",
    "    data_points = []\n",
    "    \n",
    "    for driver_id, result in individual_results.items():\n",
    "        all_params.append(result['params'])\n",
    "        driver_names.append(result['driver_name'])\n",
    "        all_nrmse_errors.append(result['errors']['Total_NRMSE'])\n",
    "        all_rmse_errors.append(result['errors']['Total_RMSE'])\n",
    "        all_rmse_speed.append(result['errors']['RMSE_speed'])\n",
    "        all_rmse_spacing.append(result['errors']['RMSE_spacing'])\n",
    "        all_rmse_acceleration.append(result['errors']['RMSE_acceleration'])\n",
    "        data_points.append(result['data_points'])\n",
    "    \n",
    "    all_params = np.array(all_params)\n",
    "    \n",
    "    # 计算统计量\n",
    "    param_means = np.mean(all_params, axis=0)\n",
    "    param_stds = np.std(all_params, axis=0)\n",
    "    param_cvs = param_stds / param_means\n",
    "    param_ranges = np.ptp(all_params, axis=0)\n",
    "    \n",
    "    param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    \n",
    "    print(\"\\n个体参数统计（驾驶员间差异性）:\")\n",
    "    print(f\"{'参数':<8} {'均值':<8} {'标准差':<8} {'变异系数':<10} {'最小值':<8} {'最大值':<8} {'极差':<8}\")\n",
    "    for i, name in enumerate(param_names):\n",
    "        min_val = np.min(all_params[:, i])\n",
    "        max_val = np.max(all_params[:, i])\n",
    "        range_val = param_ranges[i]\n",
    "        print(f\"{name:<8} {param_means[i]:<8.3f} {param_stds[i]:<8.3f} {param_cvs[i]:<10.3f} {min_val:<8.3f} {max_val:<8.3f} {range_val:<8.3f}\")\n",
    "    \n",
    "    print(\"\\n各驾驶员详细参数:\")\n",
    "    print(f\"{'驾驶员':<15} {'v0':<8} {'T':<8} {'a':<8} {'b':<8} {'s0':<8} {'Total_NRMSE':<12} {'Total_RMSE':<12} {'数据点':<8}\")\n",
    "    for driver_id, result in individual_results.items():\n",
    "        params = result['params']\n",
    "        errors = result['errors']\n",
    "        points = result['data_points']\n",
    "        print(f\"{result['driver_name']:<15} {params[0]:<8.3f} {params[1]:<8.3f} {params[2]:<8.3f} {params[3]:<8.3f} {params[4]:<8.3f} {errors['Total_NRMSE']:<12.4f} {errors['Total_RMSE']:<12.4f} {points:<8}\")\n",
    "    \n",
    "    print(f\"\\nRMSE详细统计:\")\n",
    "    print(f\"{'指标':<25} {'均值':<10} {'标准差':<10} {'最小值':<10} {'最大值':<10}\")\n",
    "    print(f\"{'RMSE_speed (m/s)':<25} {np.mean(all_rmse_speed):<10.4f} {np.std(all_rmse_speed):<10.4f} {np.min(all_rmse_speed):<10.4f} {np.max(all_rmse_speed):<10.4f}\")\n",
    "    print(f\"{'RMSE_spacing (m)':<25} {np.mean(all_rmse_spacing):<10.4f} {np.std(all_rmse_spacing):<10.4f} {np.min(all_rmse_spacing):<10.4f} {np.max(all_rmse_spacing):<10.4f}\")\n",
    "    print(f\"{'RMSE_acceleration (m/s²)':<25} {np.mean(all_rmse_acceleration):<10.4f} {np.std(all_rmse_acceleration):<10.4f} {np.min(all_rmse_acceleration):<10.4f} {np.max(all_rmse_acceleration):<10.4f}\")\n",
    "    print(f\"{'Total_RMSE':<25} {np.mean(all_rmse_errors):<10.4f} {np.std(all_rmse_errors):<10.4f} {np.min(all_rmse_errors):<10.4f} {np.max(all_rmse_errors):<10.4f}\")\n",
    "    \n",
    "    # 计算总体统计\n",
    "    avg_cv = np.mean(param_cvs)\n",
    "    max_cv_param = param_names[np.argmax(param_cvs)]\n",
    "    max_cv_value = np.max(param_cvs)\n",
    "    \n",
    "    print(f\"\\n总体统计:\")\n",
    "    print(f\"参数平均变异系数: {avg_cv:.3f}\")\n",
    "    print(f\"变异最大的参数: {max_cv_param} (CV = {max_cv_value:.3f})\")\n",
    "    print(f\"平均NRMSE拟合误差: {np.mean(all_nrmse_errors):.4f} ± {np.std(all_nrmse_errors):.4f}\")\n",
    "    print(f\"平均RMSE拟合误差: {np.mean(all_rmse_errors):.4f} ± {np.std(all_rmse_errors):.4f}\")\n",
    "    print(f\"分析驾驶员数量: {len(driver_names)}\")\n",
    "    \n",
    "    # 可视化结果\n",
    "    print(\"\\n生成可视化图表...\")\n",
    "    \n",
    "    # 1. 误差轨迹图（原有图表）\n",
    "    plot_error_trajectories(individual_results)\n",
    "    \n",
    "    # 2. 参数分布图（原有图表）\n",
    "    plot_parameter_distribution(individual_results)\n",
    "    \n",
    "    # 3. 所有驾驶员的预测误差对比图（新增图表）\n",
    "    plot_all_drivers_prediction_errors(individual_results)\n",
    "    \n",
    "    # 4. 误差对比图（原有图表）\n",
    "    fig_errors, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # NRMSE\n",
    "    bars1 = ax1.bar(driver_names, all_nrmse_errors, alpha=0.7, color='green')\n",
    "    ax1.set_xlabel('Drivers')\n",
    "    ax1.set_ylabel('Total NRMSE')\n",
    "    ax1.set_title('Total NRMSE by Driver')\n",
    "    ax1.set_xticklabels(driver_names, rotation=45)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, error in zip(bars1, all_nrmse_errors):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                f'{error:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # RMSE\n",
    "    bars2 = ax2.bar(driver_names, all_rmse_errors, alpha=0.7, color='red')\n",
    "    ax2.set_xlabel('Drivers')\n",
    "    ax2.set_ylabel('Total RMSE')\n",
    "    ax2.set_title('Total RMSE by Driver')\n",
    "    ax2.set_xticklabels(driver_names, rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, error in zip(bars2, all_rmse_errors):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                f'{error:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'individual_results': individual_results,\n",
    "        'param_means': param_means,\n",
    "        'param_stds': param_stds,\n",
    "        'param_cvs': param_cvs,\n",
    "        'param_ranges': param_ranges,\n",
    "        'driver_names': driver_names,\n",
    "        'all_nrmse_errors': all_nrmse_errors,\n",
    "        'all_rmse_errors': all_rmse_errors,\n",
    "        'all_rmse_speed': all_rmse_speed,\n",
    "        'all_rmse_spacing': all_rmse_spacing,\n",
    "        'all_rmse_acceleration': all_rmse_acceleration\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcae37-081c-4c45-906a-c79debe01787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_analyze_multiple_datasets(datasets_dict, dataset_names=None):\n",
    "    \"\"\"\n",
    "    整合多个数据集进行统一的驾驶员异质性分析\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    datasets_dict : dict\n",
    "        多个数据集的字典，格式: {'dataset1': ar_idm_data1, 'dataset2': ar_idm_data2, ...}\n",
    "    dataset_names : list, optional\n",
    "        数据集的名称列表，如果为None则使用字典的key\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"多数据集整合分析 - 驾驶员异质性\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if dataset_names is None:\n",
    "        dataset_names = list(datasets_dict.keys())\n",
    "    \n",
    "    all_individual_results = {}\n",
    "    dataset_mapping = {}  # 记录每个驾驶员来自哪个数据集\n",
    "    \n",
    "    # 对每个数据集进行个体校准\n",
    "    for dataset_name, dataset in datasets_dict.items():\n",
    "        print(f\"\\n处理数据集: {dataset_name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        individual_results = {}\n",
    "        \n",
    "        for driver_id, track_data in dataset['tracks'].items():\n",
    "            # 创建唯一驾驶员ID（包含数据集信息）\n",
    "            unique_driver_id = f\"{dataset_name}_{driver_id}\"\n",
    "            driver_name = track_data.get('driver_id', f'Driver_{driver_id}')\n",
    "            vehicle_pair = track_data.get('vehicle_pair', 'Unknown')\n",
    "            \n",
    "            print(f\"校准 {driver_name} ({vehicle_pair})...\")\n",
    "            \n",
    "            # 使用增强的校准方法\n",
    "            individual_params = calibrate_idm_enhanced(track_data)\n",
    "            \n",
    "            if individual_params is not None:\n",
    "                errors = calculate_errors(track_data, individual_params)\n",
    "                individual_results[unique_driver_id] = {\n",
    "                    'params': individual_params,\n",
    "                    'errors': errors,\n",
    "                    'driver_name': driver_name,\n",
    "                    'vehicle_pair': vehicle_pair,\n",
    "                    'data_points': len(track_data['vFollReal']),\n",
    "                    'track_data': track_data,\n",
    "                    'dataset': dataset_name\n",
    "                }\n",
    "                dataset_mapping[unique_driver_id] = dataset_name\n",
    "                print(f\"  {driver_name} 校准成功\")\n",
    "            else:\n",
    "                print(f\"  {driver_name} 校准失败\")\n",
    "        \n",
    "        all_individual_results.update(individual_results)\n",
    "        print(f\"数据集 {dataset_name} 完成: {len(individual_results)} 个成功校准\")\n",
    "    \n",
    "    if not all_individual_results:\n",
    "        print(\"没有成功的个体校准结果\")\n",
    "        return None\n",
    "    \n",
    "    # 进行综合分析\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(f\"多数据集综合分析结果\")\n",
    "    print(f\"总驾驶员数量: {len(all_individual_results)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return analyze_combined_results(all_individual_results, dataset_mapping)\n",
    "\n",
    "def analyze_combined_results(all_individual_results, dataset_mapping):\n",
    "    \"\"\"\n",
    "    分析整合后的结果\n",
    "    \"\"\"\n",
    "    all_params = []\n",
    "    driver_names = []\n",
    "    dataset_names = []\n",
    "    all_nrmse_errors = []\n",
    "    all_rmse_errors = []\n",
    "    data_points = []\n",
    "    \n",
    "    for driver_id, result in all_individual_results.items():\n",
    "        all_params.append(result['params'])\n",
    "        driver_names.append(result['driver_name'])\n",
    "        dataset_names.append(result['dataset'])\n",
    "        all_nrmse_errors.append(result['errors']['Total_NRMSE'])\n",
    "        all_rmse_errors.append(result['errors']['Total_RMSE'])\n",
    "        data_points.append(result['data_points'])\n",
    "    \n",
    "    all_params = np.array(all_params)\n",
    "    \n",
    "    # 计算总体统计量\n",
    "    param_means = np.mean(all_params, axis=0)\n",
    "    param_stds = np.std(all_params, axis=0)\n",
    "    param_cvs = param_stds / param_means\n",
    "    param_ranges = np.ptp(all_params, axis=0)\n",
    "    \n",
    "    param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    \n",
    "    print(\"\\n总体参数统计（所有驾驶员）:\")\n",
    "    print(f\"{'参数':<8} {'均值':<8} {'标准差':<8} {'变异系数':<10} {'最小值':<8} {'最大值':<8} {'极差':<8}\")\n",
    "    for i, name in enumerate(param_names):\n",
    "        min_val = np.min(all_params[:, i])\n",
    "        max_val = np.max(all_params[:, i])\n",
    "        range_val = param_ranges[i]\n",
    "        print(f\"{name:<8} {param_means[i]:<8.3f} {param_stds[i]:<8.3f} {param_cvs[i]:<10.3f} {min_val:<8.3f} {max_val:<8.3f} {range_val:<8.3f}\")\n",
    "    \n",
    "    # 按数据集分组统计\n",
    "    unique_datasets = list(set(dataset_names))\n",
    "    print(f\"\\n按数据集统计 (共 {len(unique_datasets)} 个数据集):\")\n",
    "    \n",
    "    dataset_stats = {}\n",
    "    for dataset in unique_datasets:\n",
    "        dataset_indices = [i for i, ds in enumerate(dataset_names) if ds == dataset]\n",
    "        dataset_params = all_params[dataset_indices]\n",
    "        \n",
    "        dataset_stats[dataset] = {\n",
    "            'n_drivers': len(dataset_indices),\n",
    "            'param_means': np.mean(dataset_params, axis=0),\n",
    "            'param_stds': np.std(dataset_params, axis=0),\n",
    "            'param_cvs': np.std(dataset_params, axis=0) / np.mean(dataset_params, axis=0)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n数据集: {dataset} ({len(dataset_indices)} 个驾驶员)\")\n",
    "        for i, name in enumerate(param_names):\n",
    "            mean_val = dataset_stats[dataset]['param_means'][i]\n",
    "            std_val = dataset_stats[dataset]['param_stds'][i]\n",
    "            cv_val = dataset_stats[dataset]['param_cvs'][i]\n",
    "            print(f\"  {name}: {mean_val:.3f} ± {std_val:.3f} (CV: {cv_val:.3f})\")\n",
    "    \n",
    "    # 方差分析 - 计算数据集间的差异性\n",
    "    print(f\"\\n\" + \"=\" * 50)\n",
    "    print(\"方差分析 - 数据集间参数差异检验\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    from scipy import stats\n",
    "    \n",
    "    for i, param_name in enumerate(param_names):\n",
    "        print(f\"\\n参数 {param_name} 的方差分析:\")\n",
    "        \n",
    "        # 准备各组数据\n",
    "        groups = []\n",
    "        for dataset in unique_datasets:\n",
    "            dataset_indices = [j for j, ds in enumerate(dataset_names) if ds == dataset]\n",
    "            group_data = all_params[dataset_indices, i]\n",
    "            groups.append(group_data)\n",
    "        \n",
    "        # 执行单因素方差分析\n",
    "        f_stat, p_value = stats.f_oneway(*groups)\n",
    "        \n",
    "        print(f\"  F统计量: {f_stat:.4f}\")\n",
    "        print(f\"  P值: {p_value:.4f}\")\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            print(f\"  → 数据集间存在显著差异 (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"  → 数据集间无显著差异 (p ≥ 0.05)\")\n",
    "        \n",
    "        # 计算组内和组间变异\n",
    "        overall_mean = np.mean(all_params[:, i])\n",
    "        ss_total = np.sum((all_params[:, i] - overall_mean) ** 2)\n",
    "        \n",
    "        ss_between = 0\n",
    "        for dataset in unique_datasets:\n",
    "            dataset_indices = [j for j, ds in enumerate(dataset_names) if ds == dataset]\n",
    "            group_mean = np.mean(all_params[dataset_indices, i])\n",
    "            ss_between += len(dataset_indices) * (group_mean - overall_mean) ** 2\n",
    "        \n",
    "        ss_within = ss_total - ss_between\n",
    "        \n",
    "        print(f\"  总变异 (SS_total): {ss_total:.4f}\")\n",
    "        print(f\"  组间变异 (SS_between): {ss_between:.4f}\")\n",
    "        print(f\"  组内变异 (SS_within): {ss_within:.4f}\")\n",
    "        print(f\"  组间变异比例: {ss_between/ss_total*100:.2f}%\")\n",
    "    \n",
    "    # 可视化 - 所有参数在同一张图中的箱线图\n",
    "    plot_combined_boxplot(all_params, param_names)\n",
    "    \n",
    "    # 可视化 - 参数分布直方图\n",
    "    plot_parameter_histograms(all_params, param_names, all_individual_results)\n",
    "    \n",
    "    # 可视化 - 所有驾驶员的参数散点图\n",
    "    plot_all_drivers_scatter(all_params, driver_names, param_names)\n",
    "    \n",
    "    return {\n",
    "        'all_individual_results': all_individual_results,\n",
    "        'dataset_mapping': dataset_mapping,\n",
    "        'param_means': param_means,\n",
    "        'param_stds': param_stds,\n",
    "        'param_cvs': param_cvs,\n",
    "        'param_ranges': param_ranges,\n",
    "        'driver_names': driver_names,\n",
    "        'dataset_names': dataset_names,\n",
    "        'all_nrmse_errors': all_nrmse_errors,\n",
    "        'all_rmse_errors': all_rmse_errors,\n",
    "        'dataset_stats': dataset_stats\n",
    "    }\n",
    "\n",
    "def plot_combined_boxplot(all_params, param_names):\n",
    "    \"\"\"\n",
    "    绘制所有参数在同一张图中的箱线图\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # 准备数据\n",
    "    data_to_plot = [all_params[:, i] for i in range(len(param_names))]\n",
    "    \n",
    "    # 创建箱线图\n",
    "    box_plot = plt.boxplot(data_to_plot, patch_artist=True, labels=param_names, \n",
    "                          widths=0.7, showfliers=True)\n",
    "    \n",
    "    # 设置颜色\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    for patch, color in zip(box_plot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    # 添加散点显示所有数据点\n",
    "    for i, param_data in enumerate(data_to_plot):\n",
    "        x_jitter = np.random.normal(i+1, 0.05, size=len(param_data))\n",
    "        plt.scatter(x_jitter, param_data, alpha=0.4, color=colors[i], s=30, zorder=3)\n",
    "    \n",
    "    plt.xlabel('IDM Parameters')\n",
    "    plt.ylabel('Parameter Values')\n",
    "    plt.title(f'Combined IDM Parameter Distributions - All {len(all_params)} Drivers', fontsize=16)\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_parameter_histograms(all_params, param_names, all_individual_results):\n",
    "    \"\"\"\n",
    "    绘制所有参数的直方图分布\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    for i, (param_name, color) in enumerate(zip(param_names, colors)):\n",
    "        if i < len(axes):\n",
    "            param_data = all_params[:, i]\n",
    "            \n",
    "            # 绘制直方图\n",
    "            n, bins, patches = axes[i].hist(param_data, bins=15, alpha=0.7, color=color, \n",
    "                                          density=True, edgecolor='black', linewidth=0.5)\n",
    "            \n",
    "            # 添加核密度估计\n",
    "            from scipy.stats import gaussian_kde\n",
    "            kde = gaussian_kde(param_data)\n",
    "            x_range = np.linspace(np.min(param_data), np.max(param_data), 100)\n",
    "            axes[i].plot(x_range, kde(x_range), 'r-', linewidth=2)\n",
    "            \n",
    "            # 添加均值和标准差线\n",
    "            mean_val = np.mean(param_data)\n",
    "            std_val = np.std(param_data)\n",
    "            axes[i].axvline(mean_val, color='red', linestyle='--', linewidth=2)\n",
    "            axes[i].axvline(mean_val + std_val, color='orange', linestyle=':', alpha=0.7)\n",
    "            axes[i].axvline(mean_val - std_val, color='orange', linestyle=':', alpha=0.7)\n",
    "            \n",
    "            axes[i].set_xlabel(param_name)\n",
    "            axes[i].set_ylabel('Density')\n",
    "            axes[i].set_title(f'{param_name} Distribution\\n(n={len(param_data)})')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            # 在图中添加简要统计信息\n",
    "            axes[i].text(0.05, 0.95, f'Mean: {mean_val:.2f}\\nStd: {std_val:.2f}\\nCV: {std_val/mean_val:.3f}', \n",
    "                        transform=axes[i].transAxes, fontsize=9,\n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                        verticalalignment='top')\n",
    "    \n",
    "    # 第六个子图显示总体信息\n",
    "    axes[5].axis('off')\n",
    "    total_drivers = len(all_params)\n",
    "    unique_datasets = len(set([res['dataset'] for res in all_individual_results.values()]))\n",
    "    \n",
    "    stats_text = f\"Overall Summary:\\n\\n\"\n",
    "    stats_text += f\"Total Drivers: {total_drivers}\\n\"\n",
    "    stats_text += f\"Total Datasets: {unique_datasets}\\n\\n\"\n",
    "    \n",
    "    # 计算平均变异系数\n",
    "    avg_cv = np.mean([np.std(all_params[:, i]) / np.mean(all_params[:, i]) \n",
    "                     for i in range(len(param_names))])\n",
    "    stats_text += f\"Average CV: {avg_cv:.3f}\"\n",
    "    \n",
    "    axes[5].text(0.1, 0.9, stats_text, transform=axes[5].transAxes, \n",
    "                fontfamily='monospace', verticalalignment='top', fontsize=12,\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle('IDM Parameter Histograms - Combined Analysis', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_drivers_scatter(all_params, driver_names, param_names):\n",
    "    \"\"\"\n",
    "    绘制所有驾驶员的参数散点图矩阵\n",
    "    \"\"\"\n",
    "    # 选择几个重要的参数对进行散点图分析\n",
    "    important_pairs = [(0, 1), (0, 2), (1, 2)]  # (v0,T), (v0,a), (T,a)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # 使用颜色区分不同的参数组合\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    \n",
    "    for idx, (i, j) in enumerate(important_pairs):\n",
    "        x_data = all_params[:, i]\n",
    "        y_data = all_params[:, j]\n",
    "        \n",
    "        scatter = axes[idx].scatter(x_data, y_data, alpha=0.6, s=60, \n",
    "                                  c=colors[idx], edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        # 添加椭圆显示分布\n",
    "        cov = np.cov(x_data, y_data)\n",
    "        lambda_, v = np.linalg.eig(cov)\n",
    "        lambda_ = np.sqrt(lambda_)\n",
    "        \n",
    "        ell = Ellipse(xy=(np.mean(x_data), np.mean(y_data)),\n",
    "                     width=lambda_[0]*2, height=lambda_[1]*2,\n",
    "                     angle=np.degrees(np.arctan2(v[1,0], v[0,0])),\n",
    "                     alpha=0.2, color=colors[idx])\n",
    "        axes[idx].add_patch(ell)\n",
    "        \n",
    "        axes[idx].set_xlabel(param_names[i])\n",
    "        axes[idx].set_ylabel(param_names[j])\n",
    "        axes[idx].set_title(f'{param_names[i]} vs {param_names[j]}')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 添加相关系数\n",
    "        corr = np.corrcoef(x_data, y_data)[0,1]\n",
    "        axes[idx].text(0.05, 0.95, f'ρ = {corr:.3f}', transform=axes[idx].transAxes,\n",
    "                      bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # 添加数据点数量\n",
    "        axes[idx].text(0.05, 0.85, f'n = {len(x_data)}', transform=axes[idx].transAxes,\n",
    "                      bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle(f'Parameter Relationships - All {len(all_params)} Drivers', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 使用示例\n",
    "# 假设您有多个数据集\n",
    "datasets = {\n",
    "    'dataset1': ar_idm_data1,\n",
    "    'dataset2': ar_idm_data2, \n",
    "    'dataset3': ar_idm_data3,\n",
    "    'dataset4': ar_idm_data4,\n",
    "    'dataset5': ar_idm_data5,\n",
    "    'dataset6': ar_idm_data6,\n",
    "    'dataset7': ar_idm_data7,\n",
    "    'dataset8': ar_idm_data8,\n",
    "    'dataset9': ar_idm_data9,\n",
    "}\n",
    "\n",
    "# 运行综合分析\n",
    "print(\"开始多数据集综合分析...\")\n",
    "combined_results = combine_and_analyze_multiple_datasets(datasets)\n",
    "\n",
    "if combined_results:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"多数据集分析完成总结\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"✓ 总驾驶员数量: {len(combined_results['all_individual_results'])}\")\n",
    "    print(f\"✓ 数据集数量: {len(combined_results['dataset_stats'])}\")\n",
    "    print(f\"✓ 参数平均变异系数: {np.mean(combined_results['param_cvs']):.3f}\")\n",
    "    \n",
    "    # 评估总体差异性\n",
    "    avg_cv = np.mean(combined_results['param_cvs'])\n",
    "    if avg_cv > 0.25:\n",
    "        diversity_level = \"高度显著\"\n",
    "    elif avg_cv > 0.15:\n",
    "        diversity_level = \"显著\" \n",
    "    elif avg_cv > 0.08:\n",
    "        diversity_level = \"中等\"\n",
    "    else:\n",
    "        diversity_level = \"不显著\"\n",
    "        \n",
    "    print(f\"✓ 总体驾驶员间差异性: {diversity_level} (平均CV: {avg_cv:.3f})\")\n",
    "    print(\"✓ 多数据集综合分析完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360fc42-fbf0-40c3-9e83-a4bec3bbf67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from collections import deque\n",
    "\n",
    "def validate_basic_idm_model_comprehensive_improved(trace, model, train_data, val_data, n_samples=100):\n",
    "    \"\"\"\n",
    "    Comprehensive validation for basic IDM model with improved posterior sampling\n",
    "    \"\"\"\n",
    "    print(\"Starting comprehensive basic IDM model validation...\")\n",
    "    \n",
    "    vt_val = val_data['vt']\n",
    "    s_val = val_data['s']\n",
    "    dv_val = val_data['dv']\n",
    "    label_val = val_data['label_v']\n",
    "    id_idx_val = val_data['id_idx']\n",
    "    N_veh = val_data['n_vehicles']\n",
    "    \n",
    "    dt = 0.5\n",
    "    DELTA = 4\n",
    "    \n",
    "    # Sample from posterior\n",
    "    print(f\"Drawing {n_samples} posterior samples...\")\n",
    "    with model:\n",
    "        posterior_samples = pm.sample_posterior_predictive(\n",
    "            trace, \n",
    "            var_names=['v0', 'T', 'a', 'b', 's0'], \n",
    "            samples=n_samples,\n",
    "            random_seed=42\n",
    "        )\n",
    "    \n",
    "    # Extract parameters\n",
    "    v0_samples = posterior_samples['v0']\n",
    "    T_samples = posterior_samples['T']\n",
    "    a_samples = posterior_samples['a']\n",
    "    b_samples = posterior_samples['b']\n",
    "    s0_samples = posterior_samples['s0']\n",
    "    \n",
    "    # Initialize arrays for predictions\n",
    "    all_samples_speed_predictions = []\n",
    "    all_samples_spacing_predictions = []\n",
    "    all_samples_acceleration_predictions = []\n",
    "    \n",
    "    print(\"Generating predictions for each posterior sample...\")\n",
    "    for sample_idx in range(n_samples):\n",
    "        speed_predictions = np.zeros_like(vt_val)\n",
    "        spacing_predictions = np.zeros_like(s_val)\n",
    "        acceleration_predictions = np.zeros_like(vt_val)\n",
    "        \n",
    "        # Get parameters for this sample\n",
    "        v0 = v0_samples[sample_idx]\n",
    "        T = T_samples[sample_idx]\n",
    "        a = a_samples[sample_idx]\n",
    "        b = b_samples[sample_idx]\n",
    "        s0 = s0_samples[sample_idx]\n",
    "        \n",
    "        for veh_id in range(N_veh):\n",
    "            mask = (id_idx_val == veh_id)\n",
    "            if np.sum(mask) > 0:\n",
    "                vt_veh = vt_val[mask]\n",
    "                s_veh = s_val[mask]\n",
    "                dv_veh = dv_val[mask]\n",
    "                \n",
    "                # Calculate IDM acceleration using the basic model\n",
    "                a_idm = idm_model(s_veh, vt_veh, dv_veh, v0, T, a, b, s0)\n",
    "                \n",
    "                # Predict speed (no AR correction)\n",
    "                speed_pred = vt_veh + a_idm * dt\n",
    "                \n",
    "                # Store predictions\n",
    "                speed_predictions[mask] = speed_pred\n",
    "                spacing_predictions[mask] = s_veh  # Spacing remains the same as input\n",
    "                acceleration_predictions[mask] = a_idm\n",
    "        \n",
    "        all_samples_speed_predictions.append(speed_predictions)\n",
    "        all_samples_spacing_predictions.append(spacing_predictions)\n",
    "        all_samples_acceleration_predictions.append(acceleration_predictions)\n",
    "    \n",
    "    # Calculate real acceleration from validation data\n",
    "    print(\"Calculating real acceleration from validation data...\")\n",
    "    real_acceleration = np.zeros_like(vt_val)\n",
    "    valid_indices = []\n",
    "    \n",
    "    for veh_id in range(N_veh):\n",
    "        mask = (id_idx_val == veh_id)\n",
    "        if np.sum(mask) > 2:\n",
    "            vt_veh = vt_val[mask]\n",
    "            # Use improved acceleration calculation\n",
    "            acc_veh = improved_robust_acceleration(vt_veh, dt=dt)\n",
    "            real_acceleration[mask] = acc_veh\n",
    "            valid_indices.extend(np.where(mask)[0])\n",
    "    \n",
    "    # Convert to arrays\n",
    "    all_samples_speed_predictions = np.array(all_samples_speed_predictions)\n",
    "    all_samples_spacing_predictions = np.array(all_samples_spacing_predictions)\n",
    "    all_samples_acceleration_predictions = np.array(all_samples_acceleration_predictions)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    print(\"Calculating performance metrics...\")\n",
    "    \n",
    "    # Overall metrics\n",
    "    mean_speed_pred = np.mean(all_samples_speed_predictions, axis=0)\n",
    "    mean_acceleration_pred = np.mean(all_samples_acceleration_predictions, axis=0)\n",
    "    \n",
    "    speed_metrics = calculate_metrics(label_val, mean_speed_pred)\n",
    "    acceleration_metrics = calculate_metrics(real_acceleration[valid_indices], \n",
    "                                           mean_acceleration_pred[valid_indices])\n",
    "    spacing_metrics = calculate_metrics(s_val, np.mean(all_samples_spacing_predictions, axis=0))\n",
    "    \n",
    "    # Vehicle-level metrics\n",
    "    vehicle_metrics = {}\n",
    "    unique_vehicles = np.unique(id_idx_val)\n",
    "    \n",
    "    for veh_id in unique_vehicles:\n",
    "        mask = (id_idx_val == veh_id)\n",
    "        if np.sum(mask) > 0:\n",
    "            veh_speed_true = label_val[mask]\n",
    "            veh_speed_pred = mean_speed_pred[mask]\n",
    "            veh_accel_true = real_acceleration[mask]\n",
    "            veh_accel_pred = mean_acceleration_pred[mask]\n",
    "            veh_spacing_true = s_val[mask]\n",
    "            veh_spacing_pred = np.mean(all_samples_spacing_predictions[:, mask], axis=0)\n",
    "            \n",
    "            vehicle_metrics[veh_id] = {\n",
    "                'speed': calculate_metrics(veh_speed_true, veh_speed_pred),\n",
    "                'acceleration': calculate_metrics(veh_accel_true, veh_accel_pred),\n",
    "                'spacing': calculate_metrics(veh_spacing_true, veh_spacing_pred)\n",
    "            }\n",
    "    \n",
    "    # Extract individual parameters for analysis\n",
    "    individual_params = np.column_stack([\n",
    "        v0_samples, T_samples, a_samples, b_samples, s0_samples\n",
    "    ])\n",
    "    \n",
    "    validation_results = {\n",
    "        'all_samples_speed_predictions': all_samples_speed_predictions,\n",
    "        'all_samples_spacing_predictions': all_samples_spacing_predictions,\n",
    "        'all_samples_acceleration_predictions': all_samples_acceleration_predictions,\n",
    "        'real_acceleration': real_acceleration,\n",
    "        'valid_indices': valid_indices,\n",
    "        'n_samples': n_samples,\n",
    "        'speed_metrics': speed_metrics,\n",
    "        'acceleration_metrics': acceleration_metrics,\n",
    "        'spacing_metrics': spacing_metrics,\n",
    "        'vehicle_metrics': vehicle_metrics,\n",
    "        'individual_params': individual_params,\n",
    "        'mean_predictions': {\n",
    "            'speed': mean_speed_pred,\n",
    "            'acceleration': mean_acceleration_pred,\n",
    "            'spacing': np.mean(all_samples_spacing_predictions, axis=0)\n",
    "        },\n",
    "        'parameter_samples': {\n",
    "            'v0': v0_samples,\n",
    "            'T': T_samples,\n",
    "            'a': a_samples,\n",
    "            'b': b_samples,\n",
    "            's0': s0_samples\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"Basic IDM model validation completed!\")\n",
    "    return validation_results\n",
    "\n",
    "def plot_basic_idm_validation_results(val_data, validation_results):\n",
    "    \"\"\"\n",
    "    Plot comprehensive validation results for basic IDM model\n",
    "    \"\"\"\n",
    "    vt_val = val_data['vt']\n",
    "    s_val = val_data['s']\n",
    "    label_val = val_data['label_v']\n",
    "    id_idx_val = val_data['id_idx']\n",
    "    \n",
    "    all_samples_speed = validation_results['all_samples_speed_predictions']\n",
    "    all_samples_spacing = validation_results['all_samples_spacing_predictions']\n",
    "    all_samples_acceleration = validation_results['all_samples_acceleration_predictions']\n",
    "    real_acceleration = validation_results['real_acceleration']\n",
    "    n_samples = validation_results['n_samples']\n",
    "    \n",
    "    unique_vehicles = np.unique(id_idx_val)\n",
    "    n_vehicles = len(unique_vehicles)\n",
    "    \n",
    "    # Create comprehensive subplots for each vehicle\n",
    "    fig, axes = plt.subplots(n_vehicles, 3, figsize=(20, 5*n_vehicles))\n",
    "    if n_vehicles == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, veh_id in enumerate(unique_vehicles):\n",
    "        mask = (id_idx_val == veh_id)\n",
    "        if np.sum(mask) > 0:\n",
    "            # Ensure we don't exceed array bounds\n",
    "            veh_data_points = min(np.sum(mask), len(all_samples_speed[0]))\n",
    "            time_points = np.arange(veh_data_points)\n",
    "            \n",
    "            # ========== Speed Visualization ==========\n",
    "            axes[idx, 0].plot(time_points, label_val[mask][:veh_data_points], 'k-', \n",
    "                             label='True Speed', linewidth=3, alpha=0.9)\n",
    "            \n",
    "            # Extract posterior samples for this vehicle\n",
    "            veh_speed_samples = np.array([sample[mask][:veh_data_points] for sample in all_samples_speed])\n",
    "            \n",
    "            # Calculate confidence intervals\n",
    "            lower_5 = np.percentile(veh_speed_samples, 5, axis=0)\n",
    "            upper_95 = np.percentile(veh_speed_samples, 95, axis=0)\n",
    "            lower_25 = np.percentile(veh_speed_samples, 25, axis=0)\n",
    "            upper_75 = np.percentile(veh_speed_samples, 75, axis=0)\n",
    "            \n",
    "            # Plot confidence intervals\n",
    "            axes[idx, 0].fill_between(time_points, lower_5, upper_95, \n",
    "                                     alpha=0.3, color='red', label='90% CI')\n",
    "            axes[idx, 0].fill_between(time_points, lower_25, upper_75, \n",
    "                                     alpha=0.5, color='red', label='50% CI')\n",
    "            \n",
    "            # Plot mean and median\n",
    "            mean_speed = np.mean(veh_speed_samples, axis=0)\n",
    "            median_speed = np.median(veh_speed_samples, axis=0)\n",
    "            \n",
    "            axes[idx, 0].plot(time_points, mean_speed, 'b-', \n",
    "                             label='Mean Prediction', linewidth=2, alpha=0.8)\n",
    "            axes[idx, 0].plot(time_points, median_speed, 'g--', \n",
    "                             label='Median Prediction', linewidth=2, alpha=0.8)\n",
    "            \n",
    "            # Plot some sample trajectories\n",
    "            sample_indices_to_plot = np.random.choice(len(all_samples_speed), \n",
    "                                                     min(10, len(all_samples_speed)), replace=False)\n",
    "            for sample_idx in sample_indices_to_plot:\n",
    "                axes[idx, 0].plot(time_points, all_samples_speed[sample_idx][mask][:veh_data_points], \n",
    "                                 'r-', alpha=0.2, linewidth=0.8)\n",
    "            \n",
    "            axes[idx, 0].set_title(f'Vehicle {veh_id} - Speed Prediction\\n({n_samples} Posterior Samples)', fontsize=12)\n",
    "            axes[idx, 0].set_xlabel('Time Index')\n",
    "            axes[idx, 0].set_ylabel('Speed (m/s)')\n",
    "            axes[idx, 0].legend(loc='upper right', fontsize=8)\n",
    "            axes[idx, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # ========== Spacing Visualization ==========\n",
    "            axes[idx, 1].plot(time_points, s_val[mask][:veh_data_points], 'k-', \n",
    "                             label='True Spacing', linewidth=3, alpha=0.9)\n",
    "            \n",
    "            veh_spacing_samples = np.array([sample[mask][:veh_data_points] for sample in all_samples_spacing])\n",
    "            \n",
    "            # Calculate spacing confidence intervals\n",
    "            lower_5_s = np.percentile(veh_spacing_samples, 5, axis=0)\n",
    "            upper_95_s = np.percentile(veh_spacing_samples, 95, axis=0)\n",
    "            lower_25_s = np.percentile(veh_spacing_samples, 25, axis=0)\n",
    "            upper_75_s = np.percentile(veh_spacing_samples, 75, axis=0)\n",
    "            \n",
    "            axes[idx, 1].fill_between(time_points, lower_5_s, upper_95_s, \n",
    "                                     alpha=0.3, color='magenta', label='90% CI')\n",
    "            axes[idx, 1].fill_between(time_points, lower_25_s, upper_75_s, \n",
    "                                     alpha=0.5, color='magenta', label='50% CI')\n",
    "            \n",
    "            mean_spacing = np.mean(veh_spacing_samples, axis=0)\n",
    "            median_spacing = np.median(veh_spacing_samples, axis=0)\n",
    "            \n",
    "            axes[idx, 1].plot(time_points, mean_spacing, 'g-', \n",
    "                             label='Mean Prediction', linewidth=2, alpha=0.8)\n",
    "            axes[idx, 1].plot(time_points, median_spacing, 'c--', \n",
    "                             label='Median Prediction', linewidth=2, alpha=0.8)\n",
    "            \n",
    "            # Plot sample trajectories\n",
    "            for sample_idx in sample_indices_to_plot:\n",
    "                axes[idx, 1].plot(time_points, all_samples_spacing[sample_idx][mask][:veh_data_points], \n",
    "                                 'm-', alpha=0.2, linewidth=0.8)\n",
    "            \n",
    "            axes[idx, 1].set_title(f'Vehicle {veh_id} - Spacing Prediction\\n({n_samples} Posterior Samples)', fontsize=12)\n",
    "            axes[idx, 1].set_xlabel('Time Index')\n",
    "            axes[idx, 1].set_ylabel('Spacing (m)')\n",
    "            axes[idx, 1].legend(loc='upper right', fontsize=8)\n",
    "            axes[idx, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # ========== Acceleration Visualization ==========\n",
    "            axes[idx, 2].plot(time_points, real_acceleration[mask][:veh_data_points], 'k-', \n",
    "                             label='True Acceleration', linewidth=3, alpha=0.9)\n",
    "            \n",
    "            veh_accel_samples = np.array([sample[mask][:veh_data_points] for sample in all_samples_acceleration])\n",
    "            \n",
    "            # Calculate acceleration confidence intervals\n",
    "            lower_5_a = np.percentile(veh_accel_samples, 5, axis=0)\n",
    "            upper_95_a = np.percentile(veh_accel_samples, 95, axis=0)\n",
    "            lower_25_a = np.percentile(veh_accel_samples, 25, axis=0)\n",
    "            upper_75_a = np.percentile(veh_accel_samples, 75, axis=0)\n",
    "            \n",
    "            axes[idx, 2].fill_between(time_points, lower_5_a, upper_95_a, \n",
    "                                     alpha=0.3, color='orange', label='90% CI')\n",
    "            axes[idx, 2].fill_between(time_points, lower_25_a, upper_75_a, \n",
    "                                     alpha=0.5, color='orange', label='50% CI')\n",
    "            \n",
    "            mean_acceleration = np.mean(veh_accel_samples, axis=0)\n",
    "            median_acceleration = np.median(veh_accel_samples, axis=0)\n",
    "            \n",
    "            axes[idx, 2].plot(time_points, mean_acceleration, 'c-', \n",
    "                             label='Mean Prediction', linewidth=2, alpha=0.8)\n",
    "            axes[idx, 2].plot(time_points, median_acceleration, 'y--', \n",
    "                             label='Median Prediction', linewidth=2, alpha=0.8)\n",
    "            \n",
    "            # Plot sample trajectories\n",
    "            for sample_idx in sample_indices_to_plot:\n",
    "                axes[idx, 2].plot(time_points, all_samples_acceleration[sample_idx][mask][:veh_data_points], \n",
    "                                 'y-', alpha=0.2, linewidth=0.8)\n",
    "            \n",
    "            axes[idx, 2].set_title(f'Vehicle {veh_id} - Acceleration Prediction\\n({n_samples} Posterior Samples)', fontsize=12)\n",
    "            axes[idx, 2].set_xlabel('Time Index')\n",
    "            axes[idx, 2].set_ylabel('Acceleration (m/s²)')\n",
    "            axes[idx, 2].legend(loc='upper right', fontsize=8)\n",
    "            axes[idx, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Basic IDM Model - Comprehensive Validation Results', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot parameter distributions\n",
    "    plot_basic_idm_parameter_distributions(validation_results)\n",
    "    \n",
    "    # Plot uncertainty analysis\n",
    "    plot_basic_idm_uncertainty_analysis(val_data, validation_results)\n",
    "\n",
    "def plot_basic_idm_parameter_distributions(validation_results):\n",
    "    \"\"\"\n",
    "    Plot posterior parameter distributions for basic IDM model\n",
    "    \"\"\"\n",
    "    individual_params = validation_results['individual_params']\n",
    "    param_samples = validation_results['parameter_samples']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # IDM parameter posterior distributions\n",
    "    param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    param_display_names = ['Desired Speed (v0)', 'Time Headway (T)', \n",
    "                          'Max Acceleration (a)', 'Comfort Decel (b)', \n",
    "                          'Min Spacing (s0)']\n",
    "    \n",
    "    for i in range(5):\n",
    "        row, col = i // 3, i % 3\n",
    "        params = individual_params[:, i]\n",
    "        axes[row, col].hist(params, bins=30, alpha=0.7, color='skyblue', \n",
    "                           edgecolor='black', density=True)\n",
    "        axes[row, col].axvline(np.mean(params), color='red', linestyle='--', \n",
    "                              label=f'Mean: {np.mean(params):.3f}')\n",
    "        axes[row, col].axvline(np.median(params), color='green', linestyle='--', \n",
    "                              label=f'Median: {np.median(params):.3f}')\n",
    "        axes[row, col].set_title(f'Posterior: {param_display_names[i]}', fontsize=12)\n",
    "        axes[row, col].set_xlabel('Parameter Value')\n",
    "        axes[row, col].set_ylabel('Density')\n",
    "        axes[row, col].legend(fontsize=8)\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add parameter correlations plot\n",
    "    if individual_params.shape[0] > 1:\n",
    "        # Show correlation between v0 and T\n",
    "        v0_params = individual_params[:, 0]\n",
    "        T_params = individual_params[:, 1]\n",
    "        \n",
    "        axes[1, 2].scatter(v0_params, T_params, alpha=0.6, color='purple')\n",
    "        axes[1, 2].set_xlabel('Desired Speed (v0)')\n",
    "        axes[1, 2].set_ylabel('Time Headway (T)')\n",
    "        axes[1, 2].set_title('Parameter Correlation: v0 vs T', fontsize=12)\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Calculate and display correlation coefficient\n",
    "        correlation = np.corrcoef(v0_params, T_params)[0, 1]\n",
    "        axes[1, 2].text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "                       transform=axes[1, 2].transAxes, fontsize=10,\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Basic IDM - Posterior Parameter Distributions', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "def plot_basic_idm_uncertainty_analysis(val_data, validation_results):\n",
    "    \"\"\"\n",
    "    Plot uncertainty analysis for basic IDM model\n",
    "    \"\"\"\n",
    "    all_samples_speed = validation_results['all_samples_speed_predictions']\n",
    "    all_samples_spacing = validation_results['all_samples_spacing_predictions']\n",
    "    all_samples_acceleration = validation_results['all_samples_acceleration_predictions']\n",
    "    n_samples = validation_results['n_samples']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Calculate uncertainty statistics for all vehicles\n",
    "    all_uncertainty_speed = []\n",
    "    all_uncertainty_spacing = []\n",
    "    all_uncertainty_acceleration = []\n",
    "    \n",
    "    unique_vehicles = np.unique(val_data['id_idx'])\n",
    "    \n",
    "    for veh_id in unique_vehicles:\n",
    "        mask = (val_data['id_idx'] == veh_id)\n",
    "        if np.sum(mask) > 0:\n",
    "            # Speed uncertainty (90% interval width)\n",
    "            veh_speed_samples = np.array([sample[mask] for sample in all_samples_speed])\n",
    "            speed_intervals = np.percentile(veh_speed_samples, 95, axis=0) - np.percentile(veh_speed_samples, 5, axis=0)\n",
    "            all_uncertainty_speed.extend(speed_intervals)\n",
    "            \n",
    "            # Spacing uncertainty\n",
    "            veh_spacing_samples = np.array([sample[mask] for sample in all_samples_spacing])\n",
    "            spacing_intervals = np.percentile(veh_spacing_samples, 95, axis=0) - np.percentile(veh_spacing_samples, 5, axis=0)\n",
    "            all_uncertainty_spacing.extend(spacing_intervals)\n",
    "            \n",
    "            # Acceleration uncertainty\n",
    "            veh_accel_samples = np.array([sample[mask] for sample in all_samples_acceleration])\n",
    "            accel_intervals = np.percentile(veh_accel_samples, 95, axis=0) - np.percentile(veh_accel_samples, 5, axis=0)\n",
    "            all_uncertainty_acceleration.extend(accel_intervals)\n",
    "    \n",
    "    # Plot uncertainty distributions\n",
    "    uncertainty_data = [\n",
    "        (all_uncertainty_speed, 'Speed Uncertainty (90% CI Width)', 'lightblue', 'm/s'),\n",
    "        (all_uncertainty_spacing, 'Spacing Uncertainty (90% CI Width)', 'lightgreen', 'm'),\n",
    "        (all_uncertainty_acceleration, 'Acceleration Uncertainty (90% CI Width)', 'lightyellow', 'm/s²')\n",
    "    ]\n",
    "    \n",
    "    for i, (data, title, color, unit) in enumerate(uncertainty_data):\n",
    "        if i < 3:\n",
    "            row, col = i // 2, i % 2\n",
    "            axes[row, col].hist(data, bins=30, alpha=0.7, color=color, edgecolor='black')\n",
    "            axes[row, col].axvline(np.mean(data), color='red', linestyle='--', \n",
    "                                 label=f'Mean: {np.mean(data):.3f} {unit}')\n",
    "            axes[row, col].axvline(np.median(data), color='blue', linestyle='--', \n",
    "                                 label=f'Median: {np.median(data):.3f} {unit}')\n",
    "            axes[row, col].set_title(title, fontsize=12)\n",
    "            axes[row, col].set_xlabel(f'Uncertainty ({unit})')\n",
    "            axes[row, col].set_ylabel('Frequency')\n",
    "            axes[row, col].legend(fontsize=8)\n",
    "            axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot uncertainty over time for first vehicle\n",
    "    if len(unique_vehicles) > 0:\n",
    "        first_vehicle_mask = (val_data['id_idx'] == unique_vehicles[0])\n",
    "        veh_speed_samples = np.array([sample[first_vehicle_mask] for sample in all_samples_speed])\n",
    "        \n",
    "        time_points = np.arange(min(100, np.sum(first_vehicle_mask)))\n",
    "        lower_5 = np.percentile(veh_speed_samples[:, :len(time_points)], 5, axis=0)\n",
    "        upper_95 = np.percentile(veh_speed_samples[:, :len(time_points)], 95, axis=0)\n",
    "        mean_speed = np.mean(veh_speed_samples[:, :len(time_points)], axis=0)\n",
    "        \n",
    "        axes[1, 1].fill_between(time_points, lower_5, upper_95, alpha=0.3, color='red', label='90% CI')\n",
    "        axes[1, 1].plot(time_points, mean_speed, 'b-', label='Mean Prediction', linewidth=2)\n",
    "        axes[1, 1].plot(time_points, val_data['label_v'][first_vehicle_mask][:len(time_points)], \n",
    "                       'k-', label='True Speed', linewidth=2, alpha=0.8)\n",
    "        axes[1, 1].set_title(f'Vehicle {unique_vehicles[0]} - Speed Uncertainty Over Time', fontsize=12)\n",
    "        axes[1, 1].set_xlabel('Time Index')\n",
    "        axes[1, 1].set_ylabel('Speed (m/s)')\n",
    "        axes[1, 1].legend(fontsize=8)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Basic IDM - Uncertainty Analysis', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "def print_basic_idm_validation_summary(validation_results):\n",
    "    \"\"\"\n",
    "    Print comprehensive summary of basic IDM validation results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BASIC IDM MODEL VALIDATION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    speed_metrics = validation_results['speed_metrics']\n",
    "    acceleration_metrics = validation_results['acceleration_metrics']\n",
    "    spacing_metrics = validation_results['spacing_metrics']\n",
    "    vehicle_metrics = validation_results['vehicle_metrics']\n",
    "    \n",
    "    print(f\"\\nOVERALL PERFORMANCE METRICS:\")\n",
    "    print(f\"Speed Prediction:\")\n",
    "    print(f\"  - RMSE: {speed_metrics['rmse']:.4f} m/s\")\n",
    "    print(f\"  - MAE: {speed_metrics['mae']:.4f} m/s\")\n",
    "    print(f\"  - NRMSE: {speed_metrics['nrmse']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nAcceleration Prediction:\")\n",
    "    print(f\"  - RMSE: {acceleration_metrics['rmse']:.4f} m/s²\")\n",
    "    print(f\"  - MAE: {acceleration_metrics['mae']:.4f} m/s²\")\n",
    "    print(f\"  - NRMSE: {acceleration_metrics['nrmse']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nSpacing Prediction:\")\n",
    "    print(f\"  - RMSE: {spacing_metrics['rmse']:.4f} m\")\n",
    "    print(f\"  - MAE: {spacing_metrics['mae']:.4f} m\")\n",
    "    print(f\"  - NRMSE: {spacing_metrics['nrmse']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nVEHICLE-LEVEL PERFORMANCE:\")\n",
    "    for veh_id, metrics in vehicle_metrics.items():\n",
    "        print(f\"\\nVehicle {veh_id}:\")\n",
    "        print(f\"  Speed - RMSE: {metrics['speed']['rmse']:.4f} m/s, MAE: {metrics['speed']['mae']:.4f} m/s\")\n",
    "        print(f\"  Acceleration - RMSE: {metrics['acceleration']['rmse']:.4f} m/s², MAE: {metrics['acceleration']['mae']:.4f} m/s²\")\n",
    "        print(f\"  Spacing - RMSE: {metrics['spacing']['rmse']:.4f} m, MAE: {metrics['spacing']['mae']:.4f} m\")\n",
    "    \n",
    "    # Parameter statistics\n",
    "    individual_params = validation_results['individual_params']\n",
    "    param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    param_display_names = ['Desired Speed', 'Time Headway', 'Max Acceleration', \n",
    "                          'Comfort Deceleration', 'Min Spacing']\n",
    "    \n",
    "    print(f\"\\nPARAMETER POSTERIOR STATISTICS:\")\n",
    "    for i, name in enumerate(param_display_names):\n",
    "        params = individual_params[:, i]\n",
    "        print(f\"  {name}: Mean = {np.mean(params):.3f}, Std = {np.std(params):.3f}, \"\n",
    "              f\"95% CI = [{np.percentile(params, 2.5):.3f}, {np.percentile(params, 97.5):.3f}]\")\n",
    "\n",
    "\n",
    "def run_basic_idm_calibration_only(ar_idm_data):\n",
    "    \"\"\"\n",
    "    Run only basic IDM model calibration\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BASIC IDM MODEL CALIBRATION ONLY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Data splitting\n",
    "    print(\"\\nStep 1: Data Splitting\")\n",
    "    train_data, val_data = split_data_for_ar_idm(ar_idm_data, train_ratio=0.7)\n",
    "    \n",
    "    # Model training\n",
    "    print(\"\\nStep 2: Model Training\")\n",
    "    trace, model = train_basic_idm_model(train_data)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BASIC IDM CALIBRATION COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return {\n",
    "        'trace': trace,\n",
    "        'model': model,\n",
    "        'train_data': train_data,\n",
    "        'val_data': val_data\n",
    "    }\n",
    "\n",
    "def run_basic_idm_validation_only(calibration_results, n_posterior_samples=100):\n",
    "    \"\"\"\n",
    "    Run only basic IDM model validation (using calibrated model)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BASIC IDM MODEL VALIDATION ONLY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    trace = calibration_results['trace']\n",
    "    model = calibration_results['model']\n",
    "    train_data = calibration_results['train_data']\n",
    "    val_data = calibration_results['val_data']\n",
    "    \n",
    "    # Model validation\n",
    "    print(\"\\nStep 1: Model Validation with Posterior Sampling\")\n",
    "    validation_results = validate_basic_idm_model_comprehensive_improved(\n",
    "        trace, model, train_data, val_data, n_samples=n_posterior_samples\n",
    "    )\n",
    "    \n",
    "    # Enhanced visualization\n",
    "    print(\"\\nStep 2: Enhanced Results Visualization\")\n",
    "    plot_basic_idm_validation_results(val_data, validation_results)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nStep 3: Performance Summary\")\n",
    "    print_basic_idm_validation_summary(validation_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BASIC IDM VALIDATION COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "# IDM模型定义\n",
    "def idm_model(s, v, dv, v0=30.0, T=1.5, a=1.0, b=2.0, s0=2.0):\n",
    "    \"\"\"\n",
    "    IDM模型计算加速度\n",
    "    \"\"\"\n",
    "    # 计算期望间距\n",
    "    s_star = s0 + max(0, v * T + (v * dv) / (2 * np.sqrt(a * b)))\n",
    "    \n",
    "    # 计算加速度\n",
    "    acceleration = a * (1 - (v / v0)**4 - (s_star / s)**2)\n",
    "    \n",
    "    # 物理约束：限制加速度在合理范围内\n",
    "    acceleration = np.clip(acceleration, -b, a)\n",
    "    \n",
    "    return acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3ff43-561f-42c2-bb4b-3aa18010140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results = run_basic_idm_calibration_only(ar_idm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807607c-a163-4677-bb93-8e0e55aed668",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results = run_basic_idm_validation_only(calibration_results, n_posterior_samples=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
