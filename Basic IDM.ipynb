{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7576152-31b7-4ac4-b045-c1ea73edba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "\n",
    "\n",
    "def idm_model(s, v, dv, v0=30.0, T=1.5, a=1.0, b=2.0, s0=2.0):\n",
    "   \n",
    "    s_star = s0 + max(0, v * T + (v * dv) / (2 * np.sqrt(a * b)))\n",
    "    \n",
    "   \n",
    "    acceleration = a * (1 - (v / v0)**4 - (s_star / s)**2)\n",
    "    \n",
    "  \n",
    "    acceleration = np.clip(acceleration, -b, a)\n",
    "    \n",
    "    return acceleration\n",
    "\n",
    "\n",
    "def calculate_smoothed_acceleration(v_data, dt, window_length=0.5, polyorder=2):\n",
    "   \n",
    "    if len(v_data) < window_length:\n",
    "        acc = np.gradient(v_data, dt)\n",
    "    else:\n",
    "        try:\n",
    "            v_smooth = savgol_filter(v_data, window_length, polyorder)\n",
    "            acc = np.gradient(v_smooth, dt)\n",
    "        except:\n",
    "            acc = np.gradient(v_data, dt)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "def calculate_nrmse(real, pred):\n",
    "    \n",
    "    if len(real) == 0 or len(pred) == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((real - pred) ** 2))\n",
    "    range_val = np.max(real) - np.min(real)\n",
    "    \n",
    "    if range_val < 1e-6:\n",
    "        return rmse / (np.std(real) + 1e-6)\n",
    "    \n",
    "    return rmse / range_val\n",
    "\n",
    "\n",
    "def calculate_rmse(real, pred):\n",
    "   \n",
    "    if len(real) == 0 or len(pred) == 0:\n",
    "        return 1.0\n",
    "    return np.sqrt(np.mean((real - pred) ** 2))\n",
    "\n",
    "\n",
    "def idm_objective_enhanced(params, data):\n",
    "    \n",
    "    v0, T, a, b, s0 = params\n",
    "    \n",
    "\n",
    "    if (v0 < 12 or v0 > 45 or T < 0.2 or T > 5.0 or \n",
    "        a < 0.2 or a > 6.0 or b < 0.2 or b > 6.0 or s0 < 0.5 or s0 > 10.0):\n",
    "        return 1e10\n",
    "\n",
    "    s_data, v_data, dv_data, dt, v_next_data, _ = data\n",
    "    acc_real = np.gradient(v_data, dt)\n",
    "    \n",
    "\n",
    "    v_sim = [v_data[0]]\n",
    "    s_sim = [s_data[0]]\n",
    "    if len(v_data) > 1:\n",
    "        initial_acc = (v_data[1] - v_data[0]) / dt\n",
    "    else:\n",
    "        initial_acc = 0.0\n",
    "    acc_sim = [initial_acc]\n",
    "    \n",
    "    for i in range(len(s_data)-1):\n",
    "        current_acc = idm_model(s_sim[-1], v_sim[-1], dv_data[i], v0, T, a, b, s0)\n",
    "        \n",
    "        v_next = v_sim[-1] + current_acc * dt\n",
    "        s_next = s_sim[-1] + (dv_data[i] - current_acc) * dt\n",
    "\n",
    "        v_next = max(0.1, min(45.0, v_next))\n",
    "        s_next = max(0.5, min(250.0, s_next))\n",
    "        \n",
    "        v_sim.append(v_next)\n",
    "        s_sim.append(s_next)\n",
    "        acc_sim.append(current_acc)\n",
    "    \n",
    "    v_sim = np.array(v_sim)\n",
    "    s_sim = np.array(s_sim)\n",
    "    acc_sim = np.array(acc_sim)\n",
    "    \n",
    "    min_len = min(len(v_data), len(v_sim), len(s_data), len(s_sim), len(acc_real), len(acc_sim))\n",
    "    \n",
    "    if min_len < 10:\n",
    "        return 1e10\n",
    "    \n",
    "    v_data_trim = v_data[:min_len]\n",
    "    v_sim_trim = v_sim[:min_len]\n",
    "    s_data_trim = s_data[:min_len]\n",
    "    s_sim_trim = s_sim[:min_len]\n",
    "    acc_real_trim = acc_real[:min_len]\n",
    "    acc_sim_trim = acc_sim[:min_len]\n",
    "    \n",
    " \n",
    "    nrmse_v = calculate_nrmse(v_data_trim, v_sim_trim)\n",
    "    nrmse_s = calculate_nrmse(s_data_trim, s_sim_trim)\n",
    "    nrmse_acc = calculate_nrmse(acc_real_trim, acc_sim_trim)\n",
    "    \n",
    "  \n",
    "    weights = [1, 1, 1]\n",
    "    total_nrmse = (weights[0] * nrmse_v + \n",
    "                   weights[1] * nrmse_s + \n",
    "                   weights[2] * nrmse_acc)\n",
    "    \n",
    "    return total_nrmse\n",
    "\n",
    "\n",
    "def calibrate_idm_enhanced(track_data, dt=0.5):\n",
    "    \"\"\"\n",
    "    Enhanced IDM parameter calibration using multi-start optimization to increase parameter diversity\n",
    "    \"\"\"\n",
    "    s_data = track_data['sReal']\n",
    "    v_data = track_data['vFollReal']\n",
    "    dv_data = track_data['dvReal']\n",
    "    v_next_data = track_data['vFollReal_next']\n",
    "    \n",
    "\n",
    "    acc_real = None\n",
    "    \n",
    "  \n",
    "    initial_guesses = [\n",
    "        # Aggressive driver - high desired speed, short time headway, large acceleration\n",
    "        [35.0, 0.8, 2.5, 3.0, 1.5],\n",
    "        # Conservative driver - low desired speed, long time headway, small acceleration  \n",
    "        [20.0, 2.5, 0.8, 1.5, 3.0],\n",
    "        # Moderate driver - balanced parameters\n",
    "        [28.0, 1.5, 1.2, 2.5, 2.5],\n",
    "        # Fast reactive type - short headway but medium speed\n",
    "        [30.0, 0.6, 1.8, 3.5, 2.0],\n",
    "        # Safety priority type - long headway, gentle acceleration/deceleration\n",
    "        [25.0, 3.0, 0.6, 1.2, 3.0],\n",
    "        # High-speed aggressive type\n",
    "        [35.0, 1.0, 3.0, 3.0, 1.0],\n",
    "        # Low-speed conservative type\n",
    "        [18.0, 3.5, 0.5, 1.0, 3.0]\n",
    "    ]\n",
    "    \n",
    "\n",
    "    bounds = [\n",
    "        (15.0, 65.0),   # v0 - expanded range\n",
    "        (0.1, 9.0),     # T - expanded range\n",
    "        (0.1, 9.0),     # a - expanded range\n",
    "        (0.1, 9.0),     # b - expanded range\n",
    "        (0.1, 9.0)     # s0 - expanded range\n",
    "    ]\n",
    "    \n",
    "    data = (s_data, v_data, dv_data, dt, v_next_data, acc_real)\n",
    "    \n",
    "    best_result = None\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    \n",
    "    print(f\"  Trying {len(initial_guesses)} different starting points...\")\n",
    "\n",
    "    for i, initial_guess in enumerate(initial_guesses):\n",
    "        try:\n",
    "            result = minimize(\n",
    "                idm_objective_enhanced,\n",
    "                initial_guess,\n",
    "                args=(data,),\n",
    "                bounds=bounds,\n",
    "                method='L-BFGS-B',\n",
    "                options={'maxiter': 800, 'ftol': 1e-6, 'gtol': 1e-6}\n",
    "            )\n",
    "            \n",
    "            if result.fun < best_score:\n",
    "                best_score = result.fun\n",
    "                best_params = result.x\n",
    "                best_result = result\n",
    "                print(f\"    Starting point {i+1}: NRMSE = {result.fun:.4f} - found better solution\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "\n",
    "    if best_params is None:\n",
    "        print(\"  Multi-start optimization failed, using single-start optimization...\")\n",
    "        initial_guess = [25.0, 1.5, 1.0, 2.0, 2.0]\n",
    "        try:\n",
    "            result = minimize(\n",
    "                idm_objective_enhanced,\n",
    "                initial_guess,\n",
    "                args=(data,),\n",
    "                bounds=bounds,\n",
    "                method='L-BFGS-B',\n",
    "                options={'maxiter': 500, 'ftol': 1e-5}\n",
    "            )\n",
    "            if result.fun < 10:\n",
    "                best_params = result.x\n",
    "                best_score = result.fun\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    if best_score < 15.0:  \n",
    "        print(f\"  Final result: NRMSE = {best_score:.4f}\")\n",
    "        return best_params\n",
    "    else:\n",
    "        print(f\"  Poor result: NRMSE = {best_score:.4f}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def calculate_errors(track_data, params, dt=0.5):\n",
    "    \"\"\"\n",
    "    Calculate model error metrics\n",
    "    \"\"\"\n",
    "    s_data = track_data['sReal']\n",
    "    v_data = track_data['vFollReal']\n",
    "    dv_data = track_data['dvReal']\n",
    "    v_next_data = track_data['vFollReal_next']\n",
    "    \n",
    "    v0, T, a, b, s0 = params\n",
    "    \n",
    "\n",
    "    acc_real = np.gradient(v_data, dt)\n",
    "    \n",
    " \n",
    "    v_sim = [v_data[0]]\n",
    "    s_sim = [s_data[0]]\n",
    "    if len(v_data) > 1:\n",
    "        initial_acc = (v_data[1] - v_data[0]) / dt\n",
    "    else:\n",
    "        initial_acc = 0.0\n",
    "    acc_sim = [initial_acc]\n",
    "    \n",
    "    for i in range(len(s_data)-1):\n",
    "        current_acc = idm_model(s_sim[-1], v_sim[-1], dv_data[i], v0, T, a, b, s0)\n",
    "        v_next = v_sim[-1] + current_acc * dt\n",
    "        s_next = s_sim[-1] + (dv_data[i] - current_acc) * dt\n",
    "        \n",
    "        v_next = max(0.1, min(45.0, v_next))\n",
    "        s_next = max(0.5, min(250.0, s_next))\n",
    "        \n",
    "        v_sim.append(v_next)\n",
    "        s_sim.append(s_next)\n",
    "        acc_sim.append(current_acc)\n",
    "    \n",
    "    v_sim = np.array(v_sim)\n",
    "    s_sim = np.array(s_sim)\n",
    "    acc_sim = np.array(acc_sim)\n",
    "    \n",
    "    min_len = min(len(v_data), len(v_sim), len(s_data), len(s_sim), len(acc_real), len(acc_sim))\n",
    "    \n",
    "    v_data_trim = v_data[:min_len]\n",
    "    v_sim_trim = v_sim[:min_len]\n",
    "    s_data_trim = s_data[:min_len]\n",
    "    s_sim_trim = s_sim[:min_len]\n",
    "    acc_real_trim = acc_real[:min_len]\n",
    "    acc_sim_trim = acc_sim[:min_len]\n",
    "    \n",
    "\n",
    "    speed_error = v_sim_trim - v_data_trim\n",
    "    spacing_error = s_sim_trim - s_data_trim\n",
    "    acceleration_error = acc_sim_trim - acc_real_trim\n",
    "    \n",
    "\n",
    "    nrmse_v = calculate_nrmse(v_data_trim, v_sim_trim)\n",
    "    nrmse_s = calculate_nrmse(s_data_trim, s_sim_trim)\n",
    "    nrmse_acc = calculate_nrmse(acc_real_trim, acc_sim_trim)\n",
    "    \n",
    "    rmse_speed = calculate_rmse(v_data_trim, v_sim_trim)\n",
    "    rmse_spacing = calculate_rmse(s_data_trim, s_sim_trim)\n",
    "    rmse_acceleration = calculate_rmse(acc_real_trim, acc_sim_trim)\n",
    "    \n",
    "    return {\n",
    "        'NRMSE_speed': nrmse_v,\n",
    "        'NRMSE_spacing': nrmse_s,\n",
    "        'NRMSE_acceleration': nrmse_acc,\n",
    "        'RMSE_speed': rmse_speed,\n",
    "        'RMSE_spacing': rmse_spacing,\n",
    "        'RMSE_acceleration': rmse_acceleration,\n",
    "        'Total_NRMSE': nrmse_v + nrmse_s + nrmse_acc,\n",
    "        'Total_RMSE': rmse_speed + rmse_spacing + rmse_acceleration,\n",
    "        'v_sim': v_sim_trim,\n",
    "        's_sim': s_sim_trim,\n",
    "        'acc_sim': acc_sim_trim,\n",
    "        'speed_error': speed_error,\n",
    "        'spacing_error': spacing_error,\n",
    "        'acceleration_error': acceleration_error,\n",
    "        'time_index': np.arange(min_len)\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_prediction_errors_single(driver_name, vehicle_pair, track_data, errors):\n",
    "    \"\"\"\n",
    "    Plot speed, acceleration, spacing prediction errors over time for a single driver\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "    fig.suptitle(f'{driver_name} ({vehicle_pair}) - Prediction Errors Over Time', fontsize=14)\n",
    "    \n",
    "    time_idx = errors['time_index']\n",
    "    \n",
    "    # Speed error\n",
    "    axes[0].plot(time_idx, errors['speed_error'], 'b-', linewidth=1.5, alpha=0.8)\n",
    "    axes[0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_ylabel('Speed Error (m/s)')\n",
    "    axes[0].set_title(f'Speed Prediction Error (Mean: {np.mean(errors[\"speed_error\"]):.3f}, Std: {np.std(errors[\"speed_error\"]):.3f})')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].fill_between(time_idx, errors['speed_error'], 0, alpha=0.3, color='blue')\n",
    "    \n",
    "    # Spacing error\n",
    "    axes[1].plot(time_idx, errors['spacing_error'], 'g-', linewidth=1.5, alpha=0.8)\n",
    "    axes[1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_ylabel('Spacing Error (m)')\n",
    "    axes[1].set_title(f'Spacing Prediction Error (Mean: {np.mean(errors[\"spacing_error\"]):.3f}, Std: {np.std(errors[\"spacing_error\"]):.3f})')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].fill_between(time_idx, errors['spacing_error'], 0, alpha=0.3, color='green')\n",
    "    \n",
    "    # Acceleration error\n",
    "    axes[2].plot(time_idx, errors['acceleration_error'], 'purple', linewidth=1.5, alpha=0.8)\n",
    "    axes[2].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[2].set_ylabel('Acceleration Error (m/s²)')\n",
    "    axes[2].set_xlabel('Time Index')\n",
    "    axes[2].set_title(f'Acceleration Prediction Error (Mean: {np.mean(errors[\"acceleration_error\"]):.3f}, Std: {np.std(errors[\"acceleration_error\"]):.3f})')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].fill_between(time_idx, errors['acceleration_error'], 0, alpha=0.3, color='purple')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_all_drivers_prediction_errors(individual_results):\n",
    "    \"\"\"\n",
    "    Plot speed, acceleration, spacing prediction errors over time comparison for all drivers\n",
    "    \"\"\"\n",
    "    n_drivers = len(individual_results)\n",
    "    \n",
    "    # Create three subplots for speed, spacing, acceleration errors\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    fig.suptitle('Prediction Errors Over Time - All Drivers Comparison', fontsize=16)\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, n_drivers))\n",
    "    \n",
    "    for idx, (driver_id, result) in enumerate(individual_results.items()):\n",
    "        driver_name = result['driver_name']\n",
    "        errors = result['errors']\n",
    "        time_idx = errors['time_index']\n",
    "        \n",
    "        # Speed error\n",
    "        axes[0].plot(time_idx, errors['speed_error'], \n",
    "                    color=colors[idx], linewidth=1.5, alpha=0.7, label=driver_name)\n",
    "        \n",
    "        # Spacing error\n",
    "        axes[1].plot(time_idx, errors['spacing_error'], \n",
    "                    color=colors[idx], linewidth=1.5, alpha=0.7, label=driver_name)\n",
    "        \n",
    "        # Acceleration error\n",
    "        axes[2].plot(time_idx, errors['acceleration_error'], \n",
    "                    color=colors[idx], linewidth=1.5, alpha=0.7, label=driver_name)\n",
    "    \n",
    "    # Set speed error subplot\n",
    "    axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_ylabel('Speed Error (m/s)')\n",
    "    axes[0].set_title('Speed Prediction Errors - All Drivers')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Set spacing error subplot\n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_ylabel('Spacing Error (m)')\n",
    "    axes[1].set_title('Spacing Prediction Errors - All Drivers')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Set acceleration error subplot\n",
    "    axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[2].set_ylabel('Acceleration Error (m/s²)')\n",
    "    axes[2].set_xlabel('Time Index')\n",
    "    axes[2].set_title('Acceleration Prediction Errors - All Drivers')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot error trajectories - fix parameter name error\n",
    "def plot_error_trajectories(individual_results):\n",
    "    \"\"\"\n",
    "    Plot error trajectories for each driver\n",
    "    \"\"\"\n",
    "    n_drivers = len(individual_results)\n",
    "    fig, axes = plt.subplots(n_drivers, 3, figsize=(18, 4*n_drivers))\n",
    "    \n",
    "    if n_drivers == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (driver_id, result) in enumerate(individual_results.items()):  # Fix parameter name\n",
    "        driver_name = result['driver_name']\n",
    "        track_data = result['track_data']\n",
    "        errors = result['errors']\n",
    "        \n",
    "        time_idx = np.arange(len(track_data['vFollReal']))\n",
    "        \n",
    "        # Speed trajectory\n",
    "        axes[idx, 0].plot(time_idx, track_data['vFollReal'], 'b-', label='Real Speed', linewidth=2, alpha=0.8)\n",
    "        axes[idx, 0].plot(time_idx[:len(errors['v_sim'])], errors['v_sim'], 'r--', label='Simulated Speed', linewidth=2)\n",
    "        axes[idx, 0].set_ylabel('Speed (m/s)')\n",
    "        axes[idx, 0].set_title(f'{driver_name} - Speed')\n",
    "        axes[idx, 0].legend()\n",
    "        axes[idx, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Spacing trajectory\n",
    "        axes[idx, 1].plot(time_idx, track_data['sReal'], 'g-', label='Real Spacing', linewidth=2, alpha=0.8)\n",
    "        axes[idx, 1].plot(time_idx[:len(errors['s_sim'])], errors['s_sim'], 'r--', label='Simulated Spacing', linewidth=2)\n",
    "        axes[idx, 1].set_ylabel('Spacing (m)')\n",
    "        axes[idx, 1].set_title(f'{driver_name} - Spacing')\n",
    "        axes[idx, 1].legend()\n",
    "        axes[idx, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Acceleration trajectory\n",
    "        acc_real = calculate_smoothed_acceleration(track_data['vFollReal'], 0.1)\n",
    "        min_len = min(len(acc_real), len(errors['acc_sim']))\n",
    "        axes[idx, 2].plot(time_idx[:min_len], acc_real[:min_len], 'b-', label='Real Acceleration', linewidth=2, alpha=0.8)\n",
    "        axes[idx, 2].plot(time_idx[:min_len], errors['acc_sim'][:min_len], 'r--', label='Simulated Acceleration', linewidth=2)\n",
    "        axes[idx, 2].set_ylabel('Acceleration (m/s²)')\n",
    "        axes[idx, 2].set_title(f'{driver_name} - Acceleration')\n",
    "        axes[idx, 2].legend()\n",
    "        axes[idx, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        if idx == n_drivers - 1:\n",
    "            for ax in axes[idx, :]:\n",
    "                ax.set_xlabel('Time Index')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot parameter distribution\n",
    "def plot_parameter_distribution(individual_results):\n",
    "    \"\"\"\n",
    "    Plot distribution of all parameters across all drivers\n",
    "    \"\"\"\n",
    "    all_params = []\n",
    "    driver_names = []\n",
    "    \n",
    "    for driver_id, result in individual_results.items():\n",
    "        all_params.append(result['params'])\n",
    "        driver_names.append(result['driver_name'])\n",
    "    \n",
    "    all_params = np.array(all_params)\n",
    "    param_names = ['v0 (m/s)', 'T (s)', 'a (m/s²)', 'b (m/s²)', 's0 (m)']\n",
    "    param_short_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    \n",
    "    fig, axes = plt.subplots(5, 1, figsize=(12, 15))\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    for i, (ax, param_name, short_name, color) in enumerate(zip(axes, param_names, param_short_names, colors)):\n",
    "        param_values = all_params[:, i]\n",
    "        \n",
    "        x_pos = np.arange(len(driver_names))\n",
    "        ax.plot(x_pos, param_values, 'o-', linewidth=2, markersize=8, color=color, alpha=0.8)\n",
    "        \n",
    "        for j, value in enumerate(param_values):\n",
    "            ax.annotate(f'{value:.2f}', \n",
    "                       (x_pos[j], param_values[j]),\n",
    "                       textcoords=\"offset points\",\n",
    "                       xytext=(0, 10),\n",
    "                       ha='center',\n",
    "                       fontsize=9,\n",
    "                       bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.7))\n",
    "        \n",
    "        ax.set_ylabel(param_name)\n",
    "        ax.set_title(f'{param_name} Distribution Across Drivers')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(driver_names, rotation=45)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        mean_val = np.mean(param_values)\n",
    "        std_val = np.std(param_values)\n",
    "        ax.axhline(y=mean_val, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_val:.2f}')\n",
    "        ax.axhline(y=mean_val + std_val, color='orange', linestyle=':', alpha=0.5, label=f'±1 STD')\n",
    "        ax.axhline(y=mean_val - std_val, color='orange', linestyle=':', alpha=0.5)\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    fig_box, ax_box = plt.subplots(figsize=(10, 6))\n",
    "    box_data = [all_params[:, i] for i in range(len(param_short_names))]\n",
    "    box_plot = ax_box.boxplot(box_data, labels=param_short_names, patch_artist=True)\n",
    "    \n",
    "    for patch, color in zip(box_plot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    ax_box.set_ylabel('Parameter Values')\n",
    "    ax_box.set_title('IDM Parameter Distributions Comparison')\n",
    "    ax_box.grid(True, alpha=0.3)\n",
    "    \n",
    "    for i, data in enumerate(box_data):\n",
    "        x = np.random.normal(i+1, 0.04, size=len(data))\n",
    "        ax_box.scatter(x, data, alpha=0.6, color=colors[i], s=30)\n",
    "    \n",
    "    for i, (data, name) in enumerate(zip(box_data, param_short_names)):\n",
    "        median = np.median(data)\n",
    "        mean = np.mean(data)\n",
    "        ax_box.text(i+1, np.max(data) + 0.1, f'mean: {mean:.2f}', \n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_inter_driver_heterogeneity_enhanced(ar_idm_data):\n",
    "\n",
    "    individual_results = {}\n",
    "    \n",
    "    for driver_id, track_data in ar_idm_data['tracks'].items():\n",
    "        driver_name = track_data.get('driver_id', f'Driver_{driver_id}')\n",
    "        vehicle_pair = track_data.get('vehicle_pair', 'Unknown')\n",
    "        \n",
    "        print(f\"\\nCalibrating {driver_name} ({vehicle_pair})...\")\n",
    "        print(f\"Data points: {len(track_data['vFollReal'])}\")\n",
    "        \n",
    "        # Use enhanced calibration method\n",
    "        individual_params = calibrate_idm_enhanced(track_data)\n",
    "        \n",
    "        if individual_params is not None:\n",
    "            errors = calculate_errors(track_data, individual_params)\n",
    "            individual_results[driver_id] = {\n",
    "                'params': individual_params,\n",
    "                'errors': errors,\n",
    "                'driver_name': driver_name,\n",
    "                'vehicle_pair': vehicle_pair,\n",
    "                'data_points': len(track_data['vFollReal']),\n",
    "                'track_data': track_data\n",
    "            }\n",
    "            print(f\"  {driver_name} calibration successful\")\n",
    "            param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "            params_str = \" | \".join([f\"{name}: {individual_params[i]:.3f}\" for i, name in enumerate(param_names)])\n",
    "            print(f\"  Parameters: {params_str}\")\n",
    "            print(f\"  Total NRMSE: {errors['Total_NRMSE']:.4f}\")\n",
    "            \n",
    "\n",
    "            plot_prediction_errors_single(driver_name, vehicle_pair, track_data, errors)\n",
    "            \n",
    "        else:\n",
    "            print(f\"  {driver_name} calibration failed\")\n",
    "    \n",
    "    if not individual_results:\n",
    "        print(\"No successful individual calibration results\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Inter-Driver Heterogeneity Analysis Results\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return analyze_individual_results_enhanced(individual_results)\n",
    "\n",
    "def analyze_individual_results_enhanced(individual_results):\n",
    "\n",
    "    all_params = []\n",
    "    driver_names = []\n",
    "    all_nrmse_errors = []\n",
    "    all_rmse_errors = []\n",
    "    all_rmse_speed = []\n",
    "    all_rmse_spacing = []\n",
    "    all_rmse_acceleration = []\n",
    "    data_points = []\n",
    "    \n",
    "    for driver_id, result in individual_results.items():\n",
    "        all_params.append(result['params'])\n",
    "        driver_names.append(result['driver_name'])\n",
    "        all_nrmse_errors.append(result['errors']['Total_NRMSE'])\n",
    "        all_rmse_errors.append(result['errors']['Total_RMSE'])\n",
    "        all_rmse_speed.append(result['errors']['RMSE_speed'])\n",
    "        all_rmse_spacing.append(result['errors']['RMSE_spacing'])\n",
    "        all_rmse_acceleration.append(result['errors']['RMSE_acceleration'])\n",
    "        data_points.append(result['data_points'])\n",
    "    \n",
    "    all_params = np.array(all_params)\n",
    "    \n",
    "\n",
    "    param_means = np.mean(all_params, axis=0)\n",
    "    param_stds = np.std(all_params, axis=0)\n",
    "    param_cvs = param_stds / param_means\n",
    "    param_ranges = np.ptp(all_params, axis=0)\n",
    "    \n",
    "    param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    \n",
    "    print(\"\\nIndividual Parameter Statistics (Inter-Driver Heterogeneity):\")\n",
    "    print(f\"{'Parameter':<8} {'Mean':<8} {'Std':<8} {'CV':<10} {'Min':<8} {'Max':<8} {'Range':<8}\")\n",
    "    for i, name in enumerate(param_names):\n",
    "        min_val = np.min(all_params[:, i])\n",
    "        max_val = np.max(all_params[:, i])\n",
    "        range_val = param_ranges[i]\n",
    "        print(f\"{name:<8} {param_means[i]:<8.3f} {param_stds[i]:<8.3f} {param_cvs[i]:<10.3f} {min_val:<8.3f} {max_val:<8.3f} {range_val:<8.3f}\")\n",
    "    \n",
    "    print(\"\\nDetailed Parameters by Driver:\")\n",
    "    print(f\"{'Driver':<15} {'v0':<8} {'T':<8} {'a':<8} {'b':<8} {'s0':<8} {'Total_NRMSE':<12} {'Total_RMSE':<12} {'Data Points':<8}\")\n",
    "    for driver_id, result in individual_results.items():\n",
    "        params = result['params']\n",
    "        errors = result['errors']\n",
    "        points = result['data_points']\n",
    "        print(f\"{result['driver_name']:<15} {params[0]:<8.3f} {params[1]:<8.3f} {params[2]:<8.3f} {params[3]:<8.3f} {params[4]:<8.3f} {errors['Total_NRMSE']:<12.4f} {errors['Total_RMSE']:<12.4f} {points:<8}\")\n",
    "    \n",
    "    print(f\"\\nRMSE Detailed Statistics:\")\n",
    "    print(f\"{'Metric':<25} {'Mean':<10} {'Std':<10} {'Min':<10} {'Max':<10}\")\n",
    "    print(f\"{'RMSE_speed (m/s)':<25} {np.mean(all_rmse_speed):<10.4f} {np.std(all_rmse_speed):<10.4f} {np.min(all_rmse_speed):<10.4f} {np.max(all_rmse_speed):<10.4f}\")\n",
    "    print(f\"{'RMSE_spacing (m)':<25} {np.mean(all_rmse_spacing):<10.4f} {np.std(all_rmse_spacing):<10.4f} {np.min(all_rmse_spacing):<10.4f} {np.max(all_rmse_spacing):<10.4f}\")\n",
    "    print(f\"{'RMSE_acceleration (m/s²)':<25} {np.mean(all_rmse_acceleration):<10.4f} {np.std(all_rmse_acceleration):<10.4f} {np.min(all_rmse_acceleration):<10.4f} {np.max(all_rmse_acceleration):<10.4f}\")\n",
    "    print(f\"{'Total_RMSE':<25} {np.mean(all_rmse_errors):<10.4f} {np.std(all_rmse_errors):<10.4f} {np.min(all_rmse_errors):<10.4f} {np.max(all_rmse_errors):<10.4f}\")\n",
    "    \n",
    "\n",
    "    avg_cv = np.mean(param_cvs)\n",
    "    max_cv_param = param_names[np.argmax(param_cvs)]\n",
    "    max_cv_value = np.max(param_cvs)\n",
    "    \n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"Parameter average coefficient of variation: {avg_cv:.3f}\")\n",
    "    print(f\"Parameter with highest variation: {max_cv_param} (CV = {max_cv_value:.3f})\")\n",
    "    print(f\"Average NRMSE fitting error: {np.mean(all_nrmse_errors):.4f} ± {np.std(all_nrmse_errors):.4f}\")\n",
    "    print(f\"Average RMSE fitting error: {np.mean(all_rmse_errors):.4f} ± {np.std(all_rmse_errors):.4f}\")\n",
    "    print(f\"Number of drivers analyzed: {len(driver_names)}\")\n",
    "      \n",
    "\n",
    "    plot_error_trajectories(individual_results)\n",
    "    \n",
    "\n",
    "    plot_parameter_distribution(individual_results)\n",
    "    \n",
    "\n",
    "    plot_all_drivers_prediction_errors(individual_results)\n",
    "    \n",
    "\n",
    "    fig_errors, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "\n",
    "    bars1 = ax1.bar(driver_names, all_nrmse_errors, alpha=0.7, color='green')\n",
    "    ax1.set_xlabel('Drivers')\n",
    "    ax1.set_ylabel('Total NRMSE')\n",
    "    ax1.set_title('Total NRMSE by Driver')\n",
    "    ax1.set_xticklabels(driver_names, rotation=45)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, error in zip(bars1, all_nrmse_errors):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                f'{error:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # RMSE\n",
    "    bars2 = ax2.bar(driver_names, all_rmse_errors, alpha=0.7, color='red')\n",
    "    ax2.set_xlabel('Drivers')\n",
    "    ax2.set_ylabel('Total RMSE')\n",
    "    ax2.set_title('Total RMSE by Driver')\n",
    "    ax2.set_xticklabels(driver_names, rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, error in zip(bars2, all_rmse_errors):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                f'{error:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360fc42-fbf0-40c3-9e83-a4bec3bbf67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from collections import deque\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    nrmse = rmse / (np.max(y_true) - np.min(y_true))\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'nrmse': nrmse\n",
    "    }\n",
    "\n",
    "def robust_smooth_acceleration(velocity, dt=0.5, window_size=7, poly_order=2):\n",
    "    if len(velocity) < window_size:\n",
    "        acceleration = np.gradient(velocity, dt)\n",
    "        return acceleration\n",
    "    \n",
    "    try:\n",
    "        acceleration = signal.savitzky_golay(velocity, window_length=window_size, \n",
    "                                           polyorder=poly_order, deriv=1, delta=dt)\n",
    "        \n",
    "        if len(acceleration) > 10:\n",
    "            x_fit = np.arange(5) * dt\n",
    "            y_fit = acceleration[5:10]\n",
    "            if len(y_fit) >= 2:\n",
    "                slope, intercept = np.polyfit(x_fit[:len(y_fit)], y_fit, 1)\n",
    "                for i in range(5):\n",
    "                    acceleration[i] = intercept + slope * (i * dt)\n",
    "            \n",
    "            x_fit = np.arange(5) * dt\n",
    "            y_fit = acceleration[-10:-5]\n",
    "            if len(y_fit) >= 2:\n",
    "                slope, intercept = np.polyfit(x_fit[:len(y_fit)], y_fit, 1)\n",
    "                for i in range(5):\n",
    "                    acceleration[-(5-i)] = intercept + slope * ((4-i) * dt)\n",
    "        \n",
    "        return acceleration\n",
    "        \n",
    "    except:\n",
    "        acceleration = np.zeros_like(velocity)\n",
    "        for i in range(1, len(velocity)-1):\n",
    "            acceleration[i] = (velocity[i+1] - velocity[i-1]) / (2 * dt)\n",
    "        \n",
    "        if len(velocity) > 1:\n",
    "            acceleration[0] = (velocity[1] - velocity[0]) / dt\n",
    "            acceleration[-1] = (velocity[-1] - velocity[-2]) / dt\n",
    "        \n",
    "        window = min(5, len(acceleration))\n",
    "        acceleration = np.convolve(acceleration, np.ones(window)/window, mode='same')\n",
    "        \n",
    "        return acceleration\n",
    "\n",
    "def calculate_initial_acceleration(velocity, dt=0.5, method='savitzky_golay'):\n",
    "    if len(velocity) < 3:\n",
    "        return 0.0\n",
    "    \n",
    "    if method == 'savitzky_golay':\n",
    "        acc_all = robust_smooth_acceleration(velocity, dt)\n",
    "        return acc_all[0]\n",
    "    \n",
    "    elif method == 'robust_fit':\n",
    "        n_points = min(5, len(velocity))\n",
    "        t_points = np.arange(n_points) * dt\n",
    "        v_points = velocity[:n_points]\n",
    "        \n",
    "        slope, intercept = np.polyfit(t_points, v_points, 1)\n",
    "        return slope\n",
    "    \n",
    "    elif method == 'physical_constrained':\n",
    "        if len(velocity) >= 4:\n",
    "            weights = np.array([0.1, 0.2, 0.3, 0.4])[:len(velocity)]\n",
    "            weights = weights / np.sum(weights)\n",
    "            \n",
    "            t_points = np.arange(len(velocity)) * dt\n",
    "            A = np.vstack([t_points, np.ones(len(t_points))]).T\n",
    "            W = np.diag(weights)\n",
    "            slope, intercept = np.linalg.lstsq(A.T @ W @ A, A.T @ W @ velocity, rcond=None)[0]\n",
    "            return slope\n",
    "        else:\n",
    "            return (velocity[1] - velocity[0]) / dt\n",
    "    \n",
    "    else:\n",
    "        initial_acc = (velocity[1] - velocity[0]) / dt\n",
    "        return np.clip(initial_acc, -3.0, 3.0)\n",
    "\n",
    "def improved_robust_acceleration(velocity, dt=0.5, window_size=7, poly_order=2):\n",
    "    acceleration = robust_smooth_acceleration(velocity, dt, window_size, poly_order)\n",
    "    acceleration = np.clip(acceleration, -3.0, 3.0)\n",
    "    \n",
    "    if len(acceleration) > 10:\n",
    "        acceleration[:3] = np.mean(acceleration[:5])\n",
    "        acceleration[-3:] = np.mean(acceleration[-5:])\n",
    "    \n",
    "    return acceleration\n",
    "\n",
    "def split_data_for_ar_idm(ar_idm_data, train_ratio=0.7):\n",
    "    vt = ar_idm_data['vt']\n",
    "    s = ar_idm_data['s']\n",
    "    dv = ar_idm_data['dv']\n",
    "    label_v = ar_idm_data['label_v']\n",
    "    id_idx = ar_idm_data['id_idx']\n",
    "    \n",
    "    unique_vehicles = np.unique(id_idx)\n",
    "    \n",
    "    train_data = {\n",
    "        'vt': np.array([]),\n",
    "        's': np.array([]),\n",
    "        'dv': np.array([]),\n",
    "        'label_v': np.array([]),\n",
    "        'id_idx': np.array([], dtype=int),\n",
    "        'n_vehicles': ar_idm_data['n_vehicles'],\n",
    "        'tracks': {}\n",
    "    }\n",
    "    \n",
    "    val_data = {\n",
    "        'vt': np.array([]),\n",
    "        's': np.array([]),\n",
    "        'dv': np.array([]),\n",
    "        'label_v': np.array([]),\n",
    "        'id_idx': np.array([], dtype=int),\n",
    "        'n_vehicles': ar_idm_data['n_vehicles'],\n",
    "        'tracks': {}\n",
    "    }\n",
    "    \n",
    "    for veh_id in unique_vehicles:\n",
    "        mask = (id_idx == veh_id)\n",
    "        n_points = np.sum(mask)\n",
    "        \n",
    "        if n_points < 20:\n",
    "            continue\n",
    "            \n",
    "        split_point = int(n_points * train_ratio)\n",
    "        \n",
    "        train_mask = np.zeros_like(mask, dtype=bool)\n",
    "        train_indices = np.where(mask)[0][:split_point]\n",
    "        train_mask[train_indices] = True\n",
    "        \n",
    "        val_mask = np.zeros_like(mask, dtype=bool)\n",
    "        val_indices = np.where(mask)[0][split_point:]\n",
    "        val_mask[val_indices] = True\n",
    "        \n",
    "        train_data['vt'] = np.concatenate([train_data['vt'], vt[train_mask]])\n",
    "        train_data['s'] = np.concatenate([train_data['s'], s[train_mask]])\n",
    "        train_data['dv'] = np.concatenate([train_data['dv'], dv[train_mask]])\n",
    "        train_data['label_v'] = np.concatenate([train_data['label_v'], label_v[train_mask]])\n",
    "        train_data['id_idx'] = np.concatenate([train_data['id_idx'], np.full(np.sum(train_mask), veh_id)])\n",
    "        \n",
    "        if np.sum(train_mask) > 0:\n",
    "            train_data['tracks'][veh_id] = {\n",
    "                'last_vt': vt[train_mask][-1],\n",
    "                'last_s': s[train_mask][-1],\n",
    "                'last_dv': dv[train_mask][-1] if len(dv[train_mask]) > 0 else 0.0\n",
    "            }\n",
    "        \n",
    "        val_data['vt'] = np.concatenate([val_data['vt'], vt[val_mask]])\n",
    "        val_data['s'] = np.concatenate([val_data['s'], s[val_mask]])\n",
    "        val_data['dv'] = np.concatenate([val_data['dv'], dv[val_mask]])\n",
    "        val_data['label_v'] = np.concatenate([val_data['label_v'], label_v[val_mask]])\n",
    "        val_data['id_idx'] = np.concatenate([val_data['id_idx'], np.full(np.sum(val_mask), veh_id)])\n",
    "    \n",
    "    print(f\"Training set: {len(train_data['vt'])} data points\")\n",
    "    print(f\"Validation set: {len(val_data['vt'])} data points\")\n",
    "    \n",
    "    return train_data, val_data\n",
    "def validate_basic_idm_model_comprehensive_improved(trace, model, train_data, val_data, n_samples=100):\n",
    "\n",
    "    \n",
    "    vt_val = val_data['vt']\n",
    "    s_val = val_data['s']\n",
    "    dv_val = val_data['dv']\n",
    "    label_val = val_data['label_v']\n",
    "    id_idx_val = val_data['id_idx']\n",
    "    N_veh = val_data['n_vehicles']\n",
    "    \n",
    "    dt = 0.5\n",
    "    DELTA = 4\n",
    "    \n",
    " \n",
    "    with model:\n",
    "        posterior_samples = pm.sample_posterior_predictive(\n",
    "            trace, \n",
    "            var_names=['v0', 'T', 'a', 'b', 's0'], \n",
    "            samples=n_samples,\n",
    "            random_seed=42\n",
    "        )\n",
    "    \n",
    "\n",
    "    v0_samples = posterior_samples['v0']\n",
    "    T_samples = posterior_samples['T']\n",
    "    a_samples = posterior_samples['a']\n",
    "    b_samples = posterior_samples['b']\n",
    "    s0_samples = posterior_samples['s0']\n",
    "    \n",
    "\n",
    "    all_samples_speed_predictions = []\n",
    "    all_samples_spacing_predictions = []\n",
    "    all_samples_acceleration_predictions = []\n",
    "    \n",
    "    print(\"Generating predictions for each posterior sample...\")\n",
    "    for sample_idx in range(n_samples):\n",
    "        speed_predictions = np.zeros_like(vt_val)\n",
    "        spacing_predictions = np.zeros_like(s_val)\n",
    "        acceleration_predictions = np.zeros_like(vt_val)\n",
    "        \n",
    "\n",
    "        v0 = v0_samples[sample_idx]\n",
    "        T = T_samples[sample_idx]\n",
    "        a = a_samples[sample_idx]\n",
    "        b = b_samples[sample_idx]\n",
    "        s0 = s0_samples[sample_idx]\n",
    "        \n",
    "        for veh_id in range(N_veh):\n",
    "            mask = (id_idx_val == veh_id)\n",
    "            if np.sum(mask) > 0:\n",
    "                vt_veh = vt_val[mask]\n",
    "                s_veh = s_val[mask]\n",
    "                dv_veh = dv_val[mask]\n",
    "         \n",
    "                a_idm = idm_model(s_veh, vt_veh, dv_veh, v0, T, a, b, s0)\n",
    "                \n",
    "               \n",
    "                speed_pred = vt_veh + a_idm * dt\n",
    "                \n",
    "                \n",
    "                speed_predictions[mask] = speed_pred\n",
    "                spacing_predictions[mask] = s_veh  \n",
    "                acceleration_predictions[mask] = a_idm\n",
    "        \n",
    "        all_samples_speed_predictions.append(speed_predictions)\n",
    "        all_samples_spacing_predictions.append(spacing_predictions)\n",
    "        all_samples_acceleration_predictions.append(acceleration_predictions)\n",
    "    \n",
    "\n",
    "    real_acceleration = np.zeros_like(vt_val)\n",
    "    valid_indices = []\n",
    "    \n",
    "    for veh_id in range(N_veh):\n",
    "        mask = (id_idx_val == veh_id)\n",
    "        if np.sum(mask) > 2:\n",
    "            vt_veh = vt_val[mask]\n",
    "\n",
    "            acc_veh = improved_robust_acceleration(vt_veh, dt=dt)\n",
    "            real_acceleration[mask] = acc_veh\n",
    "            valid_indices.extend(np.where(mask)[0])\n",
    "    \n",
    " \n",
    "    all_samples_speed_predictions = np.array(all_samples_speed_predictions)\n",
    "    all_samples_spacing_predictions = np.array(all_samples_spacing_predictions)\n",
    "    all_samples_acceleration_predictions = np.array(all_samples_acceleration_predictions)\n",
    "    \n",
    "\n",
    "    mean_speed_pred = np.mean(all_samples_speed_predictions, axis=0)\n",
    "    mean_acceleration_pred = np.mean(all_samples_acceleration_predictions, axis=0)\n",
    "    \n",
    "    speed_metrics = calculate_metrics(label_val, mean_speed_pred)\n",
    "    acceleration_metrics = calculate_metrics(real_acceleration[valid_indices], \n",
    "                                           mean_acceleration_pred[valid_indices])\n",
    "    spacing_metrics = calculate_metrics(s_val, np.mean(all_samples_spacing_predictions, axis=0))\n",
    "    \n",
    "    vehicle_metrics = {}\n",
    "    unique_vehicles = np.unique(id_idx_val)\n",
    "    \n",
    "    for veh_id in unique_vehicles:\n",
    "        mask = (id_idx_val == veh_id)\n",
    "        if np.sum(mask) > 0:\n",
    "            veh_speed_true = label_val[mask]\n",
    "            veh_speed_pred = mean_speed_pred[mask]\n",
    "            veh_accel_true = real_acceleration[mask]\n",
    "            veh_accel_pred = mean_acceleration_pred[mask]\n",
    "            veh_spacing_true = s_val[mask]\n",
    "            veh_spacing_pred = np.mean(all_samples_spacing_predictions[:, mask], axis=0)\n",
    "            \n",
    "            vehicle_metrics[veh_id] = {\n",
    "                'speed': calculate_metrics(veh_speed_true, veh_speed_pred),\n",
    "                'acceleration': calculate_metrics(veh_accel_true, veh_accel_pred),\n",
    "                'spacing': calculate_metrics(veh_spacing_true, veh_spacing_pred)\n",
    "            }\n",
    "\n",
    "    individual_params = np.column_stack([\n",
    "        v0_samples, T_samples, a_samples, b_samples, s0_samples\n",
    "    ])\n",
    "    \n",
    "    validation_results = {\n",
    "        'all_samples_speed_predictions': all_samples_speed_predictions,\n",
    "        'all_samples_spacing_predictions': all_samples_spacing_predictions,\n",
    "        'all_samples_acceleration_predictions': all_samples_acceleration_predictions,\n",
    "        'real_acceleration': real_acceleration,\n",
    "        'valid_indices': valid_indices,\n",
    "        'n_samples': n_samples,\n",
    "        'speed_metrics': speed_metrics,\n",
    "        'acceleration_metrics': acceleration_metrics,\n",
    "        'spacing_metrics': spacing_metrics,\n",
    "        'vehicle_metrics': vehicle_metrics,\n",
    "        'individual_params': individual_params,\n",
    "        'mean_predictions': {\n",
    "            'speed': mean_speed_pred,\n",
    "            'acceleration': mean_acceleration_pred,\n",
    "            'spacing': np.mean(all_samples_spacing_predictions, axis=0)\n",
    "        },\n",
    "        'parameter_samples': {\n",
    "            'v0': v0_samples,\n",
    "            'T': T_samples,\n",
    "            'a': a_samples,\n",
    "            'b': b_samples,\n",
    "            's0': s0_samples\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "def plot_basic_idm_validation_results(val_data, validation_results):\n",
    "   \n",
    "    vt_val = val_data['vt']\n",
    "    s_val = val_data['s']\n",
    "    label_val = val_data['label_v']\n",
    "    id_idx_val = val_data['id_idx']\n",
    "    \n",
    "    all_samples_speed = validation_results['all_samples_speed_predictions']\n",
    "    all_samples_spacing = validation_results['all_samples_spacing_predictions']\n",
    "    all_samples_acceleration = validation_results['all_samples_acceleration_predictions']\n",
    "    real_acceleration = validation_results['real_acceleration']\n",
    "    n_samples = validation_results['n_samples']\n",
    "    \n",
    "    unique_vehicles = np.unique(id_idx_val)\n",
    "    n_vehicles = len(unique_vehicles)\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(n_vehicles, 3, figsize=(20, 5*n_vehicles))\n",
    "    if n_vehicles == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, veh_id in enumerate(unique_vehicles):\n",
    "        mask = (id_idx_val == veh_id)\n",
    "        if np.sum(mask) > 0:\n",
    "          \n",
    "            veh_data_points = min(np.sum(mask), len(all_samples_speed[0]))\n",
    "            time_points = np.arange(veh_data_points)\n",
    "            \n",
    "          \n",
    "            axes[idx, 0].plot(time_points, label_val[mask][:veh_data_points], 'k-', \n",
    "                             label='True Speed', linewidth=3, alpha=0.9)\n",
    "            \n",
    "           \n",
    "            veh_speed_samples = np.array([sample[mask][:veh_data_points] for sample in all_samples_speed])\n",
    "            \n",
    "          \n",
    "            lower_5 = np.percentile(veh_speed_samples, 5, axis=0)\n",
    "            upper_95 = np.percentile(veh_speed_samples, 95, axis=0)\n",
    "            lower_25 = np.percentile(veh_speed_samples, 25, axis=0)\n",
    "            upper_75 = np.percentile(veh_speed_samples, 75, axis=0)\n",
    "            \n",
    "         \n",
    "            axes[idx, 0].fill_between(time_points, lower_5, upper_95, \n",
    "                                     alpha=0.3, color='red', label='90% CI')\n",
    "            axes[idx, 0].fill_between(time_points, lower_25, upper_75, \n",
    "                                     alpha=0.5, color='red', label='50% CI')\n",
    "            \n",
    "          \n",
    "            mean_speed = np.mean(veh_speed_samples, axis=0)\n",
    "            median_speed = np.median(veh_speed_samples, axis=0)\n",
    "            \n",
    "            axes[idx, 0].plot(time_points, mean_speed, 'b-', \n",
    "                             label='Mean Prediction', linewidth=2, alpha=0.8)\n",
    "            axes[idx, 0].plot(time_points, median_speed, 'g--', \n",
    "                             label='Median Prediction', linewidth=2, alpha=0.8)\n",
    "            \n",
    "       \n",
    "            sample_indices_to_plot = np.random.choice(len(all_samples_speed), \n",
    "                                                     min(10, len(all_samples_speed)), replace=False)\n",
    "            for sample_idx in sample_indices_to_plot:\n",
    "                axes[idx, 0].plot(time_points, all_samples_speed[sample_idx][mask][:veh_data_points], \n",
    "                                 'r-', alpha=0.2, linewidth=0.8)\n",
    "            \n",
    "            axes[idx, 0].set_title(f'Vehicle {veh_id} - Speed Prediction\\n({n_samples} Posterior Samples)', fontsize=12)\n",
    "            axes[idx, 0].set_xlabel('Time Index')\n",
    "            axes[idx, 0].set_ylabel('Speed (m/s)')\n",
    "            axes[idx, 0].legend(loc='upper right', fontsize=8)\n",
    "            axes[idx, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "           \n",
    "            axes[idx, 1].plot(time_points, s_val[mask][:veh_data_points], 'k-', \n",
    "                             label='True Spacing', linewidth=3, alpha=0.9)\n",
    "            \n",
    "            veh_spacing_samples = np.array([sample[mask][:veh_data_points] for sample in all_samples_spacing])\n",
    "            \n",
    "           \n",
    "            lower_5_s = np.percentile(veh_spacing_samples, 5, axis=0)\n",
    "            upper_95_s = np.percentile(veh_spacing_samples, 95, axis=0)\n",
    "            lower_25_s = np.percentile(veh_spacing_samples, 25, axis=0)\n",
    "            upper_75_s = np.percentile(veh_spacing_samples, 75, axis=0)\n",
    "            \n",
    "            axes[idx, 1].fill_between(time_points, lower_5_s, upper_95_s, \n",
    "                                     alpha=0.3, color='magenta', label='90% CI')\n",
    "            axes[idx, 1].fill_between(time_points, lower_25_s, upper_75_s, \n",
    "                                     alpha=0.5, color='magenta', label='50% CI')\n",
    "            \n",
    "            mean_spacing = np.mean(veh_spacing_samples, axis=0)\n",
    "            median_spacing = np.median(veh_spacing_samples, axis=0)\n",
    "            \n",
    "            axes[idx, 1].plot(time_points, mean_spacing, 'g-', \n",
    "                             label='Mean Prediction', linewidth=2, alpha=0.8)\n",
    "            axes[idx, 1].plot(time_points, median_spacing, 'c--', \n",
    "                             label='Median Prediction', linewidth=2, alpha=0.8)\n",
    "            \n",
    "           \n",
    "            for sample_idx in sample_indices_to_plot:\n",
    "                axes[idx, 1].plot(time_points, all_samples_spacing[sample_idx][mask][:veh_data_points], \n",
    "                                 'm-', alpha=0.2, linewidth=0.8)\n",
    "            \n",
    "            axes[idx, 1].set_title(f'Vehicle {veh_id} - Spacing Prediction\\n({n_samples} Posterior Samples)', fontsize=12)\n",
    "            axes[idx, 1].set_xlabel('Time Index')\n",
    "            axes[idx, 1].set_ylabel('Spacing (m)')\n",
    "            axes[idx, 1].legend(loc='upper right', fontsize=8)\n",
    "            axes[idx, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "           \n",
    "            axes[idx, 2].plot(time_points, real_acceleration[mask][:veh_data_points], 'k-', \n",
    "                             label='True Acceleration', linewidth=3, alpha=0.9)\n",
    "            \n",
    "            veh_accel_samples = np.array([sample[mask][:veh_data_points] for sample in all_samples_acceleration])\n",
    "            \n",
    "            \n",
    "            lower_5_a = np.percentile(veh_accel_samples, 5, axis=0)\n",
    "            upper_95_a = np.percentile(veh_accel_samples, 95, axis=0)\n",
    "            lower_25_a = np.percentile(veh_accel_samples, 25, axis=0)\n",
    "            upper_75_a = np.percentile(veh_accel_samples, 75, axis=0)\n",
    "            \n",
    "            axes[idx, 2].fill_between(time_points, lower_5_a, upper_95_a, \n",
    "                                     alpha=0.3, color='orange', label='90% CI')\n",
    "            axes[idx, 2].fill_between(time_points, lower_25_a, upper_75_a, \n",
    "                                     alpha=0.5, color='orange', label='50% CI')\n",
    "            \n",
    "            mean_acceleration = np.mean(veh_accel_samples, axis=0)\n",
    "            median_acceleration = np.median(veh_accel_samples, axis=0)\n",
    "            \n",
    "            axes[idx, 2].plot(time_points, mean_acceleration, 'c-', \n",
    "                             label='Mean Prediction', linewidth=2, alpha=0.8)\n",
    "            axes[idx, 2].plot(time_points, median_acceleration, 'y--', \n",
    "                             label='Median Prediction', linewidth=2, alpha=0.8)\n",
    "            \n",
    "           \n",
    "            for sample_idx in sample_indices_to_plot:\n",
    "                axes[idx, 2].plot(time_points, all_samples_acceleration[sample_idx][mask][:veh_data_points], \n",
    "                                 'y-', alpha=0.2, linewidth=0.8)\n",
    "            \n",
    "            axes[idx, 2].set_title(f'Vehicle {veh_id} - Acceleration Prediction\\n({n_samples} Posterior Samples)', fontsize=12)\n",
    "            axes[idx, 2].set_xlabel('Time Index')\n",
    "            axes[idx, 2].set_ylabel('Acceleration (m/s²)')\n",
    "            axes[idx, 2].legend(loc='upper right', fontsize=8)\n",
    "            axes[idx, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Basic IDM Model - Comprehensive Validation Results', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    plot_basic_idm_parameter_distributions(validation_results)\n",
    "    \n",
    " \n",
    "    plot_basic_idm_uncertainty_analysis(val_data, validation_results)\n",
    "\n",
    "def plot_basic_idm_parameter_distributions(validation_results):\n",
    "  \n",
    "    individual_params = validation_results['individual_params']\n",
    "    param_samples = validation_results['parameter_samples']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "   \n",
    "    param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    param_display_names = ['Desired Speed (v0)', 'Time Headway (T)', \n",
    "                          'Max Acceleration (a)', 'Comfort Decel (b)', \n",
    "                          'Min Spacing (s0)']\n",
    "    \n",
    "    for i in range(5):\n",
    "        row, col = i // 3, i % 3\n",
    "        params = individual_params[:, i]\n",
    "        axes[row, col].hist(params, bins=30, alpha=0.7, color='skyblue', \n",
    "                           edgecolor='black', density=True)\n",
    "        axes[row, col].axvline(np.mean(params), color='red', linestyle='--', \n",
    "                              label=f'Mean: {np.mean(params):.3f}')\n",
    "        axes[row, col].axvline(np.median(params), color='green', linestyle='--', \n",
    "                              label=f'Median: {np.median(params):.3f}')\n",
    "        axes[row, col].set_title(f'Posterior: {param_display_names[i]}', fontsize=12)\n",
    "        axes[row, col].set_xlabel('Parameter Value')\n",
    "        axes[row, col].set_ylabel('Density')\n",
    "        axes[row, col].legend(fontsize=8)\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "\n",
    "    if individual_params.shape[0] > 1:\n",
    "        \n",
    "        v0_params = individual_params[:, 0]\n",
    "        T_params = individual_params[:, 1]\n",
    "        \n",
    "        axes[1, 2].scatter(v0_params, T_params, alpha=0.6, color='purple')\n",
    "        axes[1, 2].set_xlabel('Desired Speed (v0)')\n",
    "        axes[1, 2].set_ylabel('Time Headway (T)')\n",
    "        axes[1, 2].set_title('Parameter Correlation: v0 vs T', fontsize=12)\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        \n",
    "        correlation = np.corrcoef(v0_params, T_params)[0, 1]\n",
    "        axes[1, 2].text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "                       transform=axes[1, 2].transAxes, fontsize=10,\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Basic IDM - Posterior Parameter Distributions', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "def plot_basic_idm_uncertainty_analysis(val_data, validation_results):\n",
    "   \n",
    "    all_samples_speed = validation_results['all_samples_speed_predictions']\n",
    "    all_samples_spacing = validation_results['all_samples_spacing_predictions']\n",
    "    all_samples_acceleration = validation_results['all_samples_acceleration_predictions']\n",
    "    n_samples = validation_results['n_samples']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    \n",
    "    all_uncertainty_speed = []\n",
    "    all_uncertainty_spacing = []\n",
    "    all_uncertainty_acceleration = []\n",
    "    \n",
    "    unique_vehicles = np.unique(val_data['id_idx'])\n",
    "    \n",
    "    for veh_id in unique_vehicles:\n",
    "        mask = (val_data['id_idx'] == veh_id)\n",
    "        if np.sum(mask) > 0:\n",
    "           \n",
    "            veh_speed_samples = np.array([sample[mask] for sample in all_samples_speed])\n",
    "            speed_intervals = np.percentile(veh_speed_samples, 95, axis=0) - np.percentile(veh_speed_samples, 5, axis=0)\n",
    "            all_uncertainty_speed.extend(speed_intervals)\n",
    "            \n",
    "           \n",
    "            veh_spacing_samples = np.array([sample[mask] for sample in all_samples_spacing])\n",
    "            spacing_intervals = np.percentile(veh_spacing_samples, 95, axis=0) - np.percentile(veh_spacing_samples, 5, axis=0)\n",
    "            all_uncertainty_spacing.extend(spacing_intervals)\n",
    "            \n",
    "            \n",
    "            veh_accel_samples = np.array([sample[mask] for sample in all_samples_acceleration])\n",
    "            accel_intervals = np.percentile(veh_accel_samples, 95, axis=0) - np.percentile(veh_accel_samples, 5, axis=0)\n",
    "            all_uncertainty_acceleration.extend(accel_intervals)\n",
    "    \n",
    "  \n",
    "    uncertainty_data = [\n",
    "        (all_uncertainty_speed, 'Speed Uncertainty (90% CI Width)', 'lightblue', 'm/s'),\n",
    "        (all_uncertainty_spacing, 'Spacing Uncertainty (90% CI Width)', 'lightgreen', 'm'),\n",
    "        (all_uncertainty_acceleration, 'Acceleration Uncertainty (90% CI Width)', 'lightyellow', 'm/s²')\n",
    "    ]\n",
    "    \n",
    "    for i, (data, title, color, unit) in enumerate(uncertainty_data):\n",
    "        if i < 3:\n",
    "            row, col = i // 2, i % 2\n",
    "            axes[row, col].hist(data, bins=30, alpha=0.7, color=color, edgecolor='black')\n",
    "            axes[row, col].axvline(np.mean(data), color='red', linestyle='--', \n",
    "                                 label=f'Mean: {np.mean(data):.3f} {unit}')\n",
    "            axes[row, col].axvline(np.median(data), color='blue', linestyle='--', \n",
    "                                 label=f'Median: {np.median(data):.3f} {unit}')\n",
    "            axes[row, col].set_title(title, fontsize=12)\n",
    "            axes[row, col].set_xlabel(f'Uncertainty ({unit})')\n",
    "            axes[row, col].set_ylabel('Frequency')\n",
    "            axes[row, col].legend(fontsize=8)\n",
    "            axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    \n",
    "    if len(unique_vehicles) > 0:\n",
    "        first_vehicle_mask = (val_data['id_idx'] == unique_vehicles[0])\n",
    "        veh_speed_samples = np.array([sample[first_vehicle_mask] for sample in all_samples_speed])\n",
    "        \n",
    "        time_points = np.arange(min(100, np.sum(first_vehicle_mask)))\n",
    "        lower_5 = np.percentile(veh_speed_samples[:, :len(time_points)], 5, axis=0)\n",
    "        upper_95 = np.percentile(veh_speed_samples[:, :len(time_points)], 95, axis=0)\n",
    "        mean_speed = np.mean(veh_speed_samples[:, :len(time_points)], axis=0)\n",
    "        \n",
    "        axes[1, 1].fill_between(time_points, lower_5, upper_95, alpha=0.3, color='red', label='90% CI')\n",
    "        axes[1, 1].plot(time_points, mean_speed, 'b-', label='Mean Prediction', linewidth=2)\n",
    "        axes[1, 1].plot(time_points, val_data['label_v'][first_vehicle_mask][:len(time_points)], \n",
    "                       'k-', label='True Speed', linewidth=2, alpha=0.8)\n",
    "        axes[1, 1].set_title(f'Vehicle {unique_vehicles[0]} - Speed Uncertainty Over Time', fontsize=12)\n",
    "        axes[1, 1].set_xlabel('Time Index')\n",
    "        axes[1, 1].set_ylabel('Speed (m/s)')\n",
    "        axes[1, 1].legend(fontsize=8)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Basic IDM - Uncertainty Analysis', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "def print_basic_idm_validation_summary(validation_results):\n",
    "   \n",
    "    \n",
    "    speed_metrics = validation_results['speed_metrics']\n",
    "    acceleration_metrics = validation_results['acceleration_metrics']\n",
    "    spacing_metrics = validation_results['spacing_metrics']\n",
    "    vehicle_metrics = validation_results['vehicle_metrics']\n",
    "    \n",
    "    print(f\"\\nOVERALL PERFORMANCE METRICS:\")\n",
    "    print(f\"Speed Prediction:\")\n",
    "    print(f\"  - RMSE: {speed_metrics['rmse']:.4f} m/s\")\n",
    "    print(f\"  - MAE: {speed_metrics['mae']:.4f} m/s\")\n",
    "    print(f\"  - NRMSE: {speed_metrics['nrmse']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nAcceleration Prediction:\")\n",
    "    print(f\"  - RMSE: {acceleration_metrics['rmse']:.4f} m/s²\")\n",
    "    print(f\"  - MAE: {acceleration_metrics['mae']:.4f} m/s²\")\n",
    "    print(f\"  - NRMSE: {acceleration_metrics['nrmse']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nSpacing Prediction:\")\n",
    "    print(f\"  - RMSE: {spacing_metrics['rmse']:.4f} m\")\n",
    "    print(f\"  - MAE: {spacing_metrics['mae']:.4f} m\")\n",
    "    print(f\"  - NRMSE: {spacing_metrics['nrmse']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nVEHICLE-LEVEL PERFORMANCE:\")\n",
    "    for veh_id, metrics in vehicle_metrics.items():\n",
    "        print(f\"\\nVehicle {veh_id}:\")\n",
    "        print(f\"  Speed - RMSE: {metrics['speed']['rmse']:.4f} m/s, MAE: {metrics['speed']['mae']:.4f} m/s\")\n",
    "        print(f\"  Acceleration - RMSE: {metrics['acceleration']['rmse']:.4f} m/s², MAE: {metrics['acceleration']['mae']:.4f} m/s²\")\n",
    "        print(f\"  Spacing - RMSE: {metrics['spacing']['rmse']:.4f} m, MAE: {metrics['spacing']['mae']:.4f} m\")\n",
    "    \n",
    "    # Parameter statistics\n",
    "    individual_params = validation_results['individual_params']\n",
    "    param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    param_display_names = ['Desired Speed', 'Time Headway', 'Max Acceleration', \n",
    "                          'Comfort Deceleration', 'Min Spacing']\n",
    "    \n",
    "    print(f\"\\nPARAMETER POSTERIOR STATISTICS:\")\n",
    "    for i, name in enumerate(param_display_names):\n",
    "        params = individual_params[:, i]\n",
    "        print(f\"  {name}: Mean = {np.mean(params):.3f}, Std = {np.std(params):.3f}, \"\n",
    "              f\"95% CI = [{np.percentile(params, 2.5):.3f}, {np.percentile(params, 97.5):.3f}]\")\n",
    "\n",
    "\n",
    "def run_basic_idm_calibration_only(ar_idm_data):\n",
    "    \n",
    "\n",
    "    train_data, val_data = split_data_for_ar_idm(ar_idm_data, train_ratio=0.7)\n",
    "    \n",
    "\n",
    "    trace, model = train_basic_idm_model(train_data)\n",
    "    \n",
    "\n",
    "    return {\n",
    "        'trace': trace,\n",
    "        'model': model,\n",
    "        'train_data': train_data,\n",
    "        'val_data': val_data\n",
    "    }\n",
    "\n",
    "def run_basic_idm_validation_only(calibration_results, n_posterior_samples=100):\n",
    "   \n",
    "    trace = calibration_results['trace']\n",
    "    model = calibration_results['model']\n",
    "    train_data = calibration_results['train_data']\n",
    "    val_data = calibration_results['val_data']\n",
    "    \n",
    "\n",
    "    validation_results = validate_basic_idm_model_comprehensive_improved(\n",
    "        trace, model, train_data, val_data, n_samples=n_posterior_samples\n",
    "    )\n",
    "    \n",
    "\n",
    "    plot_basic_idm_validation_results(val_data, validation_results)\n",
    "    \n",
    "\n",
    "    print_basic_idm_validation_summary(validation_results)\n",
    "    \n",
    "\n",
    "    return validation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3ff43-561f-42c2-bb4b-3aa18010140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results = run_basic_idm_calibration_only(ar_idm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807607c-a163-4677-bb93-8e0e55aed668",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results = run_basic_idm_validation_only(calibration_results, n_posterior_samples=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
