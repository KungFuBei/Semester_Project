{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7576152-31b7-4ac4-b045-c1ea73edba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def idm_model(s, v, dv, v0=30.0, T=1.5, a=1.0, b=2.0, s0=2.0):\n",
    "    s_star = s0 + max(0, v * T + (v * dv) / (2 * np.sqrt(a * b)))\n",
    "    acceleration = a * (1 - (v / v0)**4 - (s_star / s)**2)\n",
    "    acceleration = np.clip(acceleration, -b, a)\n",
    "    return acceleration\n",
    "\n",
    "def calculate_smoothed_acceleration(v_data, dt, window_length=0.5, polyorder=2):\n",
    "    if len(v_data) < window_length:\n",
    "        acc = np.gradient(v_data, dt)\n",
    "    else:\n",
    "        try:\n",
    "            v_smooth = savgol_filter(v_data, window_length, polyorder)\n",
    "            acc = np.gradient(v_smooth, dt)\n",
    "        except:\n",
    "            acc = np.gradient(v_data, dt)\n",
    "    return acc\n",
    "\n",
    "def calculate_nrmse(real, pred):\n",
    "    if len(real) == 0 or len(pred) == 0:\n",
    "        return 1.0\n",
    "    rmse = np.sqrt(np.mean((real - pred) ** 2))\n",
    "    range_val = np.max(real) - np.min(real)\n",
    "    if range_val < 1e-6:\n",
    "        return rmse / (np.std(real) + 1e-6)\n",
    "    return rmse / range_val\n",
    "\n",
    "def calculate_rmse(real, pred):\n",
    "    if len(real) == 0 or len(pred) == 0:\n",
    "        return 1.0\n",
    "    return np.sqrt(np.mean((real - pred) ** 2))\n",
    "\n",
    "def idm_objective_enhanced(params, data):\n",
    "    v0, T, a, b, s0 = params\n",
    "    \n",
    "    if (v0 < 12 or v0 > 45 or T < 0.2 or T > 5.0 or \n",
    "        a < 0.2 or a > 6.0 or b < 0.2 or b > 6.0 or s0 < 0.5 or s0 > 10.0):\n",
    "        return 1e10\n",
    "\n",
    "    s_data, v_data, dv_data, dt, v_next_data, _ = data\n",
    "    acc_real = np.gradient(v_data, dt)\n",
    "    \n",
    "    v_sim = [v_data[0]]\n",
    "    s_sim = [s_data[0]]\n",
    "    if len(v_data) > 1:\n",
    "        initial_acc = (v_data[1] - v_data[0]) / dt\n",
    "    else:\n",
    "        initial_acc = 0.0\n",
    "    acc_sim = [initial_acc]\n",
    "    \n",
    "    for i in range(len(s_data)-1):\n",
    "        current_acc = idm_model(s_sim[-1], v_sim[-1], dv_data[i], v0, T, a, b, s0)\n",
    "        v_next = v_sim[-1] + current_acc * dt\n",
    "        s_next = s_sim[-1] + (dv_data[i] - current_acc) * dt\n",
    "        \n",
    "        v_next = max(0.1, min(45.0, v_next))\n",
    "        s_next = max(0.5, min(250.0, s_next))\n",
    "        \n",
    "        v_sim.append(v_next)\n",
    "        s_sim.append(s_next)\n",
    "        acc_sim.append(current_acc)\n",
    "    \n",
    "    v_sim = np.array(v_sim)\n",
    "    s_sim = np.array(s_sim)\n",
    "    acc_sim = np.array(acc_sim)\n",
    "    \n",
    "    min_len = min(len(v_data), len(v_sim), len(s_data), len(s_sim), len(acc_real), len(acc_sim))\n",
    "    \n",
    "    if min_len < 10:\n",
    "        return 1e10\n",
    "    \n",
    "    v_data_trim = v_data[:min_len]\n",
    "    v_sim_trim = v_sim[:min_len]\n",
    "    s_data_trim = s_data[:min_len]\n",
    "    s_sim_trim = s_sim[:min_len]\n",
    "    acc_real_trim = acc_real[:min_len]\n",
    "    acc_sim_trim = acc_sim[:min_len]\n",
    "    \n",
    "    nrmse_v = calculate_nrmse(v_data_trim, v_sim_trim)\n",
    "    nrmse_s = calculate_nrmse(s_data_trim, s_sim_trim)\n",
    "    nrmse_acc = calculate_nrmse(acc_real_trim, acc_sim_trim)\n",
    "    \n",
    "    weights = [1, 1, 1]\n",
    "    total_nrmse = (weights[0] * nrmse_v + \n",
    "                   weights[1] * nrmse_s + \n",
    "                   weights[2] * nrmse_acc)\n",
    "    \n",
    "    return total_nrmse\n",
    "\n",
    "def calibrate_idm_enhanced(track_data, dt=0.5):\n",
    "    s_data = track_data['sReal']\n",
    "    v_data = track_data['vFollReal']\n",
    "    dv_data = track_data['dvReal']\n",
    "    v_next_data = track_data['vFollReal_next']\n",
    "    \n",
    "    acc_real = None\n",
    "    \n",
    "    initial_guesses = [\n",
    "        [35.0, 0.8, 2.5, 3.0, 1.5],\n",
    "        [20.0, 2.5, 0.8, 1.5, 3.0],\n",
    "        [28.0, 1.5, 1.2, 2.5, 2.5],\n",
    "        [30.0, 0.6, 1.8, 3.5, 2.0],\n",
    "        [25.0, 3.0, 0.6, 1.2, 3.0],\n",
    "        [35.0, 1.0, 3.0, 3.0, 1.0],\n",
    "        [18.0, 3.5, 0.5, 1.0, 3.0]\n",
    "    ]\n",
    "    \n",
    "    bounds = [\n",
    "        (15.0, 65.0),\n",
    "        (0.1, 9.0),\n",
    "        (0.1, 9.0),\n",
    "        (0.1, 9.0),\n",
    "        (0.1, 9.0)\n",
    "    ]\n",
    "    \n",
    "    data = (s_data, v_data, dv_data, dt, v_next_data, acc_real)\n",
    "    \n",
    "    best_result = None\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    \n",
    "    for i, initial_guess in enumerate(initial_guesses):\n",
    "        try:\n",
    "            result = minimize(\n",
    "                idm_objective_enhanced,\n",
    "                initial_guess,\n",
    "                args=(data,),\n",
    "                bounds=bounds,\n",
    "                method='L-BFGS-B',\n",
    "                options={'maxiter': 800, 'ftol': 1e-6, 'gtol': 1e-6}\n",
    "            )\n",
    "            \n",
    "            if result.fun < best_score:\n",
    "                best_score = result.fun\n",
    "                best_params = result.x\n",
    "                best_result = result\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if best_params is None:\n",
    "        initial_guess = [25.0, 1.5, 1.0, 2.0, 2.0]\n",
    "        try:\n",
    "            result = minimize(\n",
    "                idm_objective_enhanced,\n",
    "                initial_guess,\n",
    "                args=(data,),\n",
    "                bounds=bounds,\n",
    "                method='L-BFGS-B',\n",
    "                options={'maxiter': 500, 'ftol': 1e-5}\n",
    "            )\n",
    "            if result.fun < 10:\n",
    "                best_params = result.x\n",
    "                best_score = result.fun\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    if best_score < 15.0:\n",
    "        return best_params\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculate_errors(track_data, params, dt=0.5):\n",
    "    s_data = track_data['sReal']\n",
    "    v_data = track_data['vFollReal']\n",
    "    dv_data = track_data['dvReal']\n",
    "    v_next_data = track_data['vFollReal_next']\n",
    "    \n",
    "    v0, T, a, b, s0 = params\n",
    "    acc_real = np.gradient(v_data, dt)\n",
    "    \n",
    "    v_sim = [v_data[0]]\n",
    "    s_sim = [s_data[0]]\n",
    "    if len(v_data) > 1:\n",
    "        initial_acc = (v_data[1] - v_data[0]) / dt\n",
    "    else:\n",
    "        initial_acc = 0.0\n",
    "    acc_sim = [initial_acc]\n",
    "    \n",
    "    for i in range(len(s_data)-1):\n",
    "        current_acc = idm_model(s_sim[-1], v_sim[-1], dv_data[i], v0, T, a, b, s0)\n",
    "        v_next = v_sim[-1] + current_acc * dt\n",
    "        s_next = s_sim[-1] + (dv_data[i] - current_acc) * dt\n",
    "        \n",
    "        v_next = max(0.1, min(45.0, v_next))\n",
    "        s_next = max(0.5, min(250.0, s_next))\n",
    "        \n",
    "        v_sim.append(v_next)\n",
    "        s_sim.append(s_next)\n",
    "        acc_sim.append(current_acc)\n",
    "    \n",
    "    v_sim = np.array(v_sim)\n",
    "    s_sim = np.array(s_sim)\n",
    "    acc_sim = np.array(acc_sim)\n",
    "    \n",
    "    min_len = min(len(v_data), len(v_sim), len(s_data), len(s_sim), len(acc_real), len(acc_sim))\n",
    "    \n",
    "    v_data_trim = v_data[:min_len]\n",
    "    v_sim_trim = v_sim[:min_len]\n",
    "    s_data_trim = s_data[:min_len]\n",
    "    s_sim_trim = s_sim[:min_len]\n",
    "    acc_real_trim = acc_real[:min_len]\n",
    "    acc_sim_trim = acc_sim[:min_len]\n",
    "    \n",
    "    speed_error = v_sim_trim - v_data_trim\n",
    "    spacing_error = s_sim_trim - s_data_trim\n",
    "    acceleration_error = acc_sim_trim - acc_real_trim\n",
    "    \n",
    "    nrmse_v = calculate_nrmse(v_data_trim, v_sim_trim)\n",
    "    nrmse_s = calculate_nrmse(s_data_trim, s_sim_trim)\n",
    "    nrmse_acc = calculate_nrmse(acc_real_trim, acc_sim_trim)\n",
    "    \n",
    "    rmse_speed = calculate_rmse(v_data_trim, v_sim_trim)\n",
    "    rmse_spacing = calculate_rmse(s_data_trim, s_sim_trim)\n",
    "    rmse_acceleration = calculate_rmse(acc_real_trim, acc_sim_trim)\n",
    "    \n",
    "    return {\n",
    "        'NRMSE_speed': nrmse_v,\n",
    "        'NRMSE_spacing': nrmse_s,\n",
    "        'NRMSE_acceleration': nrmse_acc,\n",
    "        'RMSE_speed': rmse_speed,\n",
    "        'RMSE_spacing': rmse_spacing,\n",
    "        'RMSE_acceleration': rmse_acceleration,\n",
    "        'Total_NRMSE': nrmse_v + nrmse_s + nrmse_acc,\n",
    "        'Total_RMSE': rmse_speed + rmse_spacing + rmse_acceleration,\n",
    "        'v_sim': v_sim_trim,\n",
    "        's_sim': s_sim_trim,\n",
    "        'acc_sim': acc_sim_trim,\n",
    "        'speed_error': speed_error,\n",
    "        'spacing_error': spacing_error,\n",
    "        'acceleration_error': acceleration_error,\n",
    "        'time_index': np.arange(min_len)\n",
    "    }\n",
    "\n",
    "def plot_prediction_errors_single(driver_name, vehicle_pair, track_data, errors):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "    fig.suptitle(f'{driver_name} ({vehicle_pair}) - Prediction Errors Over Time', fontsize=14)\n",
    "    \n",
    "    time_idx = errors['time_index']\n",
    "    \n",
    "    axes[0].plot(time_idx, errors['speed_error'], 'b-', linewidth=1.5, alpha=0.8)\n",
    "    axes[0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_ylabel('Speed Error (m/s)')\n",
    "    axes[0].set_title(f'Speed Prediction Error (Mean: {np.mean(errors[\"speed_error\"]):.3f}, Std: {np.std(errors[\"speed_error\"]):.3f})')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].fill_between(time_idx, errors['speed_error'], 0, alpha=0.3, color='blue')\n",
    "    \n",
    "    axes[1].plot(time_idx, errors['spacing_error'], 'g-', linewidth=1.5, alpha=0.8)\n",
    "    axes[1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_ylabel('Spacing Error (m)')\n",
    "    axes[1].set_title(f'Spacing Prediction Error (Mean: {np.mean(errors[\"spacing_error\"]):.3f}, Std: {np.std(errors[\"spacing_error\"]):.3f})')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].fill_between(time_idx, errors['spacing_error'], 0, alpha=0.3, color='green')\n",
    "    \n",
    "    axes[2].plot(time_idx, errors['acceleration_error'], 'purple', linewidth=1.5, alpha=0.8)\n",
    "    axes[2].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[2].set_ylabel('Acceleration Error (m/s²)')\n",
    "    axes[2].set_xlabel('Time Index')\n",
    "    axes[2].set_title(f'Acceleration Prediction Error (Mean: {np.mean(errors[\"acceleration_error\"]):.3f}, Std: {np.std(errors[\"acceleration_error\"]):.3f})')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].fill_between(time_idx, errors['acceleration_error'], 0, alpha=0.3, color='purple')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_drivers_prediction_errors(individual_results):\n",
    "    n_drivers = len(individual_results)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    fig.suptitle('Prediction Errors Over Time - All Drivers Comparison', fontsize=16)\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, n_drivers))\n",
    "    \n",
    "    for idx, (driver_id, result) in enumerate(individual_results.items()):\n",
    "        driver_name = result['driver_name']\n",
    "        errors = result['errors']\n",
    "        time_idx = errors['time_index']\n",
    "        \n",
    "        axes[0].plot(time_idx, errors['speed_error'], \n",
    "                    color=colors[idx], linewidth=1.5, alpha=0.7, label=driver_name)\n",
    "        \n",
    "        axes[1].plot(time_idx, errors['spacing_error'], \n",
    "                    color=colors[idx], linewidth=1.5, alpha=0.7, label=driver_name)\n",
    "        \n",
    "        axes[2].plot(time_idx, errors['acceleration_error'], \n",
    "                    color=colors[idx], linewidth=1.5, alpha=0.7, label=driver_name)\n",
    "    \n",
    "    axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_ylabel('Speed Error (m/s)')\n",
    "    axes[0].set_title('Speed Prediction Errors - All Drivers')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_ylabel('Spacing Error (m)')\n",
    "    axes[1].set_title('Spacing Prediction Errors - All Drivers')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[2].set_ylabel('Acceleration Error (m/s²)')\n",
    "    axes[2].set_xlabel('Time Index')\n",
    "    axes[2].set_title('Acceleration Prediction Errors - All Drivers')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_trajectories(individual_results):\n",
    "    n_drivers = len(individual_results)\n",
    "    fig, axes = plt.subplots(n_drivers, 3, figsize=(18, 4*n_drivers))\n",
    "    \n",
    "    if n_drivers == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (driver_id, result) in enumerate(individual_results.items()):\n",
    "        driver_name = result['driver_name']\n",
    "        track_data = result['track_data']\n",
    "        errors = result['errors']\n",
    "        \n",
    "        time_idx = np.arange(len(track_data['vFollReal']))\n",
    "        \n",
    "        axes[idx, 0].plot(time_idx, track_data['vFollReal'], 'b-', label='Real Speed', linewidth=2, alpha=0.8)\n",
    "        axes[idx, 0].plot(time_idx[:len(errors['v_sim'])], errors['v_sim'], 'r--', label='Simulated Speed', linewidth=2)\n",
    "        axes[idx, 0].set_ylabel('Speed (m/s)')\n",
    "        axes[idx, 0].set_title(f'{driver_name} - Speed')\n",
    "        axes[idx, 0].legend()\n",
    "        axes[idx, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[idx, 1].plot(time_idx, track_data['sReal'], 'g-', label='Real Spacing', linewidth=2, alpha=0.8)\n",
    "        axes[idx, 1].plot(time_idx[:len(errors['s_sim'])], errors['s_sim'], 'r--', label='Simulated Spacing', linewidth=2)\n",
    "        axes[idx, 1].set_ylabel('Spacing (m)')\n",
    "        axes[idx, 1].set_title(f'{driver_name} - Spacing')\n",
    "        axes[idx, 1].legend()\n",
    "        axes[idx, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        acc_real = calculate_smoothed_acceleration(track_data['vFollReal'], 0.1)\n",
    "        min_len = min(len(acc_real), len(errors['acc_sim']))\n",
    "        axes[idx, 2].plot(time_idx[:min_len], acc_real[:min_len], 'b-', label='Real Acceleration', linewidth=2, alpha=0.8)\n",
    "        axes[idx, 2].plot(time_idx[:min_len], errors['acc_sim'][:min_len], 'r--', label='Simulated Acceleration', linewidth=2)\n",
    "        axes[idx, 2].set_ylabel('Acceleration (m/s²)')\n",
    "        axes[idx, 2].set_title(f'{driver_name} - Acceleration')\n",
    "        axes[idx, 2].legend()\n",
    "        axes[idx, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        if idx == n_drivers - 1:\n",
    "            for ax in axes[idx, :]:\n",
    "                ax.set_xlabel('Time Index')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_parameter_distribution(individual_results):\n",
    "    all_params = []\n",
    "    driver_names = []\n",
    "    \n",
    "    for driver_id, result in individual_results.items():\n",
    "        all_params.append(result['params'])\n",
    "        driver_names.append(result['driver_name'])\n",
    "    \n",
    "    all_params = np.array(all_params)\n",
    "    param_names = ['v0 (m/s)', 'T (s)', 'a (m/s²)', 'b (m/s²)', 's0 (m)']\n",
    "    param_short_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    \n",
    "    fig, axes = plt.subplots(5, 1, figsize=(12, 15))\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    for i, (ax, param_name, short_name, color) in enumerate(zip(axes, param_names, param_short_names, colors)):\n",
    "        param_values = all_params[:, i]\n",
    "        \n",
    "        x_pos = np.arange(len(driver_names))\n",
    "        ax.plot(x_pos, param_values, 'o-', linewidth=2, markersize=8, color=color, alpha=0.8)\n",
    "        \n",
    "        for j, value in enumerate(param_values):\n",
    "            ax.annotate(f'{value:.2f}', \n",
    "                       (x_pos[j], param_values[j]),\n",
    "                       textcoords=\"offset points\",\n",
    "                       xytext=(0, 10),\n",
    "                       ha='center',\n",
    "                       fontsize=9,\n",
    "                       bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.7))\n",
    "        \n",
    "        ax.set_ylabel(param_name)\n",
    "        ax.set_title(f'{param_name} Distribution Across Drivers')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(driver_names, rotation=45)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        mean_val = np.mean(param_values)\n",
    "        std_val = np.std(param_values)\n",
    "        ax.axhline(y=mean_val, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_val:.2f}')\n",
    "        ax.axhline(y=mean_val + std_val, color='orange', linestyle=':', alpha=0.5, label=f'±1 STD')\n",
    "        ax.axhline(y=mean_val - std_val, color='orange', linestyle=':', alpha=0.5)\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    fig_box, ax_box = plt.subplots(figsize=(10, 6))\n",
    "    box_data = [all_params[:, i] for i in range(len(param_short_names))]\n",
    "    box_plot = ax_box.boxplot(box_data, labels=param_short_names, patch_artist=True)\n",
    "    \n",
    "    for patch, color in zip(box_plot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    ax_box.set_ylabel('Parameter Values')\n",
    "    ax_box.set_title('IDM Parameter Distributions Comparison')\n",
    "    ax_box.grid(True, alpha=0.3)\n",
    "    \n",
    "    for i, data in enumerate(box_data):\n",
    "        x = np.random.normal(i+1, 0.04, size=len(data))\n",
    "        ax_box.scatter(x, data, alpha=0.6, color=colors[i], s=30)\n",
    "    \n",
    "    for i, (data, name) in enumerate(zip(box_data, param_short_names)):\n",
    "        median = np.median(data)\n",
    "        mean = np.mean(data)\n",
    "        ax_box.text(i+1, np.max(data) + 0.1, f'mean: {mean:.2f}', \n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_inter_driver_heterogeneity_enhanced(ar_idm_data):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Task 1: Driver Heterogeneity Analysis (Enhanced Calibration)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nPerforming individual IDM calibration (multi-start optimization)...\")\n",
    "    individual_results = {}\n",
    "    \n",
    "    for driver_id, track_data in ar_idm_data['tracks'].items():\n",
    "        driver_name = track_data.get('driver_id', f'Driver_{driver_id}')\n",
    "        vehicle_pair = track_data.get('vehicle_pair', 'Unknown')\n",
    "        \n",
    "        print(f\"\\nCalibrating {driver_name} ({vehicle_pair})...\")\n",
    "        print(f\"Data points: {len(track_data['vFollReal'])}\")\n",
    "        \n",
    "        individual_params = calibrate_idm_enhanced(track_data)\n",
    "        \n",
    "        if individual_params is not None:\n",
    "            errors = calculate_errors(track_data, individual_params)\n",
    "            individual_results[driver_id] = {\n",
    "                'params': individual_params,\n",
    "                'errors': errors,\n",
    "                'driver_name': driver_name,\n",
    "                'vehicle_pair': vehicle_pair,\n",
    "                'data_points': len(track_data['vFollReal']),\n",
    "                'track_data': track_data\n",
    "            }\n",
    "            print(f\"  {driver_name} calibration successful\")\n",
    "            param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "            params_str = \" | \".join([f\"{name}: {individual_params[i]:.3f}\" for i, name in enumerate(param_names)])\n",
    "            print(f\"  Parameters: {params_str}\")\n",
    "            print(f\"  Total NRMSE: {errors['Total_NRMSE']:.4f}\")\n",
    "            \n",
    "            plot_prediction_errors_single(driver_name, vehicle_pair, track_data, errors)\n",
    "            \n",
    "        else:\n",
    "            print(f\"  {driver_name} calibration failed\")\n",
    "    \n",
    "    if not individual_results:\n",
    "        print(\"No successful individual calibration results\")\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Driver Heterogeneity Analysis Results\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return analyze_individual_results_enhanced(individual_results)\n",
    "\n",
    "def analyze_individual_results_enhanced(individual_results):\n",
    "    all_params = []\n",
    "    driver_names = []\n",
    "    all_nrmse_errors = []\n",
    "    all_rmse_errors = []\n",
    "    all_rmse_speed = []\n",
    "    all_rmse_spacing = []\n",
    "    all_rmse_acceleration = []\n",
    "    data_points = []\n",
    "    \n",
    "    for driver_id, result in individual_results.items():\n",
    "        all_params.append(result['params'])\n",
    "        driver_names.append(result['driver_name'])\n",
    "        all_nrmse_errors.append(result['errors']['Total_NRMSE'])\n",
    "        all_rmse_errors.append(result['errors']['Total_RMSE'])\n",
    "        all_rmse_speed.append(result['errors']['RMSE_speed'])\n",
    "        all_rmse_spacing.append(result['errors']['RMSE_spacing'])\n",
    "        all_rmse_acceleration.append(result['errors']['RMSE_acceleration'])\n",
    "        data_points.append(result['data_points'])\n",
    "    \n",
    "    all_params = np.array(all_params)\n",
    "    \n",
    "    param_means = np.mean(all_params, axis=0)\n",
    "    param_stds = np.std(all_params, axis=0)\n",
    "    param_cvs = param_stds / param_means\n",
    "    param_ranges = np.ptp(all_params, axis=0)\n",
    "    \n",
    "    param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    \n",
    "    print(\"\\nIndividual Parameter Statistics (Driver Heterogeneity):\")\n",
    "    print(f\"{'Parameter':<8} {'Mean':<8} {'Std':<8} {'CV':<10} {'Min':<8} {'Max':<8} {'Range':<8}\")\n",
    "    for i, name in enumerate(param_names):\n",
    "        min_val = np.min(all_params[:, i])\n",
    "        max_val = np.max(all_params[:, i])\n",
    "        range_val = param_ranges[i]\n",
    "        print(f\"{name:<8} {param_means[i]:<8.3f} {param_stds[i]:<8.3f} {param_cvs[i]:<10.3f} {min_val:<8.3f} {max_val:<8.3f} {range_val:<8.3f}\")\n",
    "    \n",
    "    print(\"\\nDetailed Parameters by Driver:\")\n",
    "    print(f\"{'Driver':<15} {'v0':<8} {'T':<8} {'a':<8} {'b':<8} {'s0':<8} {'Total_NRMSE':<12} {'Total_RMSE':<12} {'Data Points':<8}\")\n",
    "    for driver_id, result in individual_results.items():\n",
    "        params = result['params']\n",
    "        errors = result['errors']\n",
    "        points = result['data_points']\n",
    "        print(f\"{result['driver_name']:<15} {params[0]:<8.3f} {params[1]:<8.3f} {params[2]:<8.3f} {params[3]:<8.3f} {params[4]:<8.3f} {errors['Total_NRMSE']:<12.4f} {errors['Total_RMSE']:<12.4f} {points:<8}\")\n",
    "    \n",
    "    print(f\"\\nRMSE Detailed Statistics:\")\n",
    "    print(f\"{'Metric':<25} {'Mean':<10} {'Std':<10} {'Min':<10} {'Max':<10}\")\n",
    "    print(f\"{'RMSE_speed (m/s)':<25} {np.mean(all_rmse_speed):<10.4f} {np.std(all_rmse_speed):<10.4f} {np.min(all_rmse_speed):<10.4f} {np.max(all_rmse_speed):<10.4f}\")\n",
    "    print(f\"{'RMSE_spacing (m)':<25} {np.mean(all_rmse_spacing):<10.4f} {np.std(all_rmse_spacing):<10.4f} {np.min(all_rmse_spacing):<10.4f} {np.max(all_rmse_spacing):<10.4f}\")\n",
    "    print(f\"{'RMSE_acceleration (m/s²)':<25} {np.mean(all_rmse_acceleration):<10.4f} {np.std(all_rmse_acceleration):<10.4f} {np.min(all_rmse_acceleration):<10.4f} {np.max(all_rmse_acceleration):<10.4f}\")\n",
    "    print(f\"{'Total_RMSE':<25} {np.mean(all_rmse_errors):<10.4f} {np.std(all_rmse_errors):<10.4f} {np.min(all_rmse_errors):<10.4f} {np.max(all_rmse_errors):<10.4f}\")\n",
    "    \n",
    "    avg_cv = np.mean(param_cvs)\n",
    "    max_cv_param = param_names[np.argmax(param_cvs)]\n",
    "    max_cv_value = np.max(param_cvs)\n",
    "    \n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"Average parameter CV: {avg_cv:.3f}\")\n",
    "    print(f\"Most variable parameter: {max_cv_param} (CV = {max_cv_value:.3f})\")\n",
    "    print(f\"Average NRMSE fitting error: {np.mean(all_nrmse_errors):.4f} ± {np.std(all_nrmse_errors):.4f}\")\n",
    "    print(f\"Average RMSE fitting error: {np.mean(all_rmse_errors):.4f} ± {np.std(all_rmse_errors):.4f}\")\n",
    "    print(f\"Number of drivers analyzed: {len(driver_names)}\")\n",
    "    \n",
    "    print(\"\\nGenerating visualizations...\")\n",
    "    \n",
    "    plot_error_trajectories(individual_results)\n",
    "    plot_parameter_distribution(individual_results)\n",
    "    plot_all_drivers_prediction_errors(individual_results)\n",
    "    \n",
    "    fig_errors, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    bars1 = ax1.bar(driver_names, all_nrmse_errors, alpha=0.7, color='green')\n",
    "    ax1.set_xlabel('Drivers')\n",
    "    ax1.set_ylabel('Total NRMSE')\n",
    "    ax1.set_title('Total NRMSE by Driver')\n",
    "    ax1.set_xticklabels(driver_names, rotation=45)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, error in zip(bars1, all_nrmse_errors):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                f'{error:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    bars2 = ax2.bar(driver_names, all_rmse_errors, alpha=0.7, color='red')\n",
    "    ax2.set_xlabel('Drivers')\n",
    "    ax2.set_ylabel('Total RMSE')\n",
    "    ax2.set_title('Total RMSE by Driver')\n",
    "    ax2.set_xticklabels(driver_names, rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, error in zip(bars2, all_rmse_errors):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                f'{error:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'individual_results': individual_results,\n",
    "        'param_means': param_means,\n",
    "        'param_stds': param_stds,\n",
    "        'param_cvs': param_cvs,\n",
    "        'param_ranges': param_ranges,\n",
    "        'driver_names': driver_names,\n",
    "        'all_nrmse_errors': all_nrmse_errors,\n",
    "        'all_rmse_errors': all_rmse_errors,\n",
    "        'all_rmse_speed': all_rmse_speed,\n",
    "        'all_rmse_spacing': all_rmse_spacing,\n",
    "        'all_rmse_acceleration': all_rmse_acceleration\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcae37-081c-4c45-906a-c79debe01787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy import stats\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def combine_and_analyze_multiple_datasets(datasets_dict, dataset_names=None):\n",
    "    \"\"\"\n",
    "    Combine multiple datasets for unified driver heterogeneity analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    datasets_dict : dict\n",
    "        Dictionary of multiple datasets: {'dataset1': ar_idm_data1, 'dataset2': ar_idm_data2, ...}\n",
    "    dataset_names : list, optional\n",
    "        List of dataset names, if None use dictionary keys\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Multi-Dataset Combined Analysis - Driver Heterogeneity\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if dataset_names is None:\n",
    "        dataset_names = list(datasets_dict.keys())\n",
    "    \n",
    "    all_individual_results = {}\n",
    "    dataset_mapping = {}\n",
    "    \n",
    "    for dataset_name, dataset in datasets_dict.items():\n",
    "        print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        individual_results = {}\n",
    "        \n",
    "        for driver_id, track_data in dataset['tracks'].items():\n",
    "            unique_driver_id = f\"{dataset_name}_{driver_id}\"\n",
    "            driver_name = track_data.get('driver_id', f'Driver_{driver_id}')\n",
    "            vehicle_pair = track_data.get('vehicle_pair', 'Unknown')\n",
    "            \n",
    "            print(f\"Calibrating {driver_name} ({vehicle_pair})...\")\n",
    "            \n",
    "            individual_params = calibrate_idm_enhanced(track_data)\n",
    "            \n",
    "            if individual_params is not None:\n",
    "                errors = calculate_errors(track_data, individual_params)\n",
    "                individual_results[unique_driver_id] = {\n",
    "                    'params': individual_params,\n",
    "                    'errors': errors,\n",
    "                    'driver_name': driver_name,\n",
    "                    'vehicle_pair': vehicle_pair,\n",
    "                    'data_points': len(track_data['vFollReal']),\n",
    "                    'track_data': track_data,\n",
    "                    'dataset': dataset_name\n",
    "                }\n",
    "                dataset_mapping[unique_driver_id] = dataset_name\n",
    "                print(f\"  {driver_name} calibration successful\")\n",
    "            else:\n",
    "                print(f\"  {driver_name} calibration failed\")\n",
    "        \n",
    "        all_individual_results.update(individual_results)\n",
    "        print(f\"Dataset {dataset_name} completed: {len(individual_results)} successful calibrations\")\n",
    "    \n",
    "    if not all_individual_results:\n",
    "        print(\"No successful individual calibration results\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Multi-Dataset Combined Analysis Results\")\n",
    "    print(f\"Total drivers: {len(all_individual_results)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return analyze_combined_results(all_individual_results, dataset_mapping)\n",
    "\n",
    "def analyze_combined_results(all_individual_results, dataset_mapping):\n",
    "    all_params = []\n",
    "    driver_names = []\n",
    "    dataset_names = []\n",
    "    all_nrmse_errors = []\n",
    "    all_rmse_errors = []\n",
    "    data_points = []\n",
    "    \n",
    "    for driver_id, result in all_individual_results.items():\n",
    "        all_params.append(result['params'])\n",
    "        driver_names.append(result['driver_name'])\n",
    "        dataset_names.append(result['dataset'])\n",
    "        all_nrmse_errors.append(result['errors']['Total_NRMSE'])\n",
    "        all_rmse_errors.append(result['errors']['Total_RMSE'])\n",
    "        data_points.append(result['data_points'])\n",
    "    \n",
    "    all_params = np.array(all_params)\n",
    "    \n",
    "    param_means = np.mean(all_params, axis=0)\n",
    "    param_stds = np.std(all_params, axis=0)\n",
    "    param_cvs = param_stds / param_means\n",
    "    param_ranges = np.ptp(all_params, axis=0)\n",
    "    \n",
    "    param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    \n",
    "    print(\"\\nOverall Parameter Statistics (All Drivers):\")\n",
    "    print(f\"{'Param':<8} {'Mean':<8} {'Std':<8} {'CV':<10} {'Min':<8} {'Max':<8} {'Range':<8}\")\n",
    "    for i, name in enumerate(param_names):\n",
    "        min_val = np.min(all_params[:, i])\n",
    "        max_val = np.max(all_params[:, i])\n",
    "        range_val = param_ranges[i]\n",
    "        print(f\"{name:<8} {param_means[i]:<8.3f} {param_stds[i]:<8.3f} {param_cvs[i]:<10.3f} {min_val:<8.3f} {max_val:<8.3f} {range_val:<8.3f}\")\n",
    "    \n",
    "    unique_datasets = list(set(dataset_names))\n",
    "    print(f\"\\nStatistics by Dataset (Total {len(unique_datasets)} datasets):\")\n",
    "    \n",
    "    dataset_stats = {}\n",
    "    for dataset in unique_datasets:\n",
    "        dataset_indices = [i for i, ds in enumerate(dataset_names) if ds == dataset]\n",
    "        dataset_params = all_params[dataset_indices]\n",
    "        \n",
    "        dataset_stats[dataset] = {\n",
    "            'n_drivers': len(dataset_indices),\n",
    "            'param_means': np.mean(dataset_params, axis=0),\n",
    "            'param_stds': np.std(dataset_params, axis=0),\n",
    "            'param_cvs': np.std(dataset_params, axis=0) / np.mean(dataset_params, axis=0)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nDataset: {dataset} ({len(dataset_indices)} drivers)\")\n",
    "        for i, name in enumerate(param_names):\n",
    "            mean_val = dataset_stats[dataset]['param_means'][i]\n",
    "            std_val = dataset_stats[dataset]['param_stds'][i]\n",
    "            cv_val = dataset_stats[dataset]['param_cvs'][i]\n",
    "            print(f\"  {name}: {mean_val:.3f} ± {std_val:.3f} (CV: {cv_val:.3f})\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 50)\n",
    "    print(\"ANOVA - Parameter Differences Between Datasets\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, param_name in enumerate(param_names):\n",
    "        print(f\"\\nParameter {param_name} ANOVA:\")\n",
    "        \n",
    "        groups = []\n",
    "        for dataset in unique_datasets:\n",
    "            dataset_indices = [j for j, ds in enumerate(dataset_names) if ds == dataset]\n",
    "            group_data = all_params[dataset_indices, i]\n",
    "            groups.append(group_data)\n",
    "        \n",
    "        f_stat, p_value = stats.f_oneway(*groups)\n",
    "        \n",
    "        print(f\"  F-statistic: {f_stat:.4f}\")\n",
    "        print(f\"  P-value: {p_value:.4f}\")\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            print(f\"  → Significant differences between datasets (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"  → No significant differences between datasets (p ≥ 0.05)\")\n",
    "        \n",
    "        overall_mean = np.mean(all_params[:, i])\n",
    "        ss_total = np.sum((all_params[:, i] - overall_mean) ** 2)\n",
    "        \n",
    "        ss_between = 0\n",
    "        for dataset in unique_datasets:\n",
    "            dataset_indices = [j for j, ds in enumerate(dataset_names) if ds == dataset]\n",
    "            group_mean = np.mean(all_params[dataset_indices, i])\n",
    "            ss_between += len(dataset_indices) * (group_mean - overall_mean) ** 2\n",
    "        \n",
    "        ss_within = ss_total - ss_between\n",
    "        \n",
    "        print(f\"  Total variation (SS_total): {ss_total:.4f}\")\n",
    "        print(f\"  Between-group variation (SS_between): {ss_between:.4f}\")\n",
    "        print(f\"  Within-group variation (SS_within): {ss_within:.4f}\")\n",
    "        print(f\"  Between-group variation ratio: {ss_between/ss_total*100:.2f}%\")\n",
    "    \n",
    "    plot_combined_boxplot(all_params, param_names)\n",
    "    plot_parameter_histograms(all_params, param_names, all_individual_results)\n",
    "    plot_all_drivers_scatter(all_params, driver_names, param_names)\n",
    "    \n",
    "    return {\n",
    "        'all_individual_results': all_individual_results,\n",
    "        'dataset_mapping': dataset_mapping,\n",
    "        'param_means': param_means,\n",
    "        'param_stds': param_stds,\n",
    "        'param_cvs': param_cvs,\n",
    "        'param_ranges': param_ranges,\n",
    "        'driver_names': driver_names,\n",
    "        'dataset_names': dataset_names,\n",
    "        'all_nrmse_errors': all_nrmse_errors,\n",
    "        'all_rmse_errors': all_rmse_errors,\n",
    "        'dataset_stats': dataset_stats\n",
    "    }\n",
    "\n",
    "def plot_combined_boxplot(all_params, param_names):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    data_to_plot = [all_params[:, i] for i in range(len(param_names))]\n",
    "    \n",
    "    box_plot = plt.boxplot(data_to_plot, patch_artist=True, labels=param_names, \n",
    "                          widths=0.7, showfliers=True)\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    for patch, color in zip(box_plot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    for i, param_data in enumerate(data_to_plot):\n",
    "        x_jitter = np.random.normal(i+1, 0.05, size=len(param_data))\n",
    "        plt.scatter(x_jitter, param_data, alpha=0.4, color=colors[i], s=30, zorder=3)\n",
    "    \n",
    "    plt.xlabel('IDM Parameters')\n",
    "    plt.ylabel('Parameter Values')\n",
    "    plt.title(f'Combined IDM Parameter Distributions - All {len(all_params)} Drivers', fontsize=16)\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_parameter_histograms(all_params, param_names, all_individual_results):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    for i, (param_name, color) in enumerate(zip(param_names, colors)):\n",
    "        if i < len(axes):\n",
    "            param_data = all_params[:, i]\n",
    "            \n",
    "            n, bins, patches = axes[i].hist(param_data, bins=15, alpha=0.7, color=color, \n",
    "                                          density=True, edgecolor='black', linewidth=0.5)\n",
    "            \n",
    "            from scipy.stats import gaussian_kde\n",
    "            kde = gaussian_kde(param_data)\n",
    "            x_range = np.linspace(np.min(param_data), np.max(param_data), 100)\n",
    "            axes[i].plot(x_range, kde(x_range), 'r-', linewidth=2)\n",
    "            \n",
    "            mean_val = np.mean(param_data)\n",
    "            std_val = np.std(param_data)\n",
    "            axes[i].axvline(mean_val, color='red', linestyle='--', linewidth=2)\n",
    "            axes[i].axvline(mean_val + std_val, color='orange', linestyle=':', alpha=0.7)\n",
    "            axes[i].axvline(mean_val - std_val, color='orange', linestyle=':', alpha=0.7)\n",
    "            \n",
    "            axes[i].set_xlabel(param_name)\n",
    "            axes[i].set_ylabel('Density')\n",
    "            axes[i].set_title(f'{param_name} Distribution\\n(n={len(param_data)})')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            axes[i].text(0.05, 0.95, f'Mean: {mean_val:.2f}\\nStd: {std_val:.2f}\\nCV: {std_val/mean_val:.3f}', \n",
    "                        transform=axes[i].transAxes, fontsize=9,\n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                        verticalalignment='top')\n",
    "    \n",
    "    axes[5].axis('off')\n",
    "    total_drivers = len(all_params)\n",
    "    unique_datasets = len(set([res['dataset'] for res in all_individual_results.values()]))\n",
    "    \n",
    "    stats_text = f\"Overall Summary:\\n\\n\"\n",
    "    stats_text += f\"Total Drivers: {total_drivers}\\n\"\n",
    "    stats_text += f\"Total Datasets: {unique_datasets}\\n\\n\"\n",
    "    \n",
    "    avg_cv = np.mean([np.std(all_params[:, i]) / np.mean(all_params[:, i]) \n",
    "                     for i in range(len(param_names))])\n",
    "    stats_text += f\"Average CV: {avg_cv:.3f}\"\n",
    "    \n",
    "    axes[5].text(0.1, 0.9, stats_text, transform=axes[5].transAxes, \n",
    "                fontfamily='monospace', verticalalignment='top', fontsize=12,\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle('IDM Parameter Histograms - Combined Analysis', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_drivers_scatter(all_params, driver_names, param_names):\n",
    "    important_pairs = [(0, 1), (0, 2), (1, 2)]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    \n",
    "    for idx, (i, j) in enumerate(important_pairs):\n",
    "        x_data = all_params[:, i]\n",
    "        y_data = all_params[:, j]\n",
    "        \n",
    "        scatter = axes[idx].scatter(x_data, y_data, alpha=0.6, s=60, \n",
    "                                  c=colors[idx], edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        cov = np.cov(x_data, y_data)\n",
    "        lambda_, v = np.linalg.eig(cov)\n",
    "        lambda_ = np.sqrt(lambda_)\n",
    "        \n",
    "        ell = Ellipse(xy=(np.mean(x_data), np.mean(y_data)),\n",
    "                     width=lambda_[0]*2, height=lambda_[1]*2,\n",
    "                     angle=np.degrees(np.arctan2(v[1,0], v[0,0])),\n",
    "                     alpha=0.2, color=colors[idx])\n",
    "        axes[idx].add_patch(ell)\n",
    "        \n",
    "        axes[idx].set_xlabel(param_names[i])\n",
    "        axes[idx].set_ylabel(param_names[j])\n",
    "        axes[idx].set_title(f'{param_names[i]} vs {param_names[j]}')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        \n",
    "        corr = np.corrcoef(x_data, y_data)[0,1]\n",
    "        axes[idx].text(0.05, 0.95, f'ρ = {corr:.3f}', transform=axes[idx].transAxes,\n",
    "                      bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        axes[idx].text(0.05, 0.85, f'n = {len(x_data)}', transform=axes[idx].transAxes,\n",
    "                      bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle(f'Parameter Relationships - All {len(all_params)} Drivers', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage example\n",
    "datasets = {\n",
    "    'dataset1': ar_idm_data1,\n",
    "    'dataset2': ar_idm_data2, \n",
    "    'dataset3': ar_idm_data3,\n",
    "    'dataset4': ar_idm_data4,\n",
    "    'dataset5': ar_idm_data5,\n",
    "    'dataset6': ar_idm_data6,\n",
    "    'dataset7': ar_idm_data7,\n",
    "    'dataset8': ar_idm_data8,\n",
    "    'dataset9': ar_idm_data9,\n",
    "}\n",
    "\n",
    "print(\"Starting multi-dataset combined analysis...\")\n",
    "combined_results = combine_and_analyze_multiple_datasets(datasets)\n",
    "\n",
    "if combined_results:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Multi-Dataset Analysis Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"✓ Total drivers: {len(combined_results['all_individual_results'])}\")\n",
    "    print(f\"✓ Number of datasets: {len(combined_results['dataset_stats'])}\")\n",
    "    print(f\"✓ Average parameter CV: {np.mean(combined_results['param_cvs']):.3f}\")\n",
    "    \n",
    "    avg_cv = np.mean(combined_results['param_cvs'])\n",
    "    if avg_cv > 0.25:\n",
    "        diversity_level = \"Highly significant\"\n",
    "    elif avg_cv > 0.15:\n",
    "        diversity_level = \"Significant\" \n",
    "    elif avg_cv > 0.08:\n",
    "        diversity_level = \"Moderate\"\n",
    "    else:\n",
    "        diversity_level = \"Not significant\"\n",
    "        \n",
    "    print(f\"✓ Overall driver heterogeneity: {diversity_level} (Avg CV: {avg_cv:.3f})\")\n",
    "    print(\"✓ Multi-dataset combined analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360fc42-fbf0-40c3-9e83-a4bec3bbf67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from collections import deque\n",
    "\n",
    "def validate_basic_idm_model_comprehensive_improved(trace, model, train_data, val_data, n_samples=100):\n",
    "    vt_val = val_data['vt']\n",
    "    s_val = val_data['s']\n",
    "    dv_val = val_data['dv']\n",
    "    label_val = val_data['label_v']\n",
    "    id_idx_val = val_data['id_idx']\n",
    "    N_veh = val_data['n_vehicles']\n",
    "    \n",
    "    dt = 0.5\n",
    "    DELTA = 4\n",
    "    \n",
    "    print(f\"Drawing {n_samples} posterior samples...\")\n",
    "    with model:\n",
    "        posterior_samples = pm.sample_posterior_predictive(\n",
    "            trace, \n",
    "            var_names=['v0', 'T', 'a', 'b', 's0'], \n",
    "            samples=n_samples,\n",
    "            random_seed=42\n",
    "        )\n",
    "    \n",
    "    v0_samples = posterior_samples['v0']\n",
    "    T_samples = posterior_samples['T']\n",
    "    a_samples = posterior_samples['a']\n",
    "    b_samples = posterior_samples['b']\n",
    "    s0_samples = posterior_samples['s0']\n",
    "    \n",
    "    all_samples_speed_predictions = []\n",
    "    all_samples_spacing_predictions = []\n",
    "    all_samples_acceleration_predictions = []\n",
    "    \n",
    "    print(\"Generating predictions for each posterior sample...\")\n",
    "    for sample_idx in range(n_samples):\n",
    "        speed_predictions = np.zeros_like(vt_val)\n",
    "        spacing_predictions = np.zeros_like(s_val)\n",
    "        acceleration_predictions = np.zeros_like(vt_val)\n",
    "        \n",
    "        v0 = v0_samples[sample_idx]\n",
    "        T = T_samples[sample_idx]\n",
    "        a = a_samples[sample_idx]\n",
    "        b = b_samples[sample_idx]\n",
    "        s0 = s0_samples[sample_idx]\n",
    "        \n",
    "        for veh_id in range(N_veh):\n",
    "            mask = (id_idx_val == veh_id)\n",
    "            if np.sum(mask) > 0:\n",
    "                vt_veh = vt_val[mask]\n",
    "                s_veh = s_val[mask]\n",
    "                dv_veh = dv_val[mask]\n",
    "                \n",
    "                a_idm = idm_model(s_veh, vt_veh, dv_veh, v0, T, a, b, s0)\n",
    "                speed_pred = vt_veh + a_idm * dt\n",
    "                \n",
    "                speed_predictions[mask] = speed_pred\n",
    "                spacing_predictions[mask] = s_veh\n",
    "                acceleration_predictions[mask] = a_idm\n",
    "        \n",
    "        all_samples_speed_predictions.append(speed_predictions)\n",
    "        all_samples_spacing_predictions.append(spacing_predictions)\n",
    "        all_samples_acceleration_predictions.append(acceleration_predictions)\n",
    "    \n",
    "    print(\"Calculating real acceleration from validation data...\")\n",
    "    real_acceleration = np.zeros_like(vt_val)\n",
    "    valid_indices = []\n",
    "    \n",
    "    for veh_id in range(N_veh):\n",
    "        mask = (id_idx_val == veh_id)\n",
    "        if np.sum(mask) > 2:\n",
    "            vt_veh = vt_val[mask]\n",
    "            acc_veh = improved_robust_acceleration(vt_veh, dt=dt)\n",
    "            real_acceleration[mask] = acc_veh\n",
    "            valid_indices.extend(np.where(mask)[0])\n",
    "    \n",
    "    all_samples_speed_predictions = np.array(all_samples_speed_predictions)\n",
    "    all_samples_spacing_predictions = np.array(all_samples_spacing_predictions)\n",
    "    all_samples_acceleration_predictions = np.array(all_samples_acceleration_predictions)\n",
    "    \n",
    "    print(\"Calculating performance metrics...\")\n",
    "    \n",
    "    mean_speed_pred = np.mean(all_samples_speed_predictions, axis=0)\n",
    "    mean_acceleration_pred = np.mean(all_samples_acceleration_predictions, axis=0)\n",
    "    \n",
    "    speed_metrics = calculate_metrics(label_val, mean_speed_pred)\n",
    "    acceleration_metrics = calculate_metrics(real_acceleration[valid_indices], \n",
    "                                           mean_acceleration_pred[valid_indices])\n",
    "    spacing_metrics = calculate_metrics(s_val, np.mean(all_samples_spacing_predictions, axis=0))\n",
    "    \n",
    "    vehicle_metrics = {}\n",
    "    unique_vehicles = np.unique(id_idx_val)\n",
    "    \n",
    "    for veh_id in unique_vehicles:\n",
    "        mask = (id_idx_val == veh_id)\n",
    "        if np.sum(mask) > 0:\n",
    "            veh_speed_true = label_val[mask]\n",
    "            veh_speed_pred = mean_speed_pred[mask]\n",
    "            veh_accel_true = real_acceleration[mask]\n",
    "            veh_accel_pred = mean_acceleration_pred[mask]\n",
    "            veh_spacing_true = s_val[mask]\n",
    "            veh_spacing_pred = np.mean(all_samples_spacing_predictions[:, mask], axis=0)\n",
    "            \n",
    "            vehicle_metrics[veh_id] = {\n",
    "                'speed': calculate_metrics(veh_speed_true, veh_speed_pred),\n",
    "                'acceleration': calculate_metrics(veh_accel_true, veh_accel_pred),\n",
    "                'spacing': calculate_metrics(veh_spacing_true, veh_spacing_pred)\n",
    "            }\n",
    "    \n",
    "    individual_params = np.column_stack([\n",
    "        v0_samples, T_samples, a_samples, b_samples, s0_samples\n",
    "    ])\n",
    "    \n",
    "    validation_results = {\n",
    "        'all_samples_speed_predictions': all_samples_speed_predictions,\n",
    "        'all_samples_spacing_predictions': all_samples_spacing_predictions,\n",
    "        'all_samples_acceleration_predictions': all_samples_acceleration_predictions,\n",
    "        'real_acceleration': real_acceleration,\n",
    "        'valid_indices': valid_indices,\n",
    "        'n_samples': n_samples,\n",
    "        'speed_metrics': speed_metrics,\n",
    "        'acceleration_metrics': acceleration_metrics,\n",
    "        'spacing_metrics': spacing_metrics,\n",
    "        'vehicle_metrics': vehicle_metrics,\n",
    "        'individual_params': individual_params,\n",
    "        'mean_predictions': {\n",
    "            'speed': mean_speed_pred,\n",
    "            'acceleration': mean_acceleration_pred,\n",
    "            'spacing': np.mean(all_samples_spacing_predictions, axis=0)\n",
    "        },\n",
    "        'parameter_samples': {\n",
    "            'v0': v0_samples,\n",
    "            'T': T_samples,\n",
    "            'a': a_samples,\n",
    "            'b': b_samples,\n",
    "            's0': s0_samples\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"Basic IDM model validation completed!\")\n",
    "    return validation_results\n",
    "\n",
    "def plot_basic_idm_validation_results(val_data, validation_results):\n",
    "    vt_val = val_data['vt']\n",
    "    s_val = val_data['s']\n",
    "    label_val = val_data['label_v']\n",
    "    id_idx_val = val_data['id_idx']\n",
    "    \n",
    "    all_samples_speed = validation_results['all_samples_speed_predictions']\n",
    "    all_samples_spacing = validation_results['all_samples_spacing_predictions']\n",
    "    all_samples_acceleration = validation_results['all_samples_acceleration_predictions']\n",
    "    real_acceleration = validation_results['real_acceleration']\n",
    "    n_samples = validation_results['n_samples']\n",
    "    \n",
    "    unique_vehicles = np.unique(id_idx_val)\n",
    "    n_vehicles = len(unique_vehicles)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_vehicles, 3, figsize=(20, 5*n_vehicles))\n",
    "    if n_vehicles == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, veh_id in enumerate(unique_vehicles):\n",
    "        mask = (id_idx_val == veh_id)\n",
    "        if np.sum(mask) > 0:\n",
    "            veh_data_points = min(np.sum(mask), len(all_samples_speed[0]))\n",
    "            time_points = np.arange(veh_data_points)\n",
    "            \n",
    "            axes[idx, 0].plot(time_points, label_val[mask][:veh_data_points], 'k-', \n",
    "                             label='True Speed', linewidth=3, alpha=0.9)\n",
    "            \n",
    "            veh_speed_samples = np.array([sample[mask][:veh_data_points] for sample in all_samples_speed])\n",
    "            \n",
    "            lower_5 = np.percentile(veh_speed_samples, 5, axis=0)\n",
    "            upper_95 = np.percentile(veh_speed_samples, 95, axis=0)\n",
    "            lower_25 = np.percentile(veh_speed_samples, 25, axis=0)\n",
    "            upper_75 = np.percentile(veh_speed_samples, 75, axis=0)\n",
    "            \n",
    "            axes[idx, 0].fill_between(time_points, lower_5, upper_95, \n",
    "                                     alpha=0.3, color='red', label='90% CI')\n",
    "            axes[idx, 0].fill_between(time_points, lower_25, upper_75, \n",
    "                                     alpha=0.5, color='red', label='50% CI')\n",
    "            \n",
    "            mean_speed = np.mean(veh_speed_samples, axis=0)\n",
    "            median_speed = np.median(veh_speed_samples, axis=0)\n",
    "            \n",
    "            axes[idx, 0].plot(time_points, mean_speed, 'b-', \n",
    "                             label='Mean Prediction', linewidth=2, alpha=0.8)\n",
    "            axes[idx, 0].plot(time_points, median_speed, 'g--', \n",
    "                             label='Median Prediction', linewidth=2, alpha=0.8)\n",
    "            \n",
    "            sample_indices_to_plot = np.random.choice(len(all_samples_speed), \n",
    "                                                     min(10, len(all_samples_speed)), replace=False)\n",
    "            for sample_idx in sample_indices_to_plot:\n",
    "                axes[idx, 0].plot(time_points, all_samples_speed[sample_idx][mask][:veh_data_points], \n",
    "                                 'r-', alpha=0.2, linewidth=0.8)\n",
    "            \n",
    "            axes[idx, 0].set_title(f'Vehicle {veh_id} - Speed Prediction\\n({n_samples} Posterior Samples)', fontsize=12)\n",
    "            axes[idx, 0].set_xlabel('Time Index')\n",
    "            axes[idx, 0].set_ylabel('Speed (m/s)')\n",
    "            axes[idx, 0].legend(loc='upper right', fontsize=8)\n",
    "            axes[idx, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            axes[idx, 1].plot(time_points, s_val[mask][:veh_data_points], 'k-', \n",
    "                             label='True Spacing', linewidth=3, alpha=0.9)\n",
    "            \n",
    "            veh_spacing_samples = np.array([sample[mask][:veh_data_points] for sample in all_samples_spacing])\n",
    "            \n",
    "            lower_5_s = np.percentile(veh_spacing_samples, 5, axis=0)\n",
    "            upper_95_s = np.percentile(veh_spacing_samples, 95, axis=0)\n",
    "            lower_25_s = np.percentile(veh_spacing_samples, 25, axis=0)\n",
    "            upper_75_s = np.percentile(veh_spacing_samples, 75, axis=0)\n",
    "            \n",
    "            axes[idx, 1].fill_between(time_points, lower_5_s, upper_95_s, \n",
    "                                     alpha=0.3, color='magenta', label='90% CI')\n",
    "            axes[idx, 1].fill_between(time_points, lower_25_s, upper_75_s, \n",
    "                                     alpha=0.5, color='magenta', label='50% CI')\n",
    "            \n",
    "            mean_spacing = np.mean(veh_spacing_samples, axis=0)\n",
    "            median_spacing = np.median(veh_spacing_samples, axis=0)\n",
    "            \n",
    "            axes[idx, 1].plot(time_points, mean_spacing, 'g-', \n",
    "                             label='Mean Prediction', linewidth=2, alpha=0.8)\n",
    "            axes[idx, 1].plot(time_points, median_spacing, 'c--', \n",
    "                             label='Median Prediction', linewidth=2, alpha=0.8)\n",
    "            \n",
    "            for sample_idx in sample_indices_to_plot:\n",
    "                axes[idx, 1].plot(time_points, all_samples_spacing[sample_idx][mask][:veh_data_points], \n",
    "                                 'm-', alpha=0.2, linewidth=0.8)\n",
    "            \n",
    "            axes[idx, 1].set_title(f'Vehicle {veh_id} - Spacing Prediction\\n({n_samples} Posterior Samples)', fontsize=12)\n",
    "            axes[idx, 1].set_xlabel('Time Index')\n",
    "            axes[idx, 1].set_ylabel('Spacing (m)')\n",
    "            axes[idx, 1].legend(loc='upper right', fontsize=8)\n",
    "            axes[idx, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "            axes[idx, 2].plot(time_points, real_acceleration[mask][:veh_data_points], 'k-', \n",
    "                             label='True Acceleration', linewidth=3, alpha=0.9)\n",
    "            \n",
    "            veh_accel_samples = np.array([sample[mask][:veh_data_points] for sample in all_samples_acceleration])\n",
    "            \n",
    "            lower_5_a = np.percentile(veh_accel_samples, 5, axis=0)\n",
    "            upper_95_a = np.percentile(veh_accel_samples, 95, axis=0)\n",
    "            lower_25_a = np.percentile(veh_accel_samples, 25, axis=0)\n",
    "            upper_75_a = np.percentile(veh_accel_samples, 75, axis=0)\n",
    "            \n",
    "            axes[idx, 2].fill_between(time_points, lower_5_a, upper_95_a, \n",
    "                                     alpha=0.3, color='orange', label='90% CI')\n",
    "            axes[idx, 2].fill_between(time_points, lower_25_a, upper_75_a, \n",
    "                                     alpha=0.5, color='orange', label='50% CI')\n",
    "            \n",
    "            mean_acceleration = np.mean(veh_accel_samples, axis=0)\n",
    "            median_acceleration = np.median(veh_accel_samples, axis=0)\n",
    "            \n",
    "            axes[idx, 2].plot(time_points, mean_acceleration, 'c-', \n",
    "                             label='Mean Prediction', linewidth=2, alpha=0.8)\n",
    "            axes[idx, 2].plot(time_points, median_acceleration, 'y--', \n",
    "                             label='Median Prediction', linewidth=2, alpha=0.8)\n",
    "            \n",
    "            for sample_idx in sample_indices_to_plot:\n",
    "                axes[idx, 2].plot(time_points, all_samples_acceleration[sample_idx][mask][:veh_data_points], \n",
    "                                 'y-', alpha=0.2, linewidth=0.8)\n",
    "            \n",
    "            axes[idx, 2].set_title(f'Vehicle {veh_id} - Acceleration Prediction\\n({n_samples} Posterior Samples)', fontsize=12)\n",
    "            axes[idx, 2].set_xlabel('Time Index')\n",
    "            axes[idx, 2].set_ylabel('Acceleration (m/s²)')\n",
    "            axes[idx, 2].legend(loc='upper right', fontsize=8)\n",
    "            axes[idx, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Basic IDM Model - Comprehensive Validation Results', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    plot_basic_idm_parameter_distributions(validation_results)\n",
    "    plot_basic_idm_uncertainty_analysis(val_data, validation_results)\n",
    "\n",
    "def plot_basic_idm_parameter_distributions(validation_results):\n",
    "    individual_params = validation_results['individual_params']\n",
    "    param_samples = validation_results['parameter_samples']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    param_names = ['v0', 'T', 'a', 'b', 's0']\n",
    "    param_display_names = ['Desired Speed (v0)', 'Time Headway (T)', \n",
    "                          'Max Acceleration (a)', 'Comfort Decel (b)', \n",
    "                          'Min Spacing (s0)']\n",
    "    \n",
    "    for i in range(5):\n",
    "        row, col = i // 3, i % 3\n",
    "        params = individual_params[:, i]\n",
    "        axes[row, col].hist(params, bins=30, alpha=0.7, color='skyblue', \n",
    "                           edgecolor='black', density=True)\n",
    "        axes[row, col].axvline(np.mean(params), color='red', linestyle='--', \n",
    "                              label=f'Mean: {np.mean(params):.3f}')\n",
    "        axes[row, col].axvline(np.median(params), color='green', linestyle='--', \n",
    "                              label=f'Median: {np.median(params):.3f}')\n",
    "        axes[row, col].set_title(f'Posterior: {param_display_names[i]}', fontsize=12)\n",
    "        axes[row, col].set_xlabel('Parameter Value')\n",
    "        axes[row, col].set_ylabel('Density')\n",
    "        axes[row, col].legend(fontsize=8)\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    if individual_params.shape[0] > 1:\n",
    "        v0_params = individual_params[:, 0]\n",
    "        T_params = individual_params[:, 1]\n",
    "        \n",
    "        axes[1, 2].scatter(v0_params, T_params, alpha=0.6, color='purple')\n",
    "        axes[1, 2].set_xlabel('Desired Speed (v0)')\n",
    "        axes[1, 2].set_ylabel('Time Headway (T)')\n",
    "        axes[1, 2].set_title('Parameter Correlation: v0 vs T', fontsize=12)\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        correlation = np.corrcoef(v0_params, T_params)[0, 1]\n",
    "        axes[1, 2].text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "                       transform=axes[1, 2].transAxes, fontsize=10,\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Basic IDM - Posterior Parameter Distributions', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "def plot_basic_idm_uncertainty_analysis(val_data, validation_results):\n",
    "    all_samples_speed = validation_results['all_samples_speed_predictions']\n",
    "    all_samples_spacing = validation_results['all_samples_spacing_predictions']\n",
    "    all_samples_acceleration = validation_results['all_samples_acceleration_predictions']\n",
    "    n_samples = validation_results['n_samples']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    all_uncertainty_speed = []\n",
    "    all_uncertainty_spacing = []\n",
    "    all_uncertainty_acceleration = []\n",
    "    \n",
    "    unique_vehicles = np.unique(val_data['id_idx'])\n",
    "    \n",
    "    for veh_id in unique_vehicles:\n",
    "        mask = (val_data['id_idx'] == veh_id)\n",
    "        if np.sum(mask) > 0:\n",
    "            veh_speed_samples = np.array([sample[mask] for sample in all_samples_speed])\n",
    "            speed_intervals = np.percentile(veh_speed_samples, 95, axis=0) - np.percentile(veh_speed_samples, 5, axis=0)\n",
    "            all_uncertainty_speed.extend(speed_intervals)\n",
    "            \n",
    "            veh_spacing_samples = np.array([sample[mask] for sample in all_samples_spacing])\n",
    "            spacing_intervals = np.percentile(veh_spacing_samples, 95, axis=0) - np.percentile(veh_spacing_samples, 5, axis=0)\n",
    "            all_uncertainty_spacing.extend(spacing_intervals)\n",
    "            \n",
    "            veh_accel_samples = np.array([sample[mask] for sample in all_samples_acceleration])\n",
    "            accel_intervals = np.percentile(veh_accel_samples, 95, axis=0) - np.percentile(veh_accel_samples, 5, axis=0)\n",
    "            all_uncertainty_acceleration.extend(accel_intervals)\n",
    "    \n",
    "    uncertainty_data = [\n",
    "        (all_uncertainty_speed, 'Speed Uncertainty (90% CI Width)', 'lightblue', 'm/s'),\n",
    "        (all_uncertainty_spacing, 'Spacing Uncertainty (90% CI Width)', 'lightgreen', 'm'),\n",
    "        (all_uncertainty_acceleration, 'Acceleration Uncertainty (90% CI Width)', 'lightyellow', 'm/s²')\n",
    "    ]\n",
    "    \n",
    "    for i, (data, title, color, unit) in enumerate(uncertainty_data):\n",
    "        if i < 3:\n",
    "            row, col = i // 2, i % 2\n",
    "            axes[row, col].hist(data, bins=30, alpha=0.7, color=color, edgecolor='black')\n",
    "            axes[row, col].axvline(np.mean(data), color='red', linestyle='--', \n",
    "                                 label=f'Mean: {np.mean(data):.3f} {unit}')\n",
    "            axes[row, col].axvline(np.median(data), color='blue', linestyle='--', \n",
    "                                 label=f'Median: {np.median(data):.3f} {unit}')\n",
    "            axes[row, col].set_title(title, fontsize=12)\n",
    "            axes[row, col].set_xlabel(f'Uncertainty ({unit})')\n",
    "            axes[row, col].set_ylabel('Frequency')\n",
    "            axes[row, col].legend(fontsize=8)\n",
    "            axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(unique_vehicles) > 0:\n",
    "        first_vehicle_mask = (val_data['id_idx'] == unique_vehicles[0])\n",
    "        veh_speed_samples = np.array([sample[first_vehicle_mask] for sample in all_samples_speed])\n",
    "        \n",
    "        time_points = np.arange(min(100, np.sum(first_vehicle_mask)))\n",
    "        lower_5 = np.percentile(veh_speed_samples[:, :len(time_points)], 5, axis=0)\n",
    "        upper_95 = np.percentile(veh_speed_samples[:, :len(time_points)], 95, axis=0)\n",
    "        mean_speed = np.mean(veh_speed_samples[:, :len(time_points)], axis=0)\n",
    "        \n",
    "        axes[1, 1].fill_between(time_points, lower_5, upper_95, alpha=0.3, color='red', label='90% CI')\n",
    "        axes[1, 1].plot(time_points, mean_speed, 'b-', label='Mean Prediction', linewidth=2)\n",
    "        axes[1, 1].plot(time_points, val_data['label_v'][first_vehicle_mask][:len(time_points)], \n",
    "                       'k-', label='True Speed', linewidth=2, alpha=0.8)\n",
    "        axes[1, 1].set_title(f'Vehicle {unique_vehicles[0]} - Speed Uncertainty Over Time', fontsize=12)\n",
    "        axes[1, 1].set_xlabel('Time Index')\n",
    "        axes[1, 1].set_ylabel('Speed (m/s)')\n",
    "        axes[1, 1].legend(fontsize=8)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Basic IDM - Uncertainty Analysis', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "def print_basic_idm_validation_summary(validation_results):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BASIC IDM MODEL VALIDATION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    speed_metrics = validation_results['speed_metrics']\n",
    "    acceleration_metrics = validation_results['acceleration_metrics']\n",
    "    spacing_metrics = validation_results['spacing_metrics']\n",
    "    vehicle_metrics = validation_results['vehicle_metrics']\n",
    "    \n",
    "    print(f\"\\nOVERALL PERFORMANCE METRICS:\")\n",
    "    print(f\"Speed Prediction:\")\n",
    "    print(f\"  - RMSE: {speed_metrics['rmse']:.4f} m/s\")\n",
    "    print(f\"  - MAE: {speed_metrics['mae']:.4f} m/s\")\n",
    "    print(f\"  - NRMSE: {speed_metrics['nrmse']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nAcceleration Prediction:\")\n",
    "    print(f\"  - RMSE: {acceleration_metrics['rmse']:.4f} m/s²\")\n",
    "    print(f\"  - MAE: {acceleration_metrics['mae']:.4f} m/s²\")\n",
    "    print(f\"  - NRMSE: {acceleration_metrics['nrmse']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nSpacing Prediction:\")\n",
    "    print(f\"  - RMSE: {spacing_metrics['rmse']:.4f} m\")\n",
    "    print(f\"  - MAE: {spacing_metrics['mae']:.4f} m\")\n",
    "    print(f\"  - NRMSE: {spacing_metrics['nrmse']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nVEHICLE-LEVEL PERFORMANCE:\")\n",
    "    for veh_id, metrics in vehicle_metrics.items():\n",
    "        print(f\"\\nVehicle {veh_id}:\")\n",
    "        print(f\"  Speed - RMSE: {metrics['speed']['rmse']:.4f} m/s, MAE: {metrics['speed']['mae']:.4f} m/s\")\n",
    "        print(f\"  Acceleration - RMSE: {metrics['acceleration']['rmse']:.4f} m/s², MAE: {metrics['acceleration']['mae']:.4f} m/s²\")\n",
    "        print(f\"  Spacing - RMSE: {metrics['spacing']['rmse']:.4f} m, MAE: {metrics['spacing']['mae']:.4f} m\")\n",
    "    \n",
    "    individual_params = validation_results['individual_params']\n",
    "    param_display_names = ['Desired Speed', 'Time Headway', 'Max Acceleration', \n",
    "                          'Comfort Deceleration', 'Min Spacing']\n",
    "    \n",
    "    print(f\"\\nPARAMETER POSTERIOR STATISTICS:\")\n",
    "    for i, name in enumerate(param_display_names):\n",
    "        params = individual_params[:, i]\n",
    "        print(f\"  {name}: Mean = {np.mean(params):.3f}, Std = {np.std(params):.3f}, \"\n",
    "              f\"95% CI = [{np.percentile(params, 2.5):.3f}, {np.percentile(params, 97.5):.3f}]\")\n",
    "\n",
    "def run_basic_idm_calibration_only(ar_idm_data):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BASIC IDM MODEL CALIBRATION ONLY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nStep 1: Data Splitting\")\n",
    "    train_data, val_data = split_data_for_ar_idm(ar_idm_data, train_ratio=0.7)\n",
    "    \n",
    "    print(\"\\nStep 2: Model Training\")\n",
    "    trace, model = train_basic_idm_model(train_data)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BASIC IDM CALIBRATION COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return {\n",
    "        'trace': trace,\n",
    "        'model': model,\n",
    "        'train_data': train_data,\n",
    "        'val_data': val_data\n",
    "    }\n",
    "\n",
    "def run_basic_idm_validation_only(calibration_results, n_posterior_samples=100):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BASIC IDM MODEL VALIDATION ONLY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    trace = calibration_results['trace']\n",
    "    model = calibration_results['model']\n",
    "    train_data = calibration_results['train_data']\n",
    "    val_data = calibration_results['val_data']\n",
    "    \n",
    "    print(\"\\nStep 1: Model Validation with Posterior Sampling\")\n",
    "    validation_results = validate_basic_idm_model_comprehensive_improved(\n",
    "        trace, model, train_data, val_data, n_samples=n_posterior_samples\n",
    "    )\n",
    "    \n",
    "    print(\"\\nStep 2: Enhanced Results Visualization\")\n",
    "    plot_basic_idm_validation_results(val_data, validation_results)\n",
    "    \n",
    "    print(\"\\nStep 3: Performance Summary\")\n",
    "    print_basic_idm_validation_summary(validation_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BASIC IDM VALIDATION COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "def idm_model(s, v, dv, v0=30.0, T=1.5, a=1.0, b=2.0, s0=2.0):\n",
    "    s_star = s0 + max(0, v * T + (v * dv) / (2 * np.sqrt(a * b)))\n",
    "    acceleration = a * (1 - (v / v0)**4 - (s_star / s)**2)\n",
    "    acceleration = np.clip(acceleration, -b, a)\n",
    "    return acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3ff43-561f-42c2-bb4b-3aa18010140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results = run_basic_idm_calibration_only(ar_idm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807607c-a163-4677-bb93-8e0e55aed668",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results = run_basic_idm_validation_only(calibration_results, n_posterior_samples=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
