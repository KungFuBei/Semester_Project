{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b851d6-cf76-4f42-801d-a9cbd9e51006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytensor.tensor as pt\n",
    "import pytensor\n",
    "import numba\n",
    "pytensor.config.mode == 'NUMBA'\n",
    "import pandas as pd\n",
    "import pymc as pm  # 这是PyMC5\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pytensor.tensor as pt\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d46372-ba88-41e1-9dca-429df5334ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path, header=6, encoding='gbk')\n",
    "\n",
    "    header_df = pd.read_csv(file_path, header=None, nrows=6, encoding='gbk')\n",
    "    vehicle_names = []\n",
    "    for col_idx in range(1, 6):\n",
    "        vehicle_name = header_df.iloc[1, col_idx]\n",
    "        if pd.notna(vehicle_name):\n",
    "            vehicle_name_str = str(vehicle_name).strip()\n",
    "            vehicle_name_str = ' '.join(vehicle_name_str.split())\n",
    "            vehicle_names.append(vehicle_name_str)\n",
    "\n",
    "    if len(vehicle_names) < 5:\n",
    "        default_names = ['Vehicle 1', 'Vehicle 2', 'Vehicle 3', 'Vehicle 4', 'Vehicle 5']\n",
    "        vehicle_names = vehicle_names + default_names[len(vehicle_names):5]\n",
    "\n",
    "    print(\"Vehicle names:\", vehicle_names)\n",
    "\n",
    "    df.columns = [f'col_{i}' for i in range(len(df.columns))]\n",
    "\n",
    "    data = {\n",
    "        'time': df['col_0'].values,\n",
    "        'speeds': [\n",
    "            df['col_1'].values, \n",
    "            df['col_8'].values,  \n",
    "            df['col_15'].values,  \n",
    "            df['col_22'].values,  \n",
    "            df['col_29'].values  \n",
    "        ],\n",
    "        'head_coords': {\n",
    "            'e': df['col_5'].values,\n",
    "            'n': df['col_6'].values,\n",
    "            'u': df['col_7'].values\n",
    "        },\n",
    "        'distances': [\n",
    "            df['col_41'].values, \n",
    "            df['col_42'].values, \n",
    "            df['col_43'].values, \n",
    "            df['col_44'].values \n",
    "        ],\n",
    "        'vehicle_names': vehicle_names\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "def downsample_data(data, dt_target=0.5):\n",
    "    time = data['time']\n",
    "    if len(time) <= 1:\n",
    "        return data\n",
    "    \n",
    "    dt_current = np.mean(np.diff(time))\n",
    "    step = max(1, int(round(dt_target / dt_current)))\n",
    "    \n",
    "    indices = np.arange(0, len(time), step)\n",
    "    \n",
    "    data_downsampled = {\n",
    "        'time': time[indices],\n",
    "        'speeds': [speed[indices] for speed in data['speeds']],\n",
    "        'distances': [dist[indices] for dist in data['distances']],\n",
    "        'head_coords': {k: v[indices] for k, v in data['head_coords'].items()},\n",
    "        'vehicle_names': data['vehicle_names'],\n",
    "    }\n",
    "    \n",
    "    return data_downsampled\n",
    "\n",
    "def extract_vehicle_tracks(time, speeds, distances):\n",
    "    tracks = {}\n",
    "    \n",
    "    follower_leader_mapping = [\n",
    "        (1, 0, 0), \n",
    "        (2, 1, 1),  \n",
    "        (3, 2, 2),  \n",
    "        (4, 3, 3)   \n",
    "    ]\n",
    "    \n",
    "    for pair_id, (follower_idx, leader_idx, dist_idx) in enumerate(follower_leader_mapping):\n",
    "        follower_speed = speeds[follower_idx]\n",
    "        leader_speed = speeds[leader_idx]\n",
    "        spacing = distances[dist_idx]\n",
    "        \n",
    "        valid_mask = (\n",
    "            (follower_speed > 0) & (follower_speed < 50) &\n",
    "            (leader_speed > 0) & (leader_speed < 50) &\n",
    "            (spacing > 2) & (spacing < 200) &\n",
    "            (~np.isnan(follower_speed)) & \n",
    "            (~np.isnan(leader_speed)) & \n",
    "            (~np.isnan(spacing))\n",
    "        )\n",
    "        \n",
    "        valid_indices = np.where(valid_mask)[0]\n",
    "        valid_count = len(valid_indices)\n",
    "        \n",
    "        if valid_count < 10:  \n",
    "            print(f\"Vehicle pair {pair_id} (Vehicle {follower_idx+1} following Vehicle {leader_idx+1}) has insufficient data points, skipping\")\n",
    "            continue\n",
    "        \n",
    "        track_data = {\n",
    "            'vFollReal': follower_speed[valid_indices],\n",
    "            'vLeadReal': leader_speed[valid_indices],\n",
    "            'sReal': spacing[valid_indices],\n",
    "            'dvReal': leader_speed[valid_indices] - follower_speed[valid_indices],\n",
    "            'vFollReal_next': np.zeros(valid_count),\n",
    "            'driver_id': f\"Driver_{follower_idx+1}\", \n",
    "            'vehicle_pair': f\"V{follower_idx+1}_following_V{leader_idx+1}\"  \n",
    "        }\n",
    "\n",
    "        for i, idx in enumerate(valid_indices):\n",
    "            if idx < len(time) - 1 and valid_mask[idx + 1]:\n",
    "                track_data['vFollReal_next'][i] = follower_speed[idx + 1]\n",
    "            else:\n",
    "                track_data['vFollReal_next'][i] = np.nan\n",
    "        \n",
    "        final_valid_mask = ~np.isnan(track_data['vFollReal_next'])\n",
    "        final_count = np.sum(final_valid_mask)\n",
    "        \n",
    "        if final_count > 10:  \n",
    "            for key in ['vFollReal', 'vLeadReal', 'sReal', 'dvReal', 'vFollReal_next']:\n",
    "                track_data[key] = track_data[key][final_valid_mask]\n",
    "            \n",
    "            tracks[pair_id] = track_data\n",
    "            print(f\"Vehicle pair {pair_id}: {track_data['vehicle_pair']} - {final_count} valid data points\")\n",
    "        else:\n",
    "            print(f\"Vehicle pair {pair_id} has insufficient valid data points, skipping\")\n",
    "    \n",
    "    return tracks\n",
    "\n",
    "def convert_to_ar_idm_input(tracks):\n",
    "    vt_list, s_list, dv_list, label_v_list, id_idx_list = [], [], [], [], []\n",
    "    \n",
    "    for pair_id, track_data in tracks.items():\n",
    "        vt_list.append(track_data['vFollReal'])\n",
    "        s_list.append(track_data['sReal'])\n",
    "        dv_list.append(track_data['dvReal'])\n",
    "        label_v_list.append(track_data['vFollReal_next'])\n",
    "        id_idx_list.append(pair_id * np.ones(len(track_data['vFollReal']), dtype=int))\n",
    "    \n",
    "    vt = np.concatenate(vt_list)\n",
    "    s = np.concatenate(s_list)\n",
    "    dv = np.concatenate(dv_list)\n",
    "    label_v = np.concatenate(label_v_list)\n",
    "    id_idx = np.concatenate(id_idx_list)\n",
    "    \n",
    "    return vt, s, dv, label_v, id_idx\n",
    "\n",
    "def prepare_ar_idm_data(file_path, dt_target=0.1):\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    data_downsampled = downsample_data(data, dt_target=dt_target)\n",
    "    \n",
    "    tracks = extract_vehicle_tracks(\n",
    "        data_downsampled['time'], \n",
    "        data_downsampled['speeds'], \n",
    "        data_downsampled['distances']\n",
    "    )\n",
    "    \n",
    "    vt, s, dv, label_v, id_idx = convert_to_ar_idm_input(tracks)\n",
    "    \n",
    "    print(f\"Data preparation completed!\")\n",
    "    print(f\"Total data points: {len(vt)}\")\n",
    "    print(f\"Number of vehicles: {len(np.unique(id_idx))}\")\n",
    "    \n",
    "    return {\n",
    "        'vt': vt, 's': s, 'dv': dv, 'label_v': label_v, 'id_idx': id_idx,\n",
    "        'n_vehicles': len(np.unique(id_idx)), 'tracks': tracks\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0339426-133a-487d-a79b-ea42dca30d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle names: ['Audi(A8)', 'Tesla(Model3)', 'BMW(X5)', 'Audi(A6)', 'Mercedes(AClass)']\n",
      "Vehicle pair 0: V2_following_V1 - 1202 valid data points\n",
      "Vehicle pair 1: V3_following_V2 - 1202 valid data points\n",
      "Vehicle pair 2: V4_following_V3 - 1202 valid data points\n",
      "Vehicle pair 3: V5_following_V4 - 1202 valid data points\n",
      "Data preparation completed!\n",
      "Total data points: 4808\n",
      "Number of vehicles: 4\n"
     ]
    }
   ],
   "source": [
    "file_path = r'D:\\学习\\ETH学习是一辈子的大事\\project\\3\\ASta_040719_platoon311.csv'\n",
    "ar_idm_data = prepare_ar_idm_data(file_path, dt_target=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462f763-d4ec-4c57-bb04-43360128dd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
